{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import layers as L\n",
    "\n",
    "class PhysicsInformedNN(Model):\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, x1, u1, layers, dt, lb, ub, q):\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "        self.x0 = tf.cast(x0, dtype=tf.float32)\n",
    "        self.x1 = tf.cast(x1, dtype=tf.float32)\n",
    "\n",
    "        self.u0 = tf.cast(u0, dtype=tf.float32)\n",
    "        self.u1 = tf.cast(u1, dtype = tf.float32)\n",
    "\n",
    "        self.nn_layers = layers\n",
    "        self.dt = dt\n",
    "        self.q = max(q,1)\n",
    "\n",
    "        # Initialize NN\n",
    "        self.model = self.initialize_NN(self.nn_layers)\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)\n",
    "\n",
    "        # Load IRK weights\n",
    "        tmp = np.float32(np.loadtxt('./PINNs-master/Utilities/IRK_weights/Butcher_IRK%d.txt' % (q), ndmin = 2))\n",
    "        weights =  np.reshape(tmp[0:q**2+q], (q+1,q))\n",
    "        self.IRK_alpha = weights[0:-1,:]\n",
    "        self.IRK_beta = weights[-1:,:]\n",
    "        self.IRK_times = tmp[q**2+q:]\n",
    "\n",
    "        self.dummy_x0_tf = tf.ones((self.x0.shape[0], self.q)) # dummy variable for fwd_gradients\n",
    "        self.dummy_x1_tf = tf.ones((self.x1.shape[0], self.q)) # dummy variable for fwd_gradients\n",
    "\n",
    "        self.dummy_x0_tf2 = tf.ones((self.x0.shape[0], self.nn_layers[-2])) # dummy variable for second gradient\n",
    "        self.dummy_x1_tf2 = tf.ones((self.x1.shape[0], self.nn_layers[-2])) # dummy variable for second gradient\n",
    "\n",
    "\n",
    "    def initialize_NN(self, layers):        \n",
    "        model = tf.keras.models.Sequential()\n",
    "        for l in range(0,len(layers)-2):\n",
    "            model.add(L.Dense(units=layers[l+1], activation='tanh', input_dim=layers[l]))\n",
    "        model.add(L.Dense(units=layers[-1]))\n",
    "        return model\n",
    "\n",
    "    @tf.function\n",
    "    def net_U0(self, x):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            U = self.model(x)\n",
    "            print(f\"U: {U}\")\n",
    "            U_x = tape.gradient(U, x)\n",
    "            print(f\"U_x: {U_x}\")\n",
    "            U_xx = tape.gradient(U_x, x)\n",
    "        return U, U_x, U_xx\n",
    "\n",
    "    @tf.function\n",
    "    def net_U1(self, x):\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = tf.exp(self.lambda_2)\n",
    "        U = self.model(x)\n",
    "        with tf.GradientTape(persistent=True) as tape1:\n",
    "            tape1.watch(x)\n",
    "            U_x = tape1.gradient(U, x)\n",
    "        U_xx = tape1.gradient(U_x, x)\n",
    "        U_xxx = tape1.gradient(U_xx, x)\n",
    "        tape1.reset()\n",
    "        F = -lambda_1*U*U_x - lambda_2*U_xxx\n",
    "        U1 = U + self.dt*tf.matmul(F, tf.transpose((self.IRK_beta - self.IRK_alpha)))\n",
    "        return U1\n",
    "\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x0, x1, u0, u1):\n",
    "        U0_pred = self.net_U0(x0)\n",
    "        U1_pred = self.net_U1(x1)\n",
    "        loss = tf.reduce_sum(tf.square(u0 - U0_pred)) + \\\n",
    "               tf.reduce_sum(tf.square(u1 - U1_pred))\n",
    "        return loss\n",
    "\n",
    "    def train(self, nIter):\n",
    "        optimizer_Adam = tf.keras.optimizers.Adam()\n",
    "        for it in range(nIter):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss_value = self.call(self.x0, self.x1, self.u0, self.u1)\n",
    "            grads = tape.gradient(loss_value, self.trainable_variables)\n",
    "            optimizer_Adam.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "            # Print\n",
    "            if it % 10 == 0:\n",
    "                lambda_1_value = self.lambda_1.numpy()\n",
    "                lambda_2_value = np.exp(self.lambda_2.numpy())\n",
    "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f' % \n",
    "                      (it, loss_value, lambda_1_value, lambda_2_value))\n",
    "\n",
    "        # Using L-BFGS-B optimizer from tensorflow_probability after Adam optimizer\n",
    "        def loss_fn():\n",
    "            return self.call(self.x0, self.x1, self.u0, self.u1)\n",
    "\n",
    "        results = tfp.optimizer.lbfgs_minimize(\n",
    "            loss_fn,\n",
    "            initial_position=self.trainable_variables,\n",
    "            max_iterations=50000,\n",
    "            tolerance=1.0 * np.finfo(float).eps)\n",
    "\n",
    "        # Assign the optimization results to model parameters\n",
    "        var_updates = []\n",
    "        for var, new_var in zip(self.trainable_variables, results.position):\n",
    "            var_updates.append(var.assign(new_var))\n",
    "        self.model.updates = var_updates\n",
    "\n",
    "    def predict(self, x_star):\n",
    "        U0_star = self.net_U0(x_star)\n",
    "        U1_star = self.net_U1(x_star)\n",
    "        return U0_star, U1_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 50\n",
    "skip = 120\n",
    "\n",
    "N0 = 199\n",
    "N1 = 201\n",
    "layers = [1, 50, 50, 50, 50, q]\n",
    "\n",
    "data = scipy.io.loadmat('./PINNs-master/main/Data/KdV.mat')\n",
    "\n",
    "t_star = data['tt'].flatten()[:,None]\n",
    "x_star = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['uu'])\n",
    "\n",
    "idx_t = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.0    \n",
    "\n",
    "idx_x = np.random.choice(Exact.shape[0], N0, replace=False)\n",
    "x0 = x_star[idx_x,:]\n",
    "u0 = Exact[idx_x,idx_t][:,None]\n",
    "u0 = u0 + noise*np.std(u0)*np.random.randn(u0.shape[0], u0.shape[1])\n",
    "    \n",
    "idx_x = np.random.choice(Exact.shape[0], N1, replace=False)\n",
    "x1 = x_star[idx_x,:]\n",
    "u1 = Exact[idx_x,idx_t + skip][:,None]\n",
    "u1 = u1 + noise*np.std(u1)*np.random.randn(u1.shape[0], u1.shape[1])\n",
    "\n",
    "dt = (t_star[idx_t+skip] - t_star[idx_t]).item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = x_star.min(0)\n",
    "ub = x_star.max(0)\n",
    "\n",
    "model = PhysicsInformedNN(x0, u0, x1, u1, layers, dt, lb, ub, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(nIter = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U0_pred, U1_pred = model.predict(x_star) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
