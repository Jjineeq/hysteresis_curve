{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family']='Malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# APPLIED DISPLACEMENT TIME HISTORY\n",
    "dt = 0.001\n",
    "t = np.arange(0, 3 + dt, dt)\n",
    "a0 = 1\n",
    "fr = 1\n",
    "u = a0 * np.sin(2 * np.pi * fr * t[:len(t)])\n",
    "v = 2 * np.pi * fr * a0 * np.cos(2 * np.pi * fr * t[:len(t)])\n",
    "n = len(u)\n",
    "\n",
    "# INITIAL SETTINGS\n",
    "# Set the four model parameters\n",
    "ka = 5.0\n",
    "kb = 0.5\n",
    "alfa = 5.0\n",
    "beta = 1.0\n",
    "# Compute the internal model parameters\n",
    "u0 = -(1 / (2 * alfa)) * np.log(10 ** -20 / (ka - kb))\n",
    "f0 = ((ka - kb) / (2 * alfa)) * (1 - np.exp(-2 * alfa * u0))\n",
    "# Initialize the generalized force vector\n",
    "f = np.zeros(n)\n",
    "\n",
    "# CALCULATIONS AT EACH TIME STEP\n",
    "for i in range(1, n):\n",
    "    # Update the history variable\n",
    "    uj = u[i-1] + 2*u0*np.sign(v[i]) + np.sign(v[i])*(1/alfa)*np.log(np.abs(np.sign(v[i])*(alfa/(ka-kb))*(-2*beta*u[i-1]+np.exp(beta*u[i-1])-np.exp(-beta*u[i-1])+kb*u[i-1]+np.sign(v[i])*((ka-kb)/alfa)*np.exp(-2*alfa*u0)+np.sign(v[i])*f0-f[i-1])))\n",
    "    # Evaluate the generalized force at time t\n",
    "    if (np.sign(v[i])*uj-2*u0 < np.sign(v[i])*u[i]) or (np.sign(v[i])*u[i] < np.sign(v[i])*uj):\n",
    "        f[i] = -2*beta*u[i] + np.exp(beta*u[i]) - np.exp(-beta*u[i]) + kb*u[i] - np.sign(v[i])*((ka-kb)/alfa)*(np.exp(-alfa*(np.sign(v[i])*(u[i]-uj)+2*u0))-np.exp(-2*alfa*u0)) + np.sign(v[i])*f0\n",
    "    else:\n",
    "        f[i] = -2*beta*u[i] + np.exp(beta*u[i]) - np.exp(-beta*u[i]) + kb*u[i] + np.sign(v[i])*f0\n",
    "\n",
    "# PLOT\n",
    "plt.figure()\n",
    "plt.plot(u, f, 'k')\n",
    "plt.xlabel('generalized displacement')\n",
    "plt.ylabel('generalized force')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['u'] = u\n",
    "total['time'] = t\n",
    "total['f'] = f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>time</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.283144e-03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.017059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.256604e-02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.033687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.884844e-02</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.049898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.513010e-02</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.065705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-2.513010e-02</td>\n",
       "      <td>2.996</td>\n",
       "      <td>0.430554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-1.884844e-02</td>\n",
       "      <td>2.997</td>\n",
       "      <td>0.433910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>-1.256604e-02</td>\n",
       "      <td>2.998</td>\n",
       "      <td>0.437259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-6.283144e-03</td>\n",
       "      <td>2.999</td>\n",
       "      <td>0.440601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>-7.347881e-16</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.443936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 u   time         f\n",
       "0     0.000000e+00  0.000  0.000000\n",
       "1     6.283144e-03  0.001  0.017059\n",
       "2     1.256604e-02  0.002  0.033687\n",
       "3     1.884844e-02  0.003  0.049898\n",
       "4     2.513010e-02  0.004  0.065705\n",
       "...            ...    ...       ...\n",
       "2996 -2.513010e-02  2.996  0.430554\n",
       "2997 -1.884844e-02  2.997  0.433910\n",
       "2998 -1.256604e-02  2.998  0.437259\n",
       "2999 -6.283144e-03  2.999  0.440601\n",
       "3000 -7.347881e-16  3.000  0.443936\n",
       "\n",
       "[3001 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = total.iloc[:,0:2]\n",
    "y = total.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tf = tf.convert_to_tensor(x.values)\n",
    "y_tf = tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tf[:2000]\n",
    "x_te = x_tf[2000:]\n",
    "y_tr = y_tf[:2000]\n",
    "y_te = y_tf[2000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(2, 1), return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(64))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 2, 64)             16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,985\n",
      "Trainable params: 49,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = adam, metrics = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "63/63 [==============================] - 4s 2ms/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1386 - mse: 0.1386\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.1214\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1105 - mse: 0.1105\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1146 - mse: 0.1146\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1068 - mse: 0.1068\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.1066\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1025 - mse: 0.1025\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1024 - mse: 0.1024\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1039 - mse: 0.1039\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1019 - mse: 0.1019\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1035 - mse: 0.1035\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0996 - mse: 0.0996\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0939 - mse: 0.0939\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0778 - mse: 0.0778\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6340e-04 - mse: 6.6340e-04\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019  \n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0708e-04 - mse: 5.0708e-04\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.5323e-04 - mse: 7.5323e-04\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.2337e-04 - mse: 7.2337e-04\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8636e-04 - mse: 5.8636e-04\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8717e-04 - mse: 5.8717e-04\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017  \n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8021e-04 - mse: 9.8021e-04\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023  \n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1167e-04 - mse: 7.1167e-04\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4580e-04 - mse: 7.4580e-04\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5855e-04 - mse: 4.5855e-04\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4519e-04 - mse: 4.4519e-04\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7797e-04 - mse: 6.7797e-04\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.7031e-04 - mse: 7.7031e-04\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2572e-04 - mse: 3.2572e-04\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6301e-04 - mse: 7.6301e-04\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5125e-04 - mse: 3.5125e-04\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1028e-04 - mse: 5.1028e-04\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8818e-04 - mse: 8.8818e-04\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7722e-04 - mse: 6.7722e-04\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.3593e-04 - mse: 6.3593e-04\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3346e-04 - mse: 4.3346e-04\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8721e-04 - mse: 4.8721e-04\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6303e-04 - mse: 2.6303e-04\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9544e-04 - mse: 6.9544e-04\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3765e-04 - mse: 7.3765e-04\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4531e-04 - mse: 7.4531e-04\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4549e-04 - mse: 7.4549e-04\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3184e-04 - mse: 4.3184e-04\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9381e-04 - mse: 6.9381e-04\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6540e-04 - mse: 2.6540e-04\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8110e-04 - mse: 4.8110e-04\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6677e-04 - mse: 7.6677e-04\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010   \n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020  \n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8046e-04 - mse: 8.8046e-04\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4729e-04 - mse: 8.4729e-04\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4807e-04 - mse: 4.4807e-04\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9679e-04 - mse: 2.9679e-04\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2475e-04 - mse: 3.2475e-04\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5398e-04 - mse: 2.5398e-04\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4189e-04 - mse: 8.4189e-04\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1526e-04 - mse: 3.1526e-04\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6623e-04 - mse: 2.6623e-04\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2595e-04 - mse: 9.2595e-04\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1768e-04 - mse: 3.1768e-04\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9429e-04 - mse: 5.9429e-04\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4424e-04 - mse: 5.4424e-04\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5447e-04 - mse: 2.5447e-04\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8855e-04 - mse: 6.8855e-04\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9104e-04 - mse: 3.9104e-04\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9815e-04 - mse: 1.9815e-04\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2253e-04 - mse: 3.2253e-04\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.9153e-04 - mse: 5.9153e-04\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3679e-04 - mse: 4.3679e-04\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037  \n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3642e-04 - mse: 5.3642e-04\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5989e-04 - mse: 1.5989e-04\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0412e-04 - mse: 2.0412e-04\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2964e-04 - mse: 1.2964e-04\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2709e-04 - mse: 1.2709e-04\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4871e-04 - mse: 1.4871e-04\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026   \n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5371e-04 - mse: 5.5371e-04\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8380e-04 - mse: 2.8380e-04\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2724e-04 - mse: 1.2724e-04\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8442e-04 - mse: 2.8442e-04\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5682e-04 - mse: 5.5682e-04\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1701e-04 - mse: 2.1701e-04\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7445e-04 - mse: 3.7445e-04\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7795e-04 - mse: 4.7795e-04\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6503e-04 - mse: 6.6503e-04\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9131e-04 - mse: 1.9131e-04\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1567e-04 - mse: 1.1567e-04\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2270e-04 - mse: 3.2270e-04\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4176e-04 - mse: 4.4176e-04\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8202e-04 - mse: 1.8202e-04\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1159e-04 - mse: 2.1159e-04\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4559e-04 - mse: 3.4559e-04\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9387e-04 - mse: 8.9387e-04\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8771e-04 - mse: 3.8771e-04\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0810e-04 - mse: 2.0810e-04\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3905e-04 - mse: 2.3905e-04\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8658e-04 - mse: 1.8658e-04\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3498e-04 - mse: 2.3498e-04\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5490e-04 - mse: 2.5490e-04\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2295e-04 - mse: 6.2295e-04\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.5017e-04 - mse: 9.5017e-04\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016    \n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1590e-04 - mse: 2.1590e-04\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0228e-04 - mse: 1.0228e-04\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3565e-04 - mse: 1.3565e-04\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1193e-04 - mse: 1.1193e-04\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4197e-04 - mse: 1.4197e-04\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5518e-04 - mse: 1.5518e-04\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7805e-04 - mse: 1.7805e-04\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.3260e-05 - mse: 9.3260e-05\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2176e-04 - mse: 1.2176e-04\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6094e-04 - mse: 1.6094e-04\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012    \n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2314e-04 - mse: 5.2314e-04\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3889e-04 - mse: 1.3889e-04\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0093e-05 - mse: 7.0093e-05\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8634e-05 - mse: 5.8634e-05\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 8.8277e-05 - mse: 8.8277e-05\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5528e-05 - mse: 5.5528e-05\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1318e-04 - mse: 1.1318e-04\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2186e-05 - mse: 8.2186e-05\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3715e-04 - mse: 1.3715e-04\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 9.7775e-05 - mse: 9.7775e-05\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 9.3011e-05 - mse: 9.3011e-05\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.9759e-05 - mse: 5.9759e-05\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.2884e-05 - mse: 6.2884e-05\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5476e-04 - mse: 1.5476e-04\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.6315e-05 - mse: 7.6315e-05\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.8516e-05 - mse: 6.8516e-05\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.5804e-04 - mse: 3.5804e-04\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.6844e-04 - mse: 7.6844e-04\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.3864e-04 - mse: 3.3864e-04\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3238e-04 - mse: 1.3238e-04\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7089e-04 - mse: 1.7089e-04\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013  \n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.4839e-04 - mse: 5.4839e-04\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.4324e-04 - mse: 4.4324e-04\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.2620e-04 - mse: 5.2620e-04\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012    \n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2868e-04 - mse: 8.2868e-04\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8398e-05 - mse: 6.8398e-05\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2319e-04 - mse: 1.2319e-04\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5524e-05 - mse: 4.5524e-05\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1840e-05 - mse: 7.1840e-05\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7668e-05 - mse: 8.7668e-05\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5818e-05 - mse: 5.5818e-05\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8823e-05 - mse: 8.8823e-05\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9653e-05 - mse: 4.9653e-05\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8172e-05 - mse: 7.8172e-05\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0097e-04 - mse: 1.0097e-04\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0254e-05 - mse: 6.0254e-05\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0160e-04 - mse: 2.0160e-04\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0008e-04 - mse: 3.0008e-04\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8218e-05 - mse: 9.8218e-05\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7436e-04 - mse: 1.7436e-04\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9075e-04 - mse: 2.9075e-04\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017   \n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0599e-04 - mse: 4.0599e-04\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9333e-04 - mse: 1.9333e-04\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3828e-04 - mse: 1.3828e-04\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9063e-04 - mse: 2.9063e-04\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0394e-04 - mse: 1.0394e-04\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2744e-04 - mse: 2.2744e-04\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2700e-04 - mse: 2.2700e-04\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1966e-04 - mse: 1.1966e-04\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.5053e-05 - mse: 7.5053e-05\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.1720e-05 - mse: 5.1720e-05\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5116e-05 - mse: 5.5116e-05\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8142e-05 - mse: 8.8142e-05\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8117e-04 - mse: 4.8117e-04\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.3975e-04 - mse: 8.3975e-04\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0489e-04 - mse: 4.0489e-04\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5845e-04 - mse: 1.5845e-04\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1455e-04 - mse: 1.1455e-04\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1927e-04 - mse: 1.1927e-04\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6222e-04 - mse: 2.6222e-04\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4273e-04 - mse: 5.4273e-04\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7663e-04 - mse: 1.7663e-04\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6141e-04 - mse: 2.6141e-04\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0417e-04 - mse: 2.0417e-04\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5936e-04 - mse: 1.5936e-04\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9946e-04 - mse: 8.9946e-04\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6463e-04 - mse: 7.6463e-04\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8089e-04 - mse: 1.8089e-04\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0705e-04 - mse: 1.0705e-04\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012   \n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020  \n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9598e-04 - mse: 4.9598e-04\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0336e-04 - mse: 1.0336e-04\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7346e-05 - mse: 4.7346e-05\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5528e-05 - mse: 4.5528e-05\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4874e-05 - mse: 4.4874e-05\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1455e-05 - mse: 5.1455e-05\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2783e-05 - mse: 8.2783e-05\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8907e-04 - mse: 5.8907e-04\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9437e-04 - mse: 1.9437e-04\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5448e-05 - mse: 6.5448e-05\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0311e-04 - mse: 1.0311e-04\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6200e-05 - mse: 5.6200e-05\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2406e-05 - mse: 8.2406e-05\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4708e-05 - mse: 7.4708e-05\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2524e-04 - mse: 2.2524e-04\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9963e-04 - mse: 6.9963e-04\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.4850e-04 - mse: 3.4850e-04\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1678e-04 - mse: 1.1678e-04\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.1472e-05 - mse: 5.1472e-05\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3941e-05 - mse: 3.3941e-05\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4715e-05 - mse: 2.4715e-05\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9574e-05 - mse: 3.9574e-05\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1400e-04 - mse: 1.1400e-04\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9377e-05 - mse: 4.9377e-05\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.9869e-05 - mse: 7.9869e-05\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0453e-04 - mse: 1.0453e-04\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.5165e-05 - mse: 9.5165e-05\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0960e-04 - mse: 2.0960e-04\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2336e-04 - mse: 1.2336e-04\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4277e-04 - mse: 6.4277e-04\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9891e-04 - mse: 8.9891e-04\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032   \n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.1594e-04 - mse: 8.1594e-04\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.1803e-05 - mse: 8.1803e-05\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.5254e-05 - mse: 6.5254e-05\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.9041e-05 - mse: 6.9041e-05\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8628e-04 - mse: 2.8628e-04\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7955e-04 - mse: 1.7955e-04\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3990e-05 - mse: 4.3990e-05\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2694e-05 - mse: 4.2694e-05\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3032e-04 - mse: 1.3032e-04\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1886e-04 - mse: 1.1886e-04\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1203e-05 - mse: 7.1203e-05\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6220e-05 - mse: 2.6220e-05\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4066e-05 - mse: 2.4066e-05\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5837e-05 - mse: 2.5837e-05\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0580e-05 - mse: 6.0580e-05\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4703e-04 - mse: 7.4703e-04\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1387e-04 - mse: 3.1387e-04\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1551e-05 - mse: 7.1551e-05\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9753e-05 - mse: 8.9753e-05\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9269e-05 - mse: 4.9269e-05\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.7907e-05 - mse: 4.7907e-05\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.6536e-05 - mse: 7.6536e-05\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4278e-04 - mse: 1.4278e-04\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0158e-04 - mse: 2.0158e-04\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0613e-04 - mse: 1.0613e-04\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.4631e-05 - mse: 4.4631e-05\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.0908e-05 - mse: 4.0908e-05\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.6321e-05 - mse: 3.6321e-05\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2191e-04 - mse: 2.2191e-04\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4856e-05 - mse: 8.4856e-05\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.5892e-05 - mse: 6.5892e-05\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0405e-04 - mse: 3.0405e-04\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1694e-04 - mse: 6.1694e-04\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 0.0013  \n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1426e-04 - mse: 4.1426e-04\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4717e-04 - mse: 1.4717e-04\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4059e-05 - mse: 8.4059e-05\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9403e-05 - mse: 4.9403e-05\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 8.3613e-05 - mse: 8.3613e-05\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.8324e-05 - mse: 7.8324e-05\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1292e-05 - mse: 3.1292e-05\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8898e-05 - mse: 2.8898e-05\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6939e-05 - mse: 2.6939e-05\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.5865e-05 - mse: 5.5865e-05\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3266e-05 - mse: 4.3266e-05\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7328e-05 - mse: 4.7328e-05\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6918e-05 - mse: 7.6918e-05\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6267e-05 - mse: 6.6267e-05\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 9.0117e-05 - mse: 9.0117e-05\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8766e-05 - mse: 9.8766e-05\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.4230e-04 - mse: 2.4230e-04\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2491e-04 - mse: 1.2491e-04\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4148e-04 - mse: 2.4148e-04\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3196e-04 - mse: 2.3196e-04\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012   \n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8192e-04 - mse: 2.8192e-04\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0018e-04 - mse: 1.0018e-04\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9048e-04 - mse: 1.9048e-04\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.9631e-05 - mse: 6.9631e-05\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5384e-04 - mse: 1.5384e-04\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4470e-04 - mse: 1.4470e-04\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.8009e-05 - mse: 7.8009e-05\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6851e-04 - mse: 1.6851e-04\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4779e-05 - mse: 8.4779e-05\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8290e-04 - mse: 3.8290e-04\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2153e-04 - mse: 9.2153e-04\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 7.0733e-04 - mse: 7.0733e-04\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.1462e-04 - mse: 4.1462e-04\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1055e-05 - mse: 6.1055e-05\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9457e-05 - mse: 2.9457e-05\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5328e-05 - mse: 2.5328e-05\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6384e-05 - mse: 7.6384e-05\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 6.5898e-05 - mse: 6.5898e-05\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.7902e-05 - mse: 4.7902e-05\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.3566e-05 - mse: 5.3566e-05\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.3349e-05 - mse: 3.3349e-05\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.3574e-05 - mse: 3.3574e-05\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3392e-05 - mse: 2.3392e-05\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6690e-05 - mse: 6.6690e-05\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9625e-04 - mse: 1.9625e-04\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5742e-04 - mse: 2.5742e-04\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1144e-04 - mse: 1.1144e-04\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.4991e-05 - mse: 3.4991e-05\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.9050e-05 - mse: 4.9050e-05\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4014e-05 - mse: 4.4014e-05\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.2130e-05 - mse: 7.2130e-05\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2673e-04 - mse: 1.2673e-04\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2390e-04 - mse: 1.2390e-04\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6050e-05 - mse: 7.6050e-05\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4253e-04 - mse: 1.4253e-04\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8687e-04 - mse: 1.8687e-04\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5203e-04 - mse: 2.5203e-04\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5771e-04 - mse: 2.5771e-04\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.3568e-04 - mse: 6.3568e-04\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9735e-04 - mse: 3.9735e-04\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011  \n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5527e-04 - mse: 2.5527e-04\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.8776e-05 - mse: 3.8776e-05\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0528e-04 - mse: 1.0528e-04\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0840e-04 - mse: 1.0840e-04\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1903e-04 - mse: 1.1903e-04\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9809e-05 - mse: 5.9809e-05\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7375e-05 - mse: 5.7375e-05\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1468e-05 - mse: 5.1468e-05\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5730e-05 - mse: 8.5730e-05\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1817e-05 - mse: 2.1817e-05\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7701e-05 - mse: 2.7701e-05\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2386e-05 - mse: 6.2386e-05\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0041e-04 - mse: 4.0041e-04\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2024e-04 - mse: 1.2024e-04\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1890e-05 - mse: 7.1890e-05\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1141e-05 - mse: 3.1141e-05\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4982e-05 - mse: 1.4982e-05\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3947e-05 - mse: 2.3947e-05\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2844e-05 - mse: 6.2844e-05\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0413e-05 - mse: 5.0413e-05\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2957e-05 - mse: 4.2957e-05\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7539e-05 - mse: 3.7539e-05\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0471e-05 - mse: 4.0471e-05\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9913e-05 - mse: 2.9913e-05\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2921e-05 - mse: 3.2921e-05\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1502e-04 - mse: 4.1502e-04\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3694e-04 - mse: 7.3694e-04\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3695e-04 - mse: 7.3695e-04\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3023e-04 - mse: 3.3023e-04\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7319e-05 - mse: 6.7319e-05\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4270e-05 - mse: 7.4270e-05\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.6084e-05 - mse: 9.6084e-05\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9863e-05 - mse: 3.9863e-05\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7855e-05 - mse: 1.7855e-05\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9000e-05 - mse: 2.9000e-05\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7025e-05 - mse: 4.7025e-05\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4467e-05 - mse: 3.4467e-05\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3205e-05 - mse: 5.3205e-05\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1622e-04 - mse: 1.1622e-04\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3017e-05 - mse: 5.3017e-05\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7248e-04 - mse: 3.7248e-04\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7344e-04 - mse: 5.7344e-04\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1553e-04 - mse: 4.1553e-04\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9059e-04 - mse: 1.9059e-04\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9674e-05 - mse: 5.9674e-05\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0671e-05 - mse: 5.0671e-05\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6522e-05 - mse: 1.6522e-05\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7425e-05 - mse: 2.7425e-05\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7619e-05 - mse: 2.7619e-05\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6686e-05 - mse: 7.6686e-05\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4845e-05 - mse: 7.4845e-05\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2206e-05 - mse: 9.2206e-05\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5944e-05 - mse: 6.5944e-05\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5556e-04 - mse: 2.5556e-04\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1609e-05 - mse: 7.1609e-05\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0168e-04 - mse: 1.0168e-04\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3356e-05 - mse: 7.3356e-05\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5113e-05 - mse: 3.5113e-05\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4220e-05 - mse: 6.4220e-05\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9933e-05 - mse: 5.9933e-05\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3726e-05 - mse: 7.3726e-05\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8105e-05 - mse: 9.8105e-05\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5701e-04 - mse: 5.5701e-04\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8935e-04 - mse: 2.8935e-04\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5394e-04 - mse: 2.5394e-04\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2886e-04 - mse: 1.2886e-04\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8832e-05 - mse: 6.8832e-05\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.7034e-05 - mse: 7.7034e-05\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2831e-05 - mse: 4.2831e-05\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0344e-05 - mse: 3.0344e-05\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0470e-05 - mse: 7.0470e-05\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4915e-04 - mse: 1.4915e-04\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4549e-04 - mse: 2.4549e-04\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1217e-04 - mse: 2.1217e-04\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7911e-04 - mse: 2.7911e-04\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1764e-04 - mse: 3.1764e-04\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014  \n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3836e-04 - mse: 3.3836e-04\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8965e-05 - mse: 7.8965e-05\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5497e-05 - mse: 3.5497e-05\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7023e-05 - mse: 1.7023e-05\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3425e-05 - mse: 2.3425e-05\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0547e-05 - mse: 2.0547e-05\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8732e-05 - mse: 1.8732e-05\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8669e-05 - mse: 5.8669e-05\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1767e-05 - mse: 5.1767e-05\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5068e-05 - mse: 8.5068e-05\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5377e-05 - mse: 5.5377e-05\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5579e-05 - mse: 3.5579e-05\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6549e-05 - mse: 1.6549e-05\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9861e-05 - mse: 1.9861e-05\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010    \n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2397e-04 - mse: 5.2397e-04\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2998e-05 - mse: 6.2998e-05\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9675e-05 - mse: 4.9675e-05\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6985e-05 - mse: 2.6985e-05\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.5050e-05 - mse: 7.5050e-05\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6829e-05 - mse: 4.6829e-05\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0239e-05 - mse: 3.0239e-05\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7161e-05 - mse: 4.7161e-05\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5507e-04 - mse: 1.5507e-04\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1021e-04 - mse: 2.1021e-04\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8297e-04 - mse: 1.8297e-04\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0628e-04 - mse: 2.0628e-04\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6743e-04 - mse: 1.6743e-04\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5888e-05 - mse: 8.5888e-05\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8469e-05 - mse: 7.8469e-05\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0934e-05 - mse: 3.0934e-05\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7134e-05 - mse: 3.7134e-05\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1513e-05 - mse: 5.1513e-05\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7397e-04 - mse: 2.7397e-04\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6154e-04 - mse: 4.6154e-04\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1596e-04 - mse: 1.1596e-04\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7330e-05 - mse: 3.7330e-05\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5888e-05 - mse: 3.5888e-05\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.9481e-05 - mse: 9.9481e-05\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7568e-04 - mse: 3.7568e-04\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1091e-04 - mse: 2.1091e-04\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1154e-04 - mse: 1.1154e-04\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3120e-05 - mse: 3.3120e-05\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8599e-05 - mse: 6.8599e-05\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6605e-05 - mse: 2.6605e-05\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0909e-05 - mse: 6.0909e-05\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.9081e-05 - mse: 7.9081e-05\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4722e-05 - mse: 6.4722e-05\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6377e-05 - mse: 6.6377e-05\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0144e-04 - mse: 1.0144e-04\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8219e-05 - mse: 5.8219e-05\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2666e-05 - mse: 9.2666e-05\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5211e-04 - mse: 4.5211e-04\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2625e-04 - mse: 1.2625e-04\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.6210e-05 - mse: 3.6210e-05\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6437e-05 - mse: 4.6437e-05\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6762e-05 - mse: 2.6762e-05\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4628e-05 - mse: 4.4628e-05\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0204e-04 - mse: 2.0204e-04\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2396e-04 - mse: 1.2396e-04\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.7117e-05 - mse: 7.7117e-05\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4389e-05 - mse: 6.4389e-05\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2296e-05 - mse: 6.2296e-05\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8946e-05 - mse: 1.8946e-05\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9017e-05 - mse: 3.9017e-05\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2405e-04 - mse: 2.2405e-04\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4478e-04 - mse: 1.4478e-04\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7946e-05 - mse: 8.7946e-05\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6676e-05 - mse: 5.6676e-05\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0736e-05 - mse: 2.0736e-05\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8505e-05 - mse: 5.8505e-05\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1049e-04 - mse: 6.1049e-04\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1565e-04 - mse: 2.1565e-04\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8634e-05 - mse: 3.8634e-05\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0036e-05 - mse: 3.0036e-05\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8637e-05 - mse: 1.8637e-05\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7328e-05 - mse: 1.7328e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b209c11c50>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 968us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b209b8b6d0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGcCAYAAADgaRuPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNaElEQVR4nO3de3zT9b0/8FcuTXpPm97vFwrlDpZCuYiAguIFRBSdirrpxNs28eg4B/X8NrcxPWxzc9O5TUFRvCsqijfAIpdyLdeWUqDQUtrSe5P0luvn90eaaOXW0DTfXF7PxyOPzSRN3/1am1c+l/dHJoQQICIiIvIgudQFEBERUeBhACEiIiKPYwAhIiIij2MAISIiIo9jACEiIiKPYwAhIiIij2MAISIiIo9jACEiIiKPU0pdwLnYbDbU1tYiIiICMplM6nKIiIioD4QQMBgMSE5Ohlx+4TEOrwwgtbW1SEtLk7oMIiIiugTV1dVITU294HO8MoBEREQAsP8AkZGREldDREREfaHX65GWluZ8H78QrwwgjmmXyMhIBhAiIiIf05flE1yESkRERB7HAEJEREQexwBCREREHscAQkRERB7HAEJEREQexwBCREREHudyAOnq6sKiRYuQkZGB1NRULFmyBEKIs573ySefYMSIEUhPT8eECROwdetWtxRMREREvs/lAPL444/DZrOhoqICpaWlKCwsxIsvvtjrOSdPnsTdd9+NVatW4dSpU1i2bBnmzp0LnU7ntsKJiIjId7kUQNrb27Fq1SosX74cSqUSGo0GS5cuxcqVK3s979ChQxgyZAjy8/MBALNmzUJoaCiOHTvmvsqJiIjIZ7kUQIqLi5GVlQWtVuu8r6CgACUlJbBarc77pk6dioaGBqxfvx4A8M4770Cr1WL06NHnfF2j0Qi9Xt/rRkRERP7LpVbsdXV1SEhI6HVffHw8LBYLdDqdM5hER0fjz3/+M66++mqEhYXBZDJhy5YtUKlU53zdZ599Fs8888wl/ghERETka1waAbFYLGctOHWMfPyw7/uuXbvw5JNPYt++fTAYDPjiiy9w8803o7Ky8pyvu3TpUuh0OueturraxR+DiIiIfIlLIyBarRZNTU297mtsbERwcDA0Go3zvhdeeAGPPPIIxo4dCwCYOXMmbrrpJrzyyitYtmzZWa+rVquhVqsvoXwKBNUtndhd2YLK5k50Gi2IDAnCoLhwjM+KRnxEsNTlERHRJXApgOTl5aG8vBytra2Ijo4GABQVFaGgoABy+feDKSaTCUpl75cOCgqCyWRyQ8kUCIQQ+KrkDF7ZcgJ7T7Wd8zkyGXB5Tizun5qNqYNj+3T6IhEReQeZOFcTjwu48cYbkZycjH/84x9oa2vDlVdeid/97neYN2+e8znvv/8+nn76aWzYsAHp6enYv38/Zs6cibVr12Ly5MkX/R56vR4ajQY6nQ6RkZEu/1Dk26qaO/D4+wewp6oVACCXAWPTopCbGImIYCXaOk0oqdHjcN33i5WnDo7Fs/NHITU6VKqyiYgCnivv3y6NgADAihUrcN999yEpKQlhYWF44oknMG/ePKxevRq7d+/GCy+8gFtvvRV6vR6zZ89GR0cHoqOj8Z///KdP4YMC28ayevzynX3oNFkRqlLgvsuzcNfEDMRHnj3Vcqq5E68XVWL1zipsOdaE2X/bgr/dNhYzhyec45WJiMibuDwC4gkcAQlM7+46hSc/PgSbACZkafH8rWP6NKJxsqkDv/7APmIikwFPXTcMP5+a7YGKiYjoh1x5/+ZZMOQVPio+jf9ZYw8fC8al4q2fF/R5OiUrNgzvLJqI2yekQwjgD+vK8J/NFQNcMRER9QcDCElu89FG/PdHBwEA907JwvJbRiNI4dqvZpBCjj/eNBKPzxoCAPjjF0ewekeV22slIiL3YAAhSVW3dOKRt/fCYhOYMyYZT18/7JJ3s8hkMvzyqsF4ZMYgAMBv1pai6HjTRb6KiIikwABCkjFbbfjVu/tg6LbgsvQo/HnBaMjl/d9K+8TVubg5LxVWm8Ajb+/F6dZON1RLRETuxABCkvn7xmPYd6oNEcFK/P0nl0GtVLjldWUyGZbdNBKjUjRo7TTjl+/sg9XmdWutiYgCGgMISaL8jAEvb7IvFH1u/mikad3bvyM4SIGXF+YhQq3EvlNt+DcXpRIReRUGEPI4m03gyY8PwWITuGZEAq4fnTQg3yc1OhS/mTsCAPDX9UdRVsdTlomIvAUDCHnch8WnUVzVijCVAr/tCQgD5ea8FMwangCzVeDpT0pg41QMEZFXYAAhj+o0WfDnb8oBAI/NGoIkTciAfj+ZTIbf3TgCoSoFiqtasWZfzYB+PyIi6hsGEPKo17ZVosFgRJo2BHdNyvDI90zShOBXVw0GADz3ZRl0XWaPfF8iIjo/BhDymJYOE/7Vs/D0iatz3bbrpS/unZKF7LgwNLWb2CWViMgLMICQx7y65QQMRguGJ0Vizuhkj35vlVKO/549FACwcmslGgzdHv3+RETUGwMIeYS+24w3t9tboz86c7BbGo656urhCRiTFoUusxX/LOQoCBGRlBhAyCPe3F4Fg9GCwfHhmDUsQZIaZDIZllyTCwB4a2cVqlvYIZWISCoMIDTgukxWrNx6EgDw8IxBkox+OEzJicWUnBiYrQIvFR6XrA4iokDHAEID7r3dp9DcYUJqdIjH136cy2Mz7Sfmrtlbg3o914IQEUmBAYQGlM0m8HpRJQDggSuyoVRI/yuXn6nF+MxomKw2rOgZmSEiIs+S/t2A/Np3xxpR2dyJiGAl5uelSl2O08PTcwAAb+2ogq6TfUGIiDyNAYQG1Bs9ox8LxqUhTK2UtpgfmJ4bh6GJEegwWfHG9kqpyyEiCjgMIDRgKps6sOloIwDgbg91Pe0rmUyGh6YPAgCs2l4Jo8UqcUVERIGFAYQGzJs7qiCEfbQhMzZM6nLOct2oJCRGBqOp3YR1B+ukLoeIKKAwgNCA6DRZ8P6eagDAPZMzpS3mPIIUcud5NK9tq4QQPCmXiMhTGEBoQHx2oBaGbgsyYkIxbXCc1OWc1+0T0qFSynGoRoe9p1qlLoeIKGAwgNCAeH/PaQD2N3gpG49djDZMhXlj7b1JXttWKW0xREQBhAGE3O54QzuKq1qhkMsw/7IUqcu5qJ9OzgIAfFlyBnW6LomrISIKDAwg5HYf9Kz9mJEbh/jIYImrubjhyZEoyNLCahN4a8cpqcshIgoIDCDkVmarDR/trQEA3JqfJnE1fedYKPvu7mqYrTZpiyEiCgAMIORWhUca0NRuRGy4CjOGxktdTp/NGp6AuAg1mtqNWH+4XupyiIj8HgMIuZVj8en8vFQEecG5L30VpJDjtp4Rm7d2VklcDRGR//Oddwjyeg2GbhSWNwAAbs33nnNf+uonE9IgkwHbjjfjRGO71OUQEfk1BhBymzV7a2C1CeSlRyEnPkLqclyWGh2KGbn2aaN3dnExKhHRQGIAIbcQQjg7n/rS4tMfu7MgHQDwQfFpdJt5PgwR0UBhACG32HuqFScaOxASpMANY5KlLueSTc+NR7ImGG2dZnxZwvNhiIgGCgMIucV7u+2jH9ePTkK4WilxNZdOIZfh9gn2URD2BCEiGjgMINRvHUYLPu85Tfa28b47/eJw2/g0KOUy7KlqxZEzeqnLISLySwwg1G/rDtah02RFVmwY8jOipS6n3+Ijg3H1iAQAwNs7OQpCRDQQGECo3xyLTxfkp0Im896D51xxZ0EGAPvOng6jReJqiIj8DwMI9cuJxnbsqWqFXAbcnOd7vT/OZ1J2DLJiw9ButOCzA7VSl0NE5HcYQKhfPii2dz6dnhuPBB84eK6v5HIZ7uhZjLp6ZxWEEBJXRETkXxhA6JJZrDZ81BNAFozzn9EPh1vGpUKllKOkRo/91W1Sl0NE5FcYQOiSbTnWhAaDEdowFa4aliB1OW4XHabCnNH2niZvbuf5MERE7sQAQpfMsfj0xrHJUCn981fprkn2xaifH6xDc7tR4mqIiPyHf75r0IBr6TBhQ5n92PoF43y/98f5jE2LwuhUDUxWm/OkXyIi6j8GELokn+yrgdkqMCpFg+HJkVKXM6DummgfBVm9owpWGxejEhG5AwMIueyHB88tyPe/xac/NmdMMqJCg1DT1oXCIw1Sl0NE5BcYQMhlpbV6HDljgEopx1wfPniur4KDFM4Tft/cwcWoRETuwABCLnOMflw9PAFRoSqJq/GMhQUZkMmA7442orKpQ+pyiIh8HgMIuaTbbMWn++2dQR2jAoEgPSYU04fEAbCvBSEiov5hACGXrD9cD12XGUmaYEzJiZW6HI9ybMl9f081ukxWiashIvJtDCDkEsf0yy3jUqGQ+8fBc301bUg80rQh0HfzfBgiov5iAKE+q23rwtbjTQDsASTQKOQyLOw5JXfV9kqeD0NE1A8MINRnHxWfhhBAQZYWGTFhUpcjiVvz0xAcJEdprR67TrZIXQ4Rkc9iAKE+sdmE8+TbQFp8+mPRYSrMz7OP/ry69aTE1RAR+S4GEOqTXZUtONXSiXC1EteOSpS6HEndOyULALChrJ5bcomILhEDCPWJY/HpDaOTEKpSSlyNtHLiwzE9Nw5CAK8XVUpdDhGRT2IAoYsydJvx5aEzAAKj9Xpf/PzybAD2YKbrMktcDRGR72EAoYtae6AWXWYrcuLDkZceLXU5XmFKTgyGJkag02TFu7tOSV0OEZHPYQChi3p3l3365Sfj0yCTBVbvj/ORyWTOtSCriiphsdokroiIyLcwgNAFldTocKhGhyCFDDddliJ1OV5l7thkxIarUKvrxpclZ6Quh4jIpzCA0AV9f/BcImLC1RJX412CgxS4s6cx2atbT7IxGRGRCxhA6Ly6zVZ8vK8GAPCTCYHb++NCFk7MgEopx4HqNuw91Sp1OUREPoMBhM7ry5I6GLotSIkKwZRBgXXwXF/FRahx01j71NTLm05IXA0Rke9gAKHzeqdn8elt49MgD7CD51yxaFo2ZDJ7Y7Kj9QapyyEi8gkMIHROJxrbsetkC+Qy9v64mEFx4Zg9wt4d9l+bKiSuhojINzCA0Dm917P4dHpuPJI0IRJX4/0enDYIAPDpgVqcbu2UuBoiIu/HAEJnMVtt+Kjn4LnbxnPxaV+MSYvClJwYWG0Cr27hIXVERBfjcgDp6urCokWLkJGRgdTUVCxZsuSc2w+FEHj++eeRm5uL9PR05OTkwGxmy2pfsLGsAU3tJsSGq3Hl0Hipy/EZD0/PAQC8u/sUmtuNEldDROTdXA4gjz/+OGw2GyoqKlBaWorCwkK8+OKLZz1v2bJlWLt2LbZs2YJTp05h8+bNUCgUbimaBta7u+2txW8Zl4ogBQfJ+mryoBiMTtWg22zjIXVERBfh0rtLe3s7Vq1aheXLl0OpVEKj0WDp0qVYuXJlr+c1Njbiueeew5tvvon4ePsn6OTkZMjlfDPzdrVtXfjuaCMATr+4SiaT4eHp9rUgq4oq0W60SFwREZH3cikRFBcXIysrC1qt1nlfQUEBSkpKYLVanfd9/vnnuPzyy5GW1rc3MKPRCL1e3+tG0vhgz2kIAUzM1iIrNkzqcnzO1cMTkR0XBn23BW9ur5K6HCIir+VSAKmrq0NCQkKv++Lj42GxWKDT6Zz3HTp0CBkZGXjggQeQlZWFsWPH4o033jjv6z777LPQaDTOW1+DC7mX1Sacrdd/Mj5d4mp8k1wuwyM9a0H+vbkChm6ueyIiOheXAojFYjlrwalj5OOHp6QaDAZ89tlnWLBgAU6cOIHXX38dTzzxBL777rtzvu7SpUuh0+mct+rqald/DnKDbcebUNPWBU1IEGaPTJS6HJ9149hkZMeGoa3TjNe2VUpdDhGRV3IpgGi1WjQ1NfW6r7GxEcHBwdBoNM77YmNjMXv2bMycORMymQxjx47FwoULsXbt2nO+rlqtRmRkZK8beZ5j8elNl6UgOIgLhi+VUiHHozMHAwBe2XICui6OghAR/ZhLASQvLw/l5eVobf3+0K2ioiIUFBT0WmA6fPhwGAy9W1LL5XIEBwf3s1waKE3tRqw/XA+Ai0/dYc7oZAxJCIeh24IVW3hGDBHRj7kUQBITEzF79mw8+eSTsFgsaGpqwrJly7B48eJez7vllluwbds2bNiwAQBQVlaGt99+G7fddpvbCif3+nhvDcxWgTGpGgxL4ghUf8nlMjw2cwgAYOW2SrR2mCSuiIjIu7i8L3bFihWora1FUlIS8vPzsWjRIsybNw+rV6/Go48+CgAICQnBRx99hF//+tdITU3FHXfcgRUrVmD06NFu/wGo/2w2gbd32adffjKBi0/d5ZoRiRieFIl2owUvf8czYoiIfkgmztXGVGJ6vR4ajQY6nY7rQTxg2/Em3PnqToSrldj55FUIUyulLslvfHukHve+vgcqhRwb/msa0mNCpS6JiGjAuPL+zc5ghNU77P0q5uelMHy42YzceEwdHAuT1YZnvyyTuhwiIq/BABLg6vXd+KZn8emdBRkSV+N/ZDIZnr5+OOQy4MuSM9h5olnqkoiIvAIDSIB7b3c1rDaB8ZnRyE2MkLocv5SbGIHbe9bWPPPZYVisNokrIiKSHgNIALNYbXinZ/EpRz8G1n/NGgJNSBAO1+nx6taTUpdDRCQ5BpAAVljeiDpdN7RhKlw7ip1PB1JMuBpPXz8MAPDX9UdR2dQhcUVERNJiAAlgb+20Lz5dkJ8KtZKdTwfaLeNSMSUnBkaLDUvXHILN5nUb0IiIPIYBJECdau7Ed0cbAQB3sPeHR8hkMjx702gEB8mx/UQzXt3KDqlEFLi45zJAvVZ0EkIA04bEISMmTOpyAkZ6TCj+94bheOrjEiz/qhzjM7W4LD1a6rLcrstkRVFFEyoa29FutCI6NAijU6MwOlWDIAU/9xARA0hA0neb8f5u+4nD912eJXE1geeOCekoOt6MdYfq8Iu39+HjRyYjPsI/zkmq03XhpcLj+LD4NLrNZ+/2iY9Q4+5JGbj38iyEqvjnhyiQ8aNIAHp/dzU6TFYMSQjH1MGxUpcTcGQyGf44fxSyYsNQ09aFn6/agy6TVeqy+kUIgdU7qnDVX77D6h2n0G22ITU6BHPGJOPOgnTMHJaAqNAgNBiM+PM3RzHzL99hc88UIBEFJn4ECTAWqw2vbasEANw7JQsymUzaggKUJiQIK386Hjf9cxsOntbhobeK8a+F4xAc5HuLgY0WK5auOYQ1e2sAAHnpUfj1NUMxMVvb6/fLZLFh3aFa/Pnro6hp68I9r+3CYzOH4JdX5vD3kCgAcQQkwHxdWo+ati5ow1SYd1mK1OUEtKzYMLxydz6Cg+TYVN6I+9/wvZGQdqMFd63YhTV7a6CQy/DUdcPw4YOTMWlQzFmhQqWU46bLUrHhv6bhzoJ0CAE8v/4onvnsMHcEEQUgBpAAIoRw7rxYWJDuk5+2/c34TC1e++kEhKoU2HKsCbf8qwinWzulLqtPOk0W/Oy1Xdh1sgURaiVe++l43H9FNuTyC49mhKgUWHbTKPx+3kjIZMDrRZX4309L4IXnYhL5DaPFiq3HmvDypgr86esjWLH1JPZUtkhaE6dgAsj2imbsO9UGlVKOhZPY+dRbTBoUgzfvm4D73yhGaa0ec/6xFb+fNxLXj0ry2qmJLpMV972+B7srWxERrMTbP5+IUakal17jrokZCFMp8PgHB/DWzlNIiQ7Bw9NzBqhiosBktFjx+rZK/HvzCbR0mHo9dmt+KvIztRJVxgASUF7YeAyAfReGv+y68BfjMrT47JeX44E396CkRo9fvL0PH+Wexq+vGYrhyRc+0trTus1WLHpzD7afaEa4Wok37p3gcvhwmJ+XCn2XGb/97DCWf1WOzJgwXDcqyc0VEwWm4w3t+OU7+1BWpwcAxIarMXlQDKJDg9DUbkJ+hnThA2AACRg7TjRj58kWqBRyPDAtW+py6BxSokLw0UOT8fKmCrxUeByF5Y0oLG/EjNw43DY+HVcOjYdKKe2sqdFixUOri7HlWBNCVQq8/rPx/e5j8tMpWTjV0oWV205iyYcHMTwpEpmx7E1D1B97Kltw7+u7oe+2QBumwv9cOxTzL0uB0ov68MiEF0686vV6aDQa6HQ6REZ616c/X3Xnqzuw7XgzFk5Mxx/mjZK6HLqIisZ2/G3DMXx+sBaO/0I1IUG4PCcWUwfHYmx6FHLiwj36x8RkseHht4qxoawBwUFyvPbTCZg0KMYtr22x2nD7Kzuwu7IVI5Ij8dFDk7lGiegS7a9uw+3/2YEusxV56VH418JxiI/0zKi3K+/fDCABoKiiCXe8shNBChk2/XoGUqJCpC6J+uhEYzve33Maa/aeRoPB2Oux4CA5hiVFYmhiJHITwpGbGImhiRGIDlO5vY5usxW/eHsfNpTVQ62UY+VPx2NKjnt7yNTpunDdC1vQ2mnGw9MHYcnsoW59faJAcKq5Ezf9cxuaO0yYOjgW/7krHyEqz4V5BhBystkE5ry4FaW1etw9KQO/u3Gk1CXRJbBYbThwWofNRxux40QzSmv1aDdazvncuAg1hiZGYEhCBHITI5CbYP//l/pHqKndiPvf2ONcwPzq3fm4Ykhcf36c8/qq5AweXF0MhVyGTx+ZgpEpl7a2hCgQdZmsmPviVhxraMeI5Ei898AkhKs9u9LClfdvrgHxc2v21aC0Vo8ItRKPXjVY6nLoEikVcozLiMa4DPt6C5tNoLK5AyW1epSf0aP8TDvK6/WobulCo8GIRoMRW441Ob9eJgPStaEYlaLB+EwtxmVEY1hSJBQX2DIrhMDGsgYs/fgQGg1GaEKC8J+7xqEg2z3TLucye2Qirh+VhHWH6vDEBwfw2S8v59kxRH30+3WHcayhHfERaqz86XiPhw9XeXd11C+GbjP+9PURAMAjV+YgJlwtcUXkLnK5DNlx4ciOCwfGJDvv7zBacLTegPIzBpT3/O/RegOa2k2oau5EVXMnPj9YBwAIVytxWXoU8jO0yM+MxuD4cKiVCjS2G1Fc1YIP9pzGnqpWAMCguDD85+58DIoLH/Cf7ZkbR2BbRROOnDFg9Y4q/GwKzysiuphvSs/g7Z2nAAB/vW0sEjy05qM/GED82HNfHkG93oiMmFD8dHKm1OWQB4SplbgsPfqsnSlN7UYcqTNg36lW7K5qxb6qVhiMFmw51tRrpOTHVEo5fjY5E4/NGuKxRaGx4Wr8+ppcPPVxCf66/ihuHJsC7QCsayHyF/puM576pAQAsOiKbLevzxooDCB+antFM97qScPPzR/NHQUBLjZcjcsHq3F5z+GDVptA+RkDiqtasLuyFXsqW1Cr6wYAhKkUyEmIwMyh8bh1fJokn6R+Mj4db26vwpEzBvx1/VH8fh7XLhGdz9/WH0OjwYis2DA8fvUQqcvpMwYQP9TWacITHxwAANxRkO62rZLkPxRyGYYnR2J4ciTumpQJwL7mw2wVCFLIJO/AqpDL8P/mDMcdr+zEWzursHBiBnITIySticgbldXpsWp7JQDgmbkjoFb6zodNru7yMzabwBMfHEBNWxfStaH4n2u5lZH6RiaTQaWUSx4+HCYPisXsEYmwCeAv35RLXQ6RV/rjF2Ww2gSuG5U4YLvTBgoDiB8RQuD36w5jQ1kDVEo5/nlnHiKDg6Qui+iSPXHNEMhlwDeH63HotE7qcoi8StFx+xquIIUMS68dJnU5LmMA8RNCCPz5m3K8tq0SAPCnW0azhwL5vJz4CNw4NgUA8Px6joIQOQgh8H9f2/+buGNCOtK0oRJX5DoGED/QabLg8Q8O4KXCCgDA/94w3PlHm8jXPXrVYCjkMhSWN6K4Z1swUaDbWNaAA9VtCAlS4BdX+maPJy5CHQDdZivKzxhwrKEdxxvaUafrQmunGbouMyAEghRyqIPkiA1XIzEyGMlRIRicEI4hCRGIdaFXhxAC3x5pwLJ1ZTjR1AG5DFh20yjcPiF9AH86Is/KjA3DzXkpeH/Pafx94zGsuneC1CURSe7l7+wfOO+enIG4CN/s8cQA4gYWqw27TrZgy/Em7KlswYFqHUxW2yW9ljZMhcHx4RgUH47s2DBkxYYhTRuKcLUSaqUchm4Lqls7UVzVinUH63CsoR0AkBCpxl9vG4vJg3xj/zeRKx6ZkYMPi0/ju6ONKKvTY1gSj2igwLW7sgXFVa1QKeS4z4cb9TGAXCIhBHacaMGHxaex8Ug92jrNvR6PCVNhSEIEcuLDkaYNQXSoClGhKshlgNkq0G22osHQjTM6I061dOBofTuqWzvR0mHCzpMt2HmypU91BAfJcc/kTDw8PQeaEC44Jf+UEROGa0faW7S/svkEnr9trNQlEUnm3z2jHzePS/HYKbcDgQHERVabwMf7avCfzRU4Wt/uvF8bpsKM3HgUZGsxIVOLjJhQl7czdpmsON7QjqP1Bpxs6sDJpg6caOpAbVsXukxWmKw2hKkUiItQY2xaFCZmx+C60Unc6UIBYdEV2Vh3qA5rD9TiiWtykcxTnSkAHa03YENZA2Qy4P6p2VKX0y8MIC7YdbIF/+/TEhw5YwAAhAQpMO+yFNw4Nhn5GdFQ9vPQrBCVAqNSNRiVeu7dK1abuODhYUT+bExaFCZlx2D7iWas3HoST98wXOqSiDxuxZaTAIBrhifaz4LyYQwgfWCy2PDnb8rxypYTEAKIDFbioek5uKMg3aPTHgwfFOgWTcvG9hPNeHd3NRbPGuL1p30SuZOu04xPD9QAAH4+1XfXfjjwv96L0HWa8cDqPdhxwr4mY8G4VDx1/TBEhfJwLCJPmz4kDtlxYTjR2IGP9552tpEnCgRr9p1Gt9mGoYkRGJcRffEv8HLsA3IB9fpuzH95G3acaEG4Won/3DUOf1owhuGDSCIymQx3TcwAALyxvQpCCIkrIvIMIYTzgNE7C9K95siE/mAAOY/mdiPufHUnKho7kKQJxgcPTsLVIxKlLoso4N08LhWhKgWONbQ7RyaJ/N3Oky043tCOUJV97aE/YAA5h06TBfe8tgvHG9qRpAnG+w9MYt8BIi8RGRyEm3r+AL/Rcwookb9bvaMKAHDj2BRE+MnORwaQHxFCYMmHB1FSo0dMmAqrf17gkz32ifzZ3T1rP745XI8zum5piyEaYLpOM74prQdgn37xFwwgP/KfzSfw+cE6KOUy/OuucRjk49uciPxRbmIExmdGw2oT+GjvaanLIRpQnx+qhclqX3zqT4eMMoD8wKHTOvyp53TB38wdgfGZWokrIqLzuTU/DQDwwZ5qLkYlv7Zmr33r7c15qRJX4l4MID26zVYsfm8fLDaB60YlYqEfDXMR+aPrRiUhVKVAZXMn9vCUXPJTlU0dKK5qhVwG3Dg2Wepy3IoBpMfz64+iorED8RFqLJs3yi+2OBH5szC1EjeMTgIAvL+7WuJqiAbGmn320Y+pg+N8+tyXc2EAAVB+xoAVW+3tbZ+7eRSiw9jng8gXOKZh1h2qQ7vRInE1RO4lhMDH++xrnObn+cfW2x8K+AAihMD/+7QEVpvANSMScOXQBKlLIqI+GpcRjezYMHSarPjiYJ3U5RC51d5Tbahu6UKYSoGrh/tfH6qADyBrD9Ri58kWBAfJ8b883IrIp8hkMizoGQV5fw+nYci/fHnIHqpnDk9AiEohcTXuF9ABpNtsxR+/KAMA/GJGDlKj2e+DyNfMz0uBTAbsqWpFdUun1OUQuYUQAl+WnAFgX3DtjwI6gLyxvRL1eiNSokLw86nZUpdDRJcgITIYk7JjANhHNIn8wf7qNtS02adfpg2Jk7qcARGwAUTfbcY/N1UAABbPHIzgIP8b3iIKFI7tiWv3M4CQf/iiZ/rlqmEJfvv+FLAB5NXNJ9DWaUZOfDjm+1lzF6JAM3tEElQKOcrrDThyRi91OUT9IoTAF4f8e/oFCNAA0tJhcm67fXzWECjk7PlB5Ms0oUGYnmsfpuYoCPm6A6d1qGnrQqhK4fy99kcBGUBeL6pEh8mKEcmRmD3S/7Y2EQWiG8fa+yR8ur+WrdnJpzl2v1w5NN5vp1+AAAwg7UYLVhVVAgAemZHDjqdEfuKqYfEIUylQ09aFvafYmp180w93v1zvx9MvQAAGkHd3nYKuy4zs2DBcM4KjH0T+IjhIgWt6RjQ5DUO+6lhDO061dEKllGOaH0+/AAEWQIwWK17ZcgIA8MC0bK79IPIzjrNhvio9A5uN0zDkezaU1QMApgyKQahKKXE1AyugAsjHe2tQrzciMTIY8y7zv776RIFuSk4sItRK1OuN2FfNaRjyPRsO2wPIVcP8/1iQgAogMeFq5MSH4+dTs6BW+u/CHqJApVYqcOWweADAlz3bGIl8RVO7Efuq2wDY1zT5u4AKILOGJ+CbxVfg7kmZUpdCRAPk2pH2aZgvS85wNwz5lG+PNEAIYGRKJJI0IVKXM+ACKoAAgFwug0oZcD82UcCYNiQOIUH23TAlNWxKRr5jY8/6j6sC5FR2vhMTkV8JUSkwY6h998AXJXUSV0PUN91mK7YcawJgH60PBAwgROR3ZvdMw3zFaRjyEdtPNKPTZEViZDBGJEdKXY5HMIAQkd+5cmg8VEo5TjZ1oLzeIHU5RBdVeKQBAHDlsPiAaZDJAEJEfidcrcQVg2MBcDcM+YbvjjYCAGbk+v/uFwcGECLyS45pmK9LGUDIu1U2daCquRNBChkmDYqRuhyPYQAhIr901dB4yGXAkTMGnG7tlLocovNyjH6My4hGuNq/u5/+kMsBpKurC4sWLUJGRgZSU1OxZMmSCy7y6ujoQFxcHJ577rl+FUpE5IroMBXyM7UAgI1lDRJXQ3R+m3sCyLQhgTP9AlxCAHn88cdhs9lQUVGB0tJSFBYW4sUXXzzv81966SW0trIlMhF53syebpKO8zWIvI3RYkVRRTMAew+bQOJSAGlvb8eqVauwfPlyKJVKaDQaLF26FCtXrjzn82tra7FixQrceOONbimWiMgVM3vO09hxohn6brPE1RCdbU9lK7rMVsRFqDEsKULqcjzKpQBSXFyMrKwsaLVa530FBQUoKSmB1Wo96/mLFy/Gk08+iYiIwLqoROQdsuPCkR0XBrNVOIe5ibyJ4/fyisFxAbP91sGlAFJXV4eEhN4d2uLj42GxWKDT6Xrd//bbb6O5uRl33333RV/XaDRCr9f3uhERucOsnlEQxymjRN7EsQB1Wm5gTb8ALgYQi8Vy1oJTx8jHD5PbyZMn8dRTT+H111/vU6J79tlnodFonLe0tDRXyiIiOi/HseaF5Y2wWG0SV0P0vTO6bhw5Y4BMBkzNiZW6HI9zKYBotVo0NTX1uq+xsRHBwcHQaDQA7Ltk5s+fj//7v//rc5BYunQpdDqd81ZdXe1KWURE55WXHoXo0CDouszYU8UF8eQ9Nh+zj36MTo1CdJhK4mo8z6UNx3l5eSgvL0drayuio6MBAEVFRSgoKIBcbs8yGzduxJEjR7Bo0SIsWrQIANDZ2QmFQoGNGzdi/fr1Z72uWq2GWq3u789CRHQWpUKOGUPjsWZvDTYcrsfE7MBp9ETe7fvtt4E3/QK4OAKSmJiI2bNn48knn4TFYkFTUxOWLVuGxYsXO59zww03oKurC21tbc7bHXfcgd/85jfnDB9ERAPNuQ6krJ6H05FXsNmEc/vt1MGBN/0CXEIfkBUrVqC2thZJSUnIz8/HokWLMG/ePKxevRqPPvroQNRIRNQvU4fEQaWQo7K5ExWN7VKXQ4TyegNaOkwIVSkwJjVK6nIk4XLP19jYWHz66adn3b9w4UIsXLjwnF/z+uuvu1wYEZG7hKuVKMjWYsuxJnx7pAE58WwNQNLadty+nnJ8phYqZWCeihKYPzURBZwrh9q7ohYeYT8Qkt72numXKTmBuyaJAYSIAoLjmPPdlS0wsCsqSchitWHnyRYAwORBgbn+A2AAIaIAkRkbhqzYMFhsAtuON0tdDgWwgzU6tBst0IQEYXhSpNTlSIYBhIgChmO746Zyno5L0inqWf8xKTsGcnlgtV//IQYQIgoYMxzrQMobuB2XJFPE9R8AGECIKIAUZGkRHCRHvd6IsjqD1OVQAOo2W50deScF8PoPgAGEiAJIcJACU3r+6G86ymkY8ry9Va0wWWxIiFRjUFyY1OVIigGEiALK9J5TRzdxOy5JYFuFff3H5EGxfTqs1Z8xgBBRQJnesx23+FQrdF3cjkue5Vj/MXlQYK//ABhAiCjApGlDkRMfDqtNYOuxpot/AZGbGLrNOHhaBwCYnBPY6z8ABhAiCkAzeqZhCrkdlzxo54kWWG0CmTGhSIkKkbocyTGAEFHAcUzDbCpvhM3G7bjkGc7pF45+AGAAIaIAlJ8ZjTCVAk3tRpTW6qUuhwJEkXMBKtd/AAwgRBSA1EoFpvR8CmVXVPKEpnYjjpyx956ZlM0AAjCAEFGA+mFXVKKB5jj9dmhiBGLC1RJX4x0YQIgoIDn6geyrbkNLh0niasjffd9+nes/HBhAiCggJWlCMDQxAkIAW46xKRkNLK7/OBsDCBEFrGmOrqjlDCA0cE63dqKquRMKuQwTsrRSl+M1GECIKGBNH2JfB7L5KLfj0sBxTL+MTtUgIjhI4mq8BwMIEQWs/MxohKuVaO4w4VCNTupyyE85FqBOCfDTb3+MAYSIAlaQQo4pOfY5eU7D0EAQQmDbca7/OBcGECIKaM6uqEe5HZfcr6KxAw0GI1RKOfIyoqUux6swgBBRQHNsx91f3YZWbsclN3PsfsnPiEZwkELiarwLAwgRBbQkTQhyE+zbcTdzOy65WdFx9v84HwYQIgp4jlGQ77gOhNzIahPYfsIeQCZx/cdZGECIKOA5+oF8x+245EZldXrousyIUCsxOkUjdTlehwGEiAJefoYWYSoFmjtMKKnldlxyD8ful4JsLZQKvt3+GK8IEQU8lVL+g9NxOQ1D7uFoQDaJ/T/OiQGEiAg/2I7L03HJDUwWG3adbAEAZ68Z6o0BhIgIvbfjtnVyOy71z/7qNnSZrYgJU2FIfITU5XglBhAiIgDJUSEYkhAOmwA2H2uSuhzycY7+HxMHxUAul0lcjXdiACEi6sFpGHIXZ/8Prv84LwYQIqIe04fYp2F4Oi71R6fJgn3VrQC4/uNCGECIiHrkZ9q34za1m3C4Ti91OeSjdp1sgdkqkBIVgnRtqNTleC0GECKiHiqlHJOd23E5DUOXxrH9dkpODGQyrv84HwYQIqIfcOyGYT8QulSOBag8/+XCGECIiH7AsRB176lW6DrNEldDvqat04TSWvv0Hc9/uTAGECKiH0iJCsHgePt23C3HOQpCrtle0QwhgMHx4YiPCJa6HK/GAEJE9COchqFLtY3TL33GAEJE9COOaRiejkuucvT/mMzpl4tiACEi+pH8zGiEqhRoNBi5HZf6rE7XhRNNHZDLgIJsBpCLYQAhIvoRtVKByT0dLL87ymkY6hvH6Meo1ChoQoIkrsb7MYAQEZ3D9+tA2A+E+sax/oPTL33DAEJEdA7Tetqy7z3VBl0Xt+PShQkheP6LixhAiIjOIU0bikFxYbDaBLbydFy6iBNNHTij74ZKKUd+ZrTU5fgEBhAiovPg6bjUV4726+PSoxEcpJC4Gt/AAEJEdB6OdSDfHW2EENyOS+dXdNzR/4PrP/qKAYSI6DwmZGkREqRAA7fj0gXYbALbT/T0/2ADsj5jACEiOg/7dlz7J1p2RaXzOVynR1unGeFqJUanaKQux2cwgBARXYBzGoYBhM5j8zH778bEbC2UCr6t9hWvFBHRBTgWohafauV2XDqnLUft6z+u6Nm6TX3DAEJEdAFp2lBk92zH3Xac23Gpt06TBXuqWgAAUwczgLiCAYSI6CKmD+F2XDq3nSdaYLYKpEaHIDMmVOpyfAoDCBHRRXA7Lp2PY/3H1MFxkMlkElfjWxhAiIguwrEdt15vRFmdQepyyIts6emSO20It9+6igGEiOgigoMUmOTYjnuU0zBkV9vWheMN7ZDLgEk8/8VlDCBERH3w/em43I5Ldo4zgsamRUETEiRxNb6HAYSIqA8cC1GLq1qh7+Z2XOq9/oNcxwBCRNQH6TGhyI7t2Y7L03EDntUmsPW4o/8Hp18uBQMIEVEfTeM0DPUoqdGhrdOMCLUSY1KjpC7HJzGAEBH1kaMr6qajDdyOG+C29Ey/TM6JYfv1S8SrRkTURwVZWoSq7NtxS2t5Om4g29wzDcf1H5eOAYSIqI+CgxS4vOe49Q1l9RJXQ1JpN1qwt6oVAHAFA8glYwAhInLBzGEJAICNZewHEqi2VzTDYhPIiAlFOtuvXzIGECIiF8wYGg+ZDDhUo0O9vlvqckgChT1nAk3n6bf9wgBCROSCuAi1c9cDR0ECjxACm470BJCh8RJX49tcDiBdXV1YtGgRMjIykJqaiiVLlpy1GtxsNuN3v/sdRo0ahbS0NEydOhX79+93V81ERJKaOcz+xrOR60ACztH6dtTquhEcJMek7Bipy/FpLgeQxx9/HDabDRUVFSgtLUVhYSFefPHFXs85evQoLBYLduzYgerqaixcuBBz5syB2czugUTk+67qWQey9XgTukxWiashT/q2Z/Rj8qBYBAcpJK7Gt7kUQNrb27Fq1SosX74cSqUSGo0GS5cuxcqVK3s9b8SIEfjd736HsLAwAMADDzyAjo4OHDt2zH2VExFJZGhiBFKiQmC02LDtOLuiBhLH+o8ZuVz/0V8uBZDi4mJkZWVBq9U67ysoKEBJSQms1vN/Cujs7ERnZyc0Gs2lV0pE5CVkMhmuckzDHOE0TKDQdZlR3LP91tGUji6dSwGkrq4OCQkJve6Lj4+HxWKBTqc779c99dRTmD59OlJSUs75uNFohF6v73UjIvJmV/1gO67Nxq6ogWDrsSZYbQI58eFI03L7bX+5FEAsFstZC04dIx8ymeys53d0dOCee+7Bd999hzfffPO8r/vss89Co9E4b2lpaa6URUTkcROztQhTKdBgMKKk9vwfwMh/cPrFvVwKIFqtFk1Nvec7GxsbERwcfNb0SkVFBcaPH4+goCBs3boVcXHn/xe2dOlS6HQ65626utqVsoiIPE6tVDjbcG/gdly/Z7MJbHIGEE6/uINLASQvLw/l5eVobW113ldUVISCggLI5d+/VFtbG6688ko89thjePXVVxEaeuGhKrVajcjIyF43IiJvdyW34waMklodmtpNCFcrkZ+pvfgX0EW5FEASExMxe/ZsPPnkk7BYLGhqasKyZcuwePHiXs/74IMPMHToUNx///3urJWIyKtc2dMVtbRWjzpdl9Tl0AAqPGI//fbynFiolOzh6Q4uX8UVK1agtrYWSUlJyM/Px6JFizBv3jysXr0ajz76KADg2LFj2L59OzIzM3vdXnnlFbf/AEREUokNV2NsWhQAdkX1d871H0O5/sNdZOLHq0q9gF6vh0ajgU6n43QMEXm1lwqP409fl2NGbhxe+9kEqcuhAdDcbkT+sg0QAtj55FVIiAyWuiSv5cr7N8eRiIj6wdEPZFtFMzpNFomroYGwqbwRQgDDkiIZPtyIAYSIqB9yE+xdUU0WG7YeY1dUf7T+sH2R8axh3P3iTgwgRET9IJPJMGu4vSnZN4e5G8bfdJut2HzMvgB11vBEiavxLwwgRET9dM0I+xvTxrJ6WKw2iashd9pe0YxOkxWJkcEYmcI1ie7EAEJE1E/jM6MRHRqE1k4zdle2XvwLyGc4RrVmDo8/Z8dvunQMIERE/aRUyJ1nw3xdekbiashdbDaBDT1N5jj94n4MIEREbnB1zzqQ9Yfrzzozi3zTgdNtaDQYEa5WYmI2u5+6GwMIEZEbXDEkDiFBCtS0daG0lid6+wPH7pdpuXFQKxUSV+N/GECIiNwgOEiBaUPsXTI5DeMfvt9+myBxJf6JAYSIyE2uHtGzHbeU23F9XWVTB441tEMhl/H02wHCAEJE5CZXDU2AUi5Deb0BlU0dUpdD/eBYfFqQpYUmNEjiavwTAwgRkZtoQoMwMTsGAKdhfJ1j+62jyRy5HwMIEZEbOadh2BXVZ7V0mLCnsgUAMJPrPwYMAwgRkRs5PjHvPdWKBkO3xNXQpdhYVg+bAIYmRiBNGyp1OX6LAYSIyI2SNCEYk6qBEN/voiDf8lWJffrM0WKfBgYDCBGRm13d88bF3TC+x9BtxpaeU42vG5UkcTX+jQGEiMjNHJ+ciyqaoO82S1wNueLbIw0wWW3IjgvDkIRwqcvxawwgRERulhMfjuy4MJitAoVHGqQuh1zw5SH79Mt1I5N4+NwAYwAhIhoA1460j4J8cahO4kqorzqMFhSW2wPj7JFc/zHQGECIiAaAY/3ApvJGdBgtEldDfbGpvBFGiw3p2lCMSI6Uuhy/xwBCRDQAhidFIiMmFEaLDd9yGsYnfFliH626dlQip188gAGEiGgAyGQy5yiI442NvFe32eoMiteO5O4XT2AAISIaINf1vJEVHmlEp4nTMN5s89FGdJqsSNYEY0yqRupyAgIDCBHRABmZEok0bQi6zFZsKm+Uuhy6gC97mo9dO4q7XzyFAYSIaIDIZDLnKAh3w3gvo8WKDT1da68bxd0vnsIAQkQ0gBzrQL490oBus1Xiauhcio43w2C0ICFSjcvSoqUuJ2AwgBARDaDRqRqkRIWg08RpGG/12cFaAMDsEYmQyzn94ikMIEREA0gmkzmbknE3jPfpNludZ/bMGZMscTWBhQGEiGiAXTfaPg2zsYzTMN5mU3kD2o0WpESFIC+d0y+exABCRDTAxqZGIUkTjHajxXnSKnmHzw7YR6VuGJ3E6RcPYwAhIhpgcrnM2dyKu2G8R7vRgg1lnH6RCgMIEZEHOLZ3bjhcD6OF0zDewP7vwobs2DCe/SIBBhAiIg/IS49GQqQaBqMFW45yGsYbrD1g3/1yw5hkNh+TAAMIEZEHyOXfnw3j2PZJ0mnrNGHzUfu26LljePaLFBhAiIg8ZG7POoP1h+vRZeI0jJS+KjkDi01gWFIkcuIjpC4nIDGAEBF5yNi0KKRp7U3JNh6pl7qcgOaYfpnLxaeSYQAhIvIQmUyGOaPtb3hr93MaRioN+m5sP9EMwL79lqTBAEJE5EGO7Z6byhuh7zZLXE1gWneoDkIAeelRSNOGSl1OwGIAISLyoKGJERgcHw6T1Yave46AJ8/6eF8NAE6/SI0BhIjIg2QymXMU5LODbErmaccbDDh4WgelXMbmYxJjACEi8jDHG9+2401objdKXE1gWbPXPvoxPTcOMeFqiasJbAwgREQelhUbhlEpGlhtAl9wGsZjbDaBT3sW/950WarE1RADCBGRBBzrDz7jbhiP2XmyBTVtXYgIVuKqYfFSlxPwGECIiCRwfc/2z12VLajTdUlcTWBYs/c0APvW2+AghcTVEAMIEZEEkqNCMCFTCwD4/AAXow60LpMVX/ZMd3H6xTswgBARSWTOGJ4N4ynry+rRbrQgTRuC/IxoqcshMIAQEUnm2lFJUMhlOHhah5NNHVKX49cc0y83jU2BXM6Tb70BAwgRkURiw9WYkhML4PvmWOR+DYZubDnWBAC4KY/TL96CAYSISELzL0sBAHyyrwZCCImr8U9r99fCahO4LD0KWbFhUpdDPRhAiIgkdPWIBISqFDjV0oniqlapy/FLjtElR9gj78AAQkQkoVCVErNHJgIA1nAaxu0O1+pRWqtHkEKGG0az9bo3YQAhIpLY/J5toesO1sFosUpcjX95f081AGDW8AREh6kkroZ+iAGEiEhikwbFICFSDV2XGYVHGqQux28YLVZ8st8+qnRrfprE1dCPMYAQEUlMIZdh3lj7+gTHYWnUf+sP16Ot04wkTTCmDo6Tuhz6EQYQIiIvcFOePYAUljegtcMkcTX+4b3d9umXW8alQsHeH16HAYSIyAsMTYzE8KRImK0Cnx9ia/b+qmnrwtbj9t4fC8Zx+sUbMYAQEXmJ+T2jIB/3dO2kS/fhntMQApiUHYP0mFCpy6FzYAAhIvISc8ckQy4D9p5qQyVbs18ym03gg2L79Mtt4zn64a0YQIiIvER8ZDAu71ksydbsl277iWacbu1CRPD3PVbI+zCAEBF5EUe3zo/2nobNxtbsl8Kx+PTGsckIDlJIXA2dDwMIEZEXmT0yERHBSpxu7UJRRbPU5fictk4Tvio9AwC4LT9d4mroQhhAiIi8SHCQAjeOtbcMf6+niyf13YfFp2Gy2DA8KRIjUyKlLocugAGEiMjL/GS8/ZP716Vn0NbJniB9ZbMJvLXzFABg4cQMyGTs/eHNGECIiLzMyBQNhidFwmSx4RMuRu2zoopmnGzqQLha6RxFIu/FAEJE5IUc20ff3V0NIbgYtS9W76gCYO+nEqZWSlwNXQwDCBGRF5o3NgUqpRxHzhhwqEYndTle74yuG+vL6gHYp1/I+7kcQLq6urBo0SJkZGQgNTUVS5YsOWc637dvHyZOnIiMjAwMHz4c69evd0vBRESBQBMahGt7elg4tpXS+b27+xSsNoEJmVoMSYiQuhzqA5cDyOOPPw6bzYaKigqUlpaisLAQL774Yq/nGAwGzJkzB3/4wx9QVVWFl19+GQsWLMCZM2fcVjgRkb+7recI+bX7a9FlskpcjfeyWG14d5c9pN05kVtvfYVLAaS9vR2rVq3C8uXLoVQqodFosHTpUqxcubLX89555x2MHz8eM2fOBABMmzYNV1xxBd577z33VU5E5OcmZscgTRsCg9GCzw/WSl2O19pQ1oAz+m7EhKnY+dSHuBRAiouLkZWVBa1W67yvoKAAJSUlsFq/T+fbt2/HlClTen1tQUEB9u/f379qiYgCiFwuw+0T7J/o3+xZYElne3NHJQBgQX4a1Ep2PvUVLgWQuro6JCQk9LovPj4eFosFOp3uos9rbj53Vz+j0Qi9Xt/rRkRE9mkYlUKOg6d12F/dJnU5XqesTo9tx5shlwELOf3iU1wKIBaL5awFp46Rjx82fDnf887XFObZZ5+FRqNx3tLSeHohEREAxISrccPoJADAG9srpS3GC63cehIAcO3IJKRGh0pcDbnCpQCi1WrR1NTU677GxkYEBwdDo9Fc9HmJieeem1u6dCl0Op3zVl3NFd9ERA53TbJvK/38QB2a240SV+M9Gg1GfLrfvjbm3suzJK6GXOVSAMnLy0N5eTlaW1ud9xUVFaGgoABy+fcvNW7cOBQVFfX62qKiIkyaNOmcr6tWqxEZGdnrRkREdmPTojAqRQOT1cbzYX5g9Y4qmKw2jE2LwriMaKnLIRe5FEASExMxe/ZsPPnkk7BYLGhqasKyZcuwePHiXs+78847sXHjRnz77bcAgC+++AJlZWVYsGCB2wonIgoUMpnMOQry1o5TsFhtElckvW6z1dn59D6Ofvgkl/uArFixArW1tUhKSkJ+fj4WLVqEefPmYfXq1Xj00UcBAKmpqXj33Xfx8MMPIz4+Hn/4wx/w2WefISwszO0/ABFRIJg7JhnRoUGoaevClyXsqfTJvho0d5iQrAl2Nmwj3yITXnjIgF6vh0ajgU6n43QMEVGPv64/ihc2HsOoFA3W/mJKwJ72arHacNXz36GquRNPXz8MP5+aLXVJ1MOV92+eBUNE5CPunpSB4CA5DtXosL3i3G0NAsG6Q3Woau5EdGgQ7ijg1ltfxQBCROQjYsLVuLWnPfu/Np+QuBpp2GwCL357HIB97Ueoiqfe+ioGECIiH/Lzy7MhlwGbjzbicG3gNW385nA9jjW0I0KtxF2TMqUuh/qBAYSIyIekx4Ti2lH2xmT/+q5C4mo8SwiBlwrtox93T86AJiRI4oqoPxhAiIh8zEPTBgEAPjtYi2P1Bomr8ZxvDtfjUI0OIUEK3DuFW299HQMIEZGPGZmiwTUjEiAE8NcNR6UuxyMsVhuWf3UEAHDv5ZmICVdLXBH1FwMIEZEPemzWEMhkwBeHzqCkRnfxL/BxH+09jYrGDkSFBuGBnhEg8m0MIEREPmhoYiTmjE4GADy/3r9HQbrNVvx1/TEAwC9m5CAymGs//AEDCBGRj3ps1hAo5DJ8e6QB2443XfwLfNS/vzuBM/pupESFYOHEDKnLITdhACEi8lFZsWG4q+cN+bdrS2H2wzNiqpo78NIm+86X/752KIKDFBJXRO7CAEJE5MMemzkE2jAVjjW0483tVVKX41ZCCPx2bSlMFhsuz4nFnNFJUpdEbsQAQkTkwzShQfj1NbkA7DtiGg1GiStyn69L61FY3ogghQzP3DgiYM++8VcMIEREPu7W/DSMStHA0G3BUx8fgheeMeqy5nYjnv7kEABg0RXZGBQXLnFF5G4MIEREPk4hl2H5LaMRpJDhm8P1+HhfjdQl9YsQAkvXHEJTuwlDEsLxyysHS10SDQAGECIiPzAsKRKLZw4BAPxmbSlONXdKXNGle2vnKXxzuB5BChn+ettYLjz1UwwgRER+4oErspGXHgVDtwUPrC5Gl8kqdUku21PZgmc+KwUAPHF1LkYkaySuiAYKAwgRkZ9QKuR46c48xIarUFanx/+sOQibzXfWg5xu7cRDb+2F2Spw/agkLLoiW+qSaAAxgBAR+ZEkTQj+cXseFHIZPt1fiz+sK/OJRakNhm4sfHUnGg1G5CZEYPkto7nrxc8xgBAR+ZlJg2Lw5wWjAQArt53En74u9+oQUqfrwsJXd6KyuRNp2hCsuncCwtRKqcuiAcYAQkTkh266LBW/mTMcAPDPTRVY8uFBr+yUWlanx00vFeFofTsSItV4676JSNQES10WeQADCBGRn/rZlCw8O38U5DLgg+LTuOVf21HV3CF1WQDsW23f3F6JeS9twxl9N3Liw/HRQ5ORHhMqdWnkIQwgRER+7PYJ6Xj1nnxEBitxoLoN172wBS8VHke3WbodMiU1Otz+yg7876elMFpsuGJIHD56cDJSoxk+AolMeOHEoF6vh0ajgU6nQ2RkpNTlEBH5vJq2Ljz27n7sqmwBACRGBuOuSRm4NT8NcRHqAf/+ZqsN24434Y3tVSgsb4AQgEopx3/PHoqfTc6EXM4Fp/7AlfdvBhAiogBhswl8eqAGy78qR52uGwAgkwF56dGYPiQOo9OiMCI5EjFhqn7tQBFCQN9lwYmmdhyq0WFPZSs2lTdA321xPmfumGQsmZ3LUQ8/wwBCRETnZbRY8fmBOryxowoHqtvOejwkSIGkqGDEhqsRrlYiVKVAmEoJheL7UCIDIAB0m63oMlnRabKi02RBa6cZdW1d6DhHE7TYcBVuGJ2MeyZnIis2bOB+QJIMAwgREfVJbVsXNpbVY1dlK0pqdDjZ5L5FqrHhKoxM0WB0igbTcuMwNi0aCk61+DUGECIiuiTdZivq9d2oaetCa4cZHUYLOkwWdBgtcDRV/eG7RnCQHKEqBUJU9pGSyOAgJEcFI0kTghAVz3AJNK68f7PTCxEROQUHKZARE4aMGE6R0MDiNlwiIiLyOAYQIiIi8jgGECIiIvI4BhAiIiLyOAYQIiIi8jgGECIiIvI4BhAiIiLyOAYQIiIi8jgGECIiIvI4BhAiIiLyOAYQIiIi8jgGECIiIvI4BhAiIiLyOK88DVf0nPWs1+slroSIiIj6yvG+7XgfvxCvDCAGgwEAkJaWJnElRERE5CqDwQCNRnPB58hEX2KKh9lsNtTW1iIiIgIymcytr63X65GWlobq6mpERka69bXpe7zOnsHr7Bm8zp7B6+w5A3WthRAwGAxITk6GXH7hVR5eOQIil8uRmpo6oN8jMjKSv+AewOvsGbzOnsHr7Bm8zp4zENf6YiMfDlyESkRERB7HAEJEREQeF3ABRK1W4ze/+Q3UarXUpfg1XmfP4HX2DF5nz+B19hxvuNZeuQiViIiI/FvAjYAQERGR9BhAiIiIyOMYQIiIiMjjAiaAdHV1YdGiRcjIyEBqaiqWLFnSp1axdLZvv/0WU6ZMQU5ODgYNGoR//OMfzscqKysxa9YsZGRkICcnB6tXr+71te+88w6GDRuG1NRUzJgxAydPnvR0+T7poYcewtChQ53/vG/fPkycOBEZGRkYPnw41q9f3+v5f/vb35CTk4OUlBTcdNNNaG5u9nTJPmfXrl244oorkJGRgeTkZKxZswYAr7U71dTUYM6cOUhJSUF2djZ+//vfOx/jde4fIQTeeOMNTJo0qdf9/bmuzc3NWLBgAdLT05GRkYG//OUvbi86IDz00EPivvvuE2azWbS1tYn8/Hzx97//XeqyfNKvfvUrceTIESGEEBUVFSIlJUV8+eWXwmKxiJEjR4rXXntNCCFEaWmpiI6OFvv27RNCCFFUVCQyMzNFVVWVEEKIZcuWiXHjxknxI/iUU6dOidDQUJGbmyuEEEKv14uUlBSxfv16IYQQmzZtEhqNRtTV1QkhhHjvvffEZZddJpqbm4XFYhEPPvigmD9/vmT1+4KysjKRlJTkvKZGo1HU19fzWrvZlVdeKZYsWSJsNptobm4WY8aMEa+99hqvcz99+eWXYuTIkWLQoEHOvxNC9P9vxbXXXit++9vfCpvNJmpqakRGRoZYu3at2+oOiABiMBhEaGioaG5udt730UcfibFjx0pYlf947LHHxK9//Wvx9ddfn3VNf/nLX4rFixcLIYS4/fbbxd/+9jfnY2azWWi1WrF//36P1utrbr75ZvHII484/7D8+9//FvPmzev1nDlz5jiv7aRJk8Qnn3zifKyxsVEolcpev//U2/z588Uf//jHs+7ntXav6OhocejQIec/P/XUU+KRRx7hde6nDz/8UKxbt04UFhb2CiD9ua7l5eUiLi5OmM1m5+N/+ctfznq9/giIKZji4mJkZWVBq9U67ysoKEBJSQmsVquElfmHxsZGaDQabN++HVOmTOn1WEFBAfbv3w8AZz2uVCqRl5fnfJzOtm7dOjQ3N+OWW25x3neh62yxWLBnz55ej8fGxiIzMxOHDh3yWN2+pLu7G59//jl+9rOfnfUYr7V73XLLLXjxxRdhMplQVVWFTz/9FLfccguvcz/dfPPNuO666866vz/Xdfv27ZgwYQKUSuVZX+suARFA6urqkJCQ0Ou++Ph4WCwW6HQ6iaryD7t27cLnn3+OO+6447zX2TGneLHHqbfm5mb86le/wssvv9zr/gtdx6amJlitVsTGxp7zcTrb0aNHERISgsLCQowePRrZ2dl44IEHoNfrea3dbNmyZfjqq68QHR2NrKwszJgxA9OnT+d1HiD9ua6e+HsdEAHEYrGcteDUMfLh7tN2A8m7776LuXPnYtWqVcjKyjrvdXZc44s9Tt8TQuC+++7D4sWLey0+BS58HS0Wi/Prz/U4nc1gMDg/De7atQsHDhxAY2MjHn30UV5rN7JarbjuuuuwePFi6HQ61NTU4MCBA3jhhRd4nQdIf66rJ/5eB0QA0Wq1aGpq6nVfY2MjgoOD+3xqH33ParXi4YcfxjPPPIOvv/4ac+fOBXD+65yYmNinx+l7zz33HMxmM37xi1+c9diFrmN0dDSEEGhtbT3n43S22NhYmM1mPPfccwgODkZERAR++9vfYu3atbzWbvTtt9/CZDJh8eLFUCqVSEpKwvPPP4/ly5fzOg+Q/lxXT/y9DogAkpeXh/Ly8l4XuqioCAUFBZDLA+ISuNXixYtx4sQJ7NmzB2PGjHHeP27cOBQVFfV6blFRkXNb2I8fN5lMKC4uxsSJEz1TuA/5+9//ji1btiA6OhpRUVG44YYbcOzYMURFRV3wOoeFhSE3N7fX43V1daivr+/174q+l5GRAZVKhe7ubud9crkcwcHBvNZuZDKZeq0nAICgoCCYTCZe5wHSn+s6btw47Ny5Ezab7ayvdRu3LWf1cnPnzhUPPvigMJvNorGxUYwaNUp8/PHHUpflc7q6uoRCoRC1tbVnPdbR0SGSkpLEm2++KYQQYvfu3SIpKUlUV1cLIYRYs2aNyMzMFNXV1cJisYinn37arSuq/dkPV7dXV1eLqKgosXHjRiGEEOvWrRMZGRmivb1dCCHE888/L/Lz80Vra6swGo3innvuce5EonN7+OGHxf333y/MZrPo7u4W8+fPF0uWLOG1dqO2tjaRnJws3n77bSGEfXfiDTfcIB588EFeZzf58S6Y/lxXm80mxowZI/74xz8Kq9UqKioqRHp6utizZ4/b6g2YANLY2Cjmzp0rYmNjRUZGhvjHP/4hdUk+qbS0VMhkMpGRkdHrdvXVVwshhNizZ4+47LLLRFxcnBg1apQoLCzs9fXLly8XSUlJIiEhQdx2222ipaVFgp/C9/z4D8tXX30lcnNzRVxcnJg0aZI4ePCg8zGr1Soef/xxERcXJ5KSksSDDz4ouru7pSjbZxgMBrFw4UIRHx8vBg0aJJYsWSKMRqMQgtfanQ4dOiRmzZolMjIyRFZWlli8eLHo6OgQQvA6u8OP/04I0b/rWlFRIaZNmyZiY2PF4MGDxfvvv+/WenkaLhEREXkcF0AQERGRxzGAEBERkccxgBAREZHHMYAQERGRxzGAEBERkccxgBAREZHHMYAQERGRxzGAEBERkccxgBAREZHHMYAQERGRxzGAEBERkccxgBAREZHH/X8bh70ANLRjfQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b20ee4e910>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABREAAAKSCAYAAABFgZznAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAADR8ElEQVR4nOzdZ3hcV7n28f/MqPfeu2VZ7nbc4tixHdvpcXohlBASOEAOEAiBl3A4tNACBw4BDp00EpKQAulOd5zEjnsvstV7l0a9zMx+P2xVS3KVNBrp/l3XvmZm76WZR05U5tZa67EYhmEgIiIiIiIiIiIiMgKruwsQERERERERERGRiU0hooiIiIiIiIiIiJyUQkQRERERERERERE5KYWIIiIiIiIiIiIiclIKEUVEREREREREROSkFCKKiIiIiIiIiIjISSlEFBERERERERERkZPycncBZ8vlclFeXk5wcDAWi8Xd5YiIiIiIiIiIiHgUwzBobm4mISEBq/Xkcw09NkQsLy8nOTnZ3WWIiIiIiIiIiIh4tJKSEpKSkk46xmNDxODgYMD8JENCQtxcjYiIiIiIiIiIiGdpamoiOTm5L2c7GY8NEXuXMIeEhChEFBEREREREREROUuns1WgGquIiIiIiIiIiIjISSlEFBERERERERERkZNSiCgiIiIiIiIiIiIn5bF7Ip4up9NJd3e3u8vweN7e3thsNneXISIiIiIiIiIibjBpQ0TDMKisrKSxsdHdpUwaYWFhxMXFndZmmyIiIiIiIiIiMnlM2hCxN0CMiYkhICBAwdc5MAyDtrY2qqurAYiPj3dzRSIiIiIiIiIiMp4mZYjodDr7AsTIyEh3lzMp+Pv7A1BdXU1MTIyWNouIiIiIiIiITCGTsrFK7x6IAQEBbq5kcun999QekyIiIiIiIiIiU8ukDBF7aQnz6NK/p4iIiIiIiIjI1DSpQ0QRERERERERERE5dwoRJ6nbb7+dn/3sZ+4uQ0REREREREREJgGFiCIiIiIiIiIiInJSChEnMJfL5e4SREREREREREREpk6IaBgGbV0OtxyGYZx2nWlpafz5z39m4cKFrFu3js2bN7N06VLS0tJYtmwZO3fu7Bv75JNPMn/+fFJSUpg2bRqPP/74WPzTiYiIiIiIiIjIFOfl7gLGS3u3k1nffd0tr334h5cS4HP6/9TPPfccmzdvpqSkhDVr1vDaa6+xaNEi3njjDa699lqOHTtGQEAAABs3biQ+Pp6dO3eyatUqNmzYQGho6Fh9KiIiIiIiIiIiMgVNmZmInuT2228nODiY3//+93zxi19k0aJFAFxyySXExcWxbds2AG699VaioqI4fPgwFRUVeHl5kZeX587SRURERERERERkEpoyMxH9vW0c/uGlbnvtM5GamgpAfn4+Tz/9NI8++mjftdbWVqqrqwG455572LhxI/PmzSMtLQ0vLy+6urpGr3ARERERERERERGmUIhosVjOaEmxO1mt5gTRhIQE/uu//ouvfvWrQ8a88847vPrqqxw8eBAvLy8Mw+APf/jDOFcqIiIiIiIiIiJTgZYzT2C33XYbDz74IDk5OQB0d3fzwgsvANDZ2UlnZydtbW0YhsFPfvIT2tvb3VmuiIiIiIiIiIhMUgoRJ7BVq1bxox/9iOuvv57U1FTmzp3L3r17Abj00ku5+OKLycrKYsaMGYSFhZGQkODegkVEREREREREZFKyGIZhuLuIs9HU1ERoaCh2u52QkJBB1zo6OigoKCA9PR0/Pz83VTj56N9VRERERERERGTyOFm+diLNRBQREREREREREZGTUogoIiIiIiIiIiIiJ6UQUURERERERERERE5KIaKIiIiIiIiIiMgJjlc1881n9/GPbcXuLmVC8HJ3ASIiIiIiIiIiIhNFW5eD372Ty+835QFwsKyJjy9LcXNV7qcQUUREREREREREpjzDMHj9UCU/fOkw5faOvvPnZ0S6saqJQyGiiIiIiIiIiIhMafk1LXz/pcNsPlYz6Ly/t4271013U1UTi0JEERERERERERGZklo6Hfz2neM89EEB3U4DH5uV/1iVwZ6SBj7MrePGRUmEBni7u8wJQSGiiIiIiIiIiIhMKYZh8O+9Zfz01aNUN3cCsDormu9tmIXFYuH/NuUC8JkVaW6scmJRiDjJVFZWEh8fj2EYANxzzz2sWrWKa6+91r2FiYiIiIiIiIhMAAfL7HzvxUPsKmoAIDUygO9eNYu12TFYLBa+98JBDAPWZseQER3k5monDoWIk9yvfvWr0xr38MMPc+jQIf7nf/5njCsSERERERERERl/dS2d/M8bx3hqRzGGYe53+KW1mXz2wnR8vWwA2Nu7eWZXKQB3rkx3Z7kTjkJED+VyubBaraP2fEVFRbS0tIza84mIiIiIiIiITAQOp4vHPyriV28eo6nDAcA1CxL41uXZxIf6Dxr79I5i2rqcZMcFc8E0dWUeaPRSqInOMKCr1T1Hz9Li05GWlsZzzz3HJZdcQkpKCtnZ2Tz99NMA3H777Xz729/msssuIy4ujpaWFvLz87niiitISUlh+vTpPPXUU4Oeb82aNYPObd68mQsvvJD09HQSExN5/vnn+eQnP8mvf/1rnnjiCdLS0vpeT0RERERERETEk23Jq+XK33zA9186TFOHg5nxIfzz88t58GMLhwSIDqeLR7cUAXDHinQsFos7Sp6wps5MxO42+EmCe1772+XgE3jaw3/+85/z5JNPkpGRwY4dO1i/fj3Z2dkAPPnkk2zcuJGsrCy6urq4+OKL+cY3vsErr7xCW1sbn/zkJ0d83u3bt3PzzTfz7LPPsnLlStra2qiqquL666/n+9//PpWVlfzxj388509XRERERERERMSdyhrb+ckrR3jlQAUAYQHe3HvJDG5dmoLNOnw4+PqhKsoa24kM9OHqBW7KkCawqRMiepCvfvWrZGRkALBkyRJuvfVWnn/+eQAuueQSZsyYAcArr7xCVFQUX/jCFwAIDAzkJz/5Cf/+97+Hfd4HHniAb33rW6xcuRKAgIAA0tO1vl9EREREREREJof2Lid/2pzHH9/Lo6PbhdUCn1iWytcvySIswOekH/u3D/IB+MT5qfh528ajXI8ydUJE7wBzRqC7XvsMnBjsxcTEUFdXB0Bqamrf+by8PGbOnDlobHh4+IjPm5OTw3/+53+eUS0iIiIiIiIiIhOdy2Xwwr4yHngth8qmDgCWpkfw/Q2zmZUQcsqP31PcwO7iRnxsVj55fspYl+uRpk6IaLGc0ZJid+oNDHsdPnyYFStWsG/fvkHNVKKioiguLh40Nj8/f8TnjY+PJy8vj7Vr145uwSIiIiIiIiIibrKzsJ77Xz7MvlI7AIlh/nzr8myumhd/2vsaPvRhIQAb5icQE+w3VqV6tKnTWMWD/PjHP6ampgYwlyxv2rSJT33qU0PGXX755ezcuZNnnnkGgNraWu6///4Rn/cLX/gCP/rRjzhw4AAAzc3NHDt2DICIiIi+ANLhcIzq5yMiIiIiIiIiMtpK6tv4z3/s5sY/bmVfqZ1AHxvfuHQGb399NRvmJ5x2gFjW2M6rPXsn3rEybQwr9mwKESegG2+8kXXr1pGcnMzPfvYz3njjDaKiooaMi4uL44UXXuAnP/kJCQkJXHHFFXzlK18Z8XlvuOEG7r//fj7+8Y+TkpLC+eefT0lJCQC33HIL9fX1pKWl8eKLL47Z5yYiIiIiIiIici6aO7p5YONR1v3qPV7ZX4HFAh9bksy731jDf16Uecb7GT70QQFOl8HyjEhmJ4SOUdWez2IYhuHuIs5GU1MToaGh2O12QkIGr23v6OigoKCA9PR0/Pw8awpqWloaTz31FOeff767SxnCk/9dRURERERERMSzOV0G/9xZwi/fyKG2pQuAC6ZF8p0rZ53WvofDsbd3c8FP36a1y8kjn1nCmhkxo1nyhHeyfO1EU2dPRBERERERERER8Uhbcmv54cuHOVrZDEB6VCDfvmIm62fGnPay5eE8sa2I1i4n2XHBrM6KHq1yJyWFiCIiIiIiIiIiMiHl17Twk1eP8taRKgBC/Lz4yrrp3LY8DR+vc9ulr9Ph5OGehiqfuzDjnMLIqUAh4gRTWFjo7hJERERERERERNyqrqWT376Ty+MfFeFwGdisFj65LIWvrs8iPNBnVF7j33vKqGnuJC7Ejw3zE0blOSczhYgiIiIiIiIiIjIhtHc5eejDAv6wKY+WTgcAF82I5r+unElmTPCovY7LZfDnzfmA2ZH5XGc1TgWTOkT00J4xE5b+PUVERERERERkLDhdBs/tLuVXbxyjsqkDgDmJIdx3+UxWZEaN+uu9c7SavJpWgn29uHVpyqg//2Q0KUNEb29vANra2vD393dzNZNHW1sb0P/vKyIiIiIiIiJyLgzDYNOxGn726lFyqsymKYlh/nzzshlsmJeA1To2+xT2zkL8+LIUgv2Uc5yOSRki2mw2wsLCqK6uBiAgIECbY54DwzBoa2ujurqasLAwbDabu0sSEREREREREQ93oNTOT187wpa8OgBC/b358tpMPnl+Kn7eY5c97C5uYHthPd42C59ZkT5mrzPZTMoQESAuLg6gL0iUcxcWFtb37yoiIiIiIiIicjZK6tv4nzdyeGFvOQA+XlY+c0Ead63JJDRg7GcF/vk9cxbi1fMTiQv1G/PXmywmbYhosViIj48nJiaG7u5ud5fj8by9vTUDUURERERERETOWmNbF//3bi6Pbimiy+kC4LqFiXz9kiySwgPGpYaC2lZeP1wJwH+syhiX15wsJm2I2Mtmsyn8EhERERERERFxk/YuJw9vKeCPm/Jo6jA7Lq/IjOS+y2cyJzF0XGv5y/v5GIbZ8XlG3Oh1e54KJn2IKCIiIiIiIiIi46/L4eLpHcX85p1capo7AciOC+a+K2ayanrUuPevqGrq4NmdpQB8fvW0cX3tyUAhooiIiIiIiIiIjBqXy+DFfeX86s1jFNe3AZAc4c/XL57BhvkJ2Mao4/Kp/PX9fLqcLhanhrMsPcItNXgyhYgiIiIiIiIiInLODMPgnaPV/OL1HI5WNgMQFeTL3esyuWVJCj5eVrfV1tDaxRPbigH4z4syx30W5GSgEFFERERERERERM7Jtvw6fv56DruKGgAI9vPiC6un8ZkVaQT4uD9+enRrIW1dTmbGh7BmRrS7y/FI7v+vKCIiIiIiIiIiHulQuZ1fvJ7DppwaAPy8rdx+QTpfWJ1BWICPm6sztXQ6ePjDQgD+86JpmoV4lhQiioiIiIiIiIjIGSmobeWXb+Tw8v4KALysFm5ZksxX1k0nNsTPzdUN9uS2Yuzt3aRHBXL5nHh3l+OxFCKKiIiIiIiIiMhpKW1o47dv5/Ls7lKcLgOAaxYk8LX1WaRFBbq5uqE6up385f18AL64eprbmrpMBgoRRURERERERETkpCrs7fzunVz+ubOEbqcZHl40I5pvXJrNrIQQN1c3sud2l1Ld3El8qB/XLkx0dzkeTSGiiIiIiIiIiIgMq7qpg99vyuMf24vpcrgAWJkZxdcuzmJRaribqzs5h9PFH9/LA+BzF2a4tTv0ZKAQUUREREREREREBqlr6eSP7+Xx94+K6Og2w8Ol6RHcc3EW52dEurm60/PKgQpK6tuJCPThY0uT3V2Ox1OIKCIiIiIiIiIiADS0dvHn9/N5dEshbV1OAM5LCePrl8zggmmRHtPZ2OUy+P275izEO1akEeCjCOxc6V9QRERERERERGSKs7d387cPCnjogwJaOh0AzEsK5WsXZ7EmK9pjwsNebxyuJKeqmWBfLz61PM3d5UwKChFFRERERERERKao5o5uHvmwkL+8n09ThxkezowP4Z6Ls1g/M8bjwkMwZyE++HYuALevSCPU39vNFU0OChFFRERERERERKYYe3s3j24p5G8fFGBv7wZgekwQX7s4i8tmx2G1el542OvNI1UcqWgi0MfGnSvT3V3OpKEQUURERERERERkimhs6+KhDwt5+MMCmntmHmZEB3L3uulcNS8BmweHhwCGYfCbt48D8OkL0ggL8HFzRZOHQkQRERERERERkUmuvrWLv76fz2Nbi/r2PMyKDeJLa6dz5dx4jw8Pe719pJpD5U0E+Nj47IUZ7i5nUlGIKCIiIiIiIiIySdU0d/LX9/P5+0dFfd2Ws+OCuXvddC718GXLJzIMgwd7ZiHetjyNiEDNQhxNChFFRERERERERCaZ6qYO/rQ5nye2FdHR7QJgTmIIX1k7nfUzYydVeNhrU04NB8rs+Hvb+NyF2gtxtClEFBERERERERGZJCrs7fzpvXz+sb2YLocZHs5PDuPudZlcNMMzuy2fDsMw+HXPLMRPLU8lMsjXzRVNPgoRRUREREREREQ8XGlDG398L49/7iily2mGh4tSw7l73XQunB41acPDXu8dq2FfSSN+3lY+p70Qx4RCRBERERERERERD5Vb3cwfNuXzwt4yHC4DgGXpEdy9bjrLp0VO+vAQBu+F+IllqUQHaxbiWFCIKCIiIiIiIiLiYfaXNvL7d/N4/XAlhpkdsiIzki+vnc75GZHuLW6cfZBby57iRny9rHx+tWYhjhWFiCIiIiIiIiIiHsAwDLbm1/GHTXm8f7y27/wls2K566JMFiSHua84NzEMg1+9eQyAW5emEBPs5+aKJi+FiCIiIiIiIiIiE5jLZfDWkSp+vymPvSWNANisFq6Zn8AX1kwjKzbYvQW60bs51ewpNvdCvGvNNHeXM6kpRBQRERERERERmYAcThcv7S/nD5vyOFbVAoCPl5VbFifzH6sySI4IcHOF7uVyGfzyDXMW4qeXpxETolmIY0khooiIiIiIiIjIBNLR7eSZXaX8eXMeJfXtAAT5evGp5ancsSJdjUN6vH6okkPlTQT5evGF1ZqFONYUIoqIiIiIiIiITAD2tm4e31bEwx8WUtvSCUBkoA93rEznk+enEurv7eYKJw6nq38vxDtWphMe6OPmiiY/hYgiIiIiIiIiIm5U2tDGQx8U8tSOYtq6nAAkhPrxH6syuGVJCv4+NjdXOPG8uK+M49UthPp7c+fKdHeXMyUoRBQRERERERERcYODZXb+vDmfVw5U4HQZAGTHBfO5CzPYMD8BHy+rmyucmLqdLn791nEA/mNVhmZojhOFiCIiIiIiIiIi48QwDDYfr+XPm/P4MLeu7/yKzEg+d2EGq7OisVgsbqxw4ntuVylFdW1EBvpw+wVp7i5nylCIKCIiIiIiIiIyxrocLl7aV85f3s/naGUzADarhSvnxvMfqzKYkxjq5go9Q6fDyW/eNmchfnHNNAJ9FW2NF/1Li4iIiIiIiIiMkeaObp7cXsxDHxRS2dQBQICPjY8tSeGOlWkkhQe4uULP8tT2EsrtHcSF+PHJ81PdXc6UohBRRERERERERGSUVdo7ePjDAv6xrZjmTgcA0cG+3H5BGp9clkpogPbxO1PtXU5+924uAF9am4mftxrOjCeFiCIiIiIiIiIio2RfSSMPfVjAK/srcPQ0S8mMCeI/LszgmoUJ+Hop+Dpbj20tpKa5k6Rwf25enOzucqYchYgiIiIiIiIiIufA4XTxxuEq/vZBAbuKGvrOL02P4POrMrhoRgxWq5qlnIumjm7+8F4eAHevm67O1W4wZiGiYRj8/e9/5w9/+ANbt24ddsyePXv44he/SEVFBYGBgTz44INcfPHFY1WSiIiIiIiIiMiosbd3888dJTyypZCyxnYAvG0WNsxL4DMr0pmbpGYpo+VP7+XR2NZNZkwQ1y1MdHc5U9KYhIgbN27kG9/4Bu3t7Xh5Df8Szc3NbNiwgUceeYT169fz3nvvcc0113D06FHi4uLGoiwRERERERERkXNWUNvKIx8W8MyuUtq6nABEBPrwiWUpfOr8VGJC/Nxc4eRS1dTB3z4oAOCbl87Ay6ZZiO4wJiFia2srDzzwAAEBAXzhC18YdsyTTz7JkiVLWL9+PQCrV69m1apVPP3009x9991jUZaIiIiIiIiIyFkxDIOteXU89GEBbx+txjC3O2RGbDB3rEzjmgWJavQxRn791nE6ul0sSg3n4lmx7i5nyhqTEPGGG24AYNOmTSOO2bp1KytWrBh0btmyZezdu3fY8Z2dnXR2dvY9bmpqOuc6RUREREREREROpqPbyYv7ynnogwKOVjb3nV+bHcMdK9JZkRmJxaL9DsdKbnUL/9xZAsC3Ls/Wv7Ubua2xSkVFBWvXrh10LiYmhm3btg07/qc//Sk/+MEPxqM0EREREREREZniqps6eGJbMU9sK6K2pQsAf28bNy1O4vYL0siIDnJzhVPD/7yeg9NlsH5mLEvSItxdzpTmthDR4XBg9M797eF0OkdMlO+77z7uueeevsdNTU0kJ6udt4iIiIiIiIiMDsMw2FXUwKNbi3jtQAUOl5lbJIT68ekL0vjYkhRCA7zdXOXUsbu4gY2HKrFa4JuXzXB3OVOe20LEiIgIamtrB52rqakZsamKr68vvr6+41GaiIiIiIiIiEwh7V1OXtxXxqNbijhc0b992qLUcD6zIo3LZsepmcc4MwyDn716FIAbFyWRFRvs5orEbSHiokWL2LJly6DZhVu2bOGWW25xV0kiIiIiIiIiMoUU17Xx948K+efOUuzt3QD4elm5dkEin1qeypzEUDdXOHW9m1PN9sJ6fL2sfHV9lrvLEdwYIn7iE5/gZz/7Ge+88w5r167l1Vdf5ciRI9x0003uKklEREREREREJjmXy2Dz8Roe21rEuzn9XZaTI/y57fw0blqcRFiAj3uLnOKcLoMHXssB4PYVaSSE+bu5IoFxDhEff/xxduzYwYMPPkhSUhJPPfUUd911F/X19WRmZvLSSy8RGBg4niWJiIiIiIiIyBRgb+/m2V2l/H1rIYV1bX3nV2dF8+kLUlmdFYPNqs6/E8G/9pSRU9VMiJ8Xd63OdHc50sNinNjdxEM0NTURGhqK3W4nJCTE3eWIiIiIiIiIyAR0qNzOE9uK+dfuMtq7nQAE+3lx06JkPrU8lfQoTWaaSNq7nKz95SYq7B186/JsvrB6mrtLmtTOJF9z23JmEREREREREZGx0N7l5OX95TyxrZi9JY1952fEBnPbBalcuyCRQF9FIhPRX9/Pp8LeQWKYP7dfkObucmQAfcWIiIiIiIiIyKSQW93ME9uKeW5XKU0dDgC8bRYumR3HJ5elcn5GBBaLlixPVNVNHfzhvTwA/t/l2fh529xckQykEFFEREREREREPFaXw8Xrhyp5YlsRH+XX951PCvfn48tSuGlRMtHBvm6sUE7XL984RluXk4UpYWyYF+/ucuQEChFFRERERERExOMU17Xx5I5i/rmjhLrWLgCsFlg3M5ZPLEth1fRorGqU4jEOlzfxz10lAHznylmaMToBKUQUEREREREREY/gcLp4+2g1T2wr5v3jNfS2io0N8eVjS1K4ZUkyCWH+7i1SzphhGPzolcMYBlw1L55FqeHuLkmGoRBRRERERERERCa0kvo2ntlVyj93lFDZ1NF3flVWNJ9YlsK67Bi8bFY3Vijn4p2j1WzJq8PHy8r/uyzb3eXICBQiioiIiIiIiMiE0+lw8tbhap7aUcwHubV9sw4jA324aXEyty5NJjUy0L1Fyjnrdrr4yatHALhjRTrJEQFurkhGohBRRERERERERCaM41XNPL2jhOf3lFHfs9chwIrMSG5ZksKls2Px9VLX3sniye3F5NW0EhHow10XTXN3OXISChFFRERERERExK1aOx28sr+Cp3YUs7u4se98bIgvNy9O5qZFyaREaobaZGNv7+Z/3zwGwNcuziLEz9vNFcnJKEQUERERERERkXFnGAb7Su08vaOYF/eW09rlBMBmtbAuO4aPLU1m1fRo7XU4if3fu7k0tHWTGRPErUuS3V2OnIJCRBEREREREREZN41tXfxrTxlP7yjhaGVz3/m0yABuWZLCDYsSiQn2c2OFMh4Ka1t55MNCAP7rypkKiz2AQkQRERERERERGVNOl8EHubU8u6uU1w9V0uVwAeDrZeWKufHcsiSZZekRWCwWN1cq4+X+lw/T5XSxKiuaNVnR7i5HToNCRBEREREREREZE7nVLTy3u5Tnd5dS1dTZd35mfAi3Lk3mmvmJhAZoH7yp5t2cat4+Wo2X1cL3NsxSeOwhFCKKiIiIiIiIyKixt3Xz0v5ynt1Vyt6Sxr7zYQHeXLsgkRvOS2JOYoiCoymqy+Hi/pcOA3DHynSmRQe5uSI5XQoRRUREREREROSc9C5XfmZnCW8crupbrmyzWrhoRjQ3LkriouwYfL1sbq5U3O2RLQXk17YSFeTLl9dmurscOQMKEUVERERERETkrIy0XHlGbDA3LU7imgWJRAf7urFCmUiqmzp48K3jAHzr8myC/bSU3ZMoRBQRERERERGR03aq5co3LkpidoKWK8tQD2zMobXLyYLkMK5fmOjucuQMKUQUERERERERkZPqcrh471gN/95TxptHtFxZztzu4gae210KwA+uno3VqpDZ0yhEFBEREREREZEhDMNgd3ED/9pTxsv7K2hs6+67puXKciZcLoPvv3gIgJsXJzE/Ocy9BclZUYgoIiIiIiIiIn3yalp4YU8Z/9pbRkl9e9/56GBfrpmfwLULE7VcWc7IM7tK2F9qJ9jXi29cmu3ucuQsKUQUERERERERmeJqmjt5eX85/95Txr5Se9/5QB8bl86J47qFiVwwLQqblqDKGWpo7eJnrx0F4O710zVz1YMpRBQRERERERGZgtq6HLx5uIp/7Snj/eO1OF0GYO5zuGp6FNcuTOTiWbEE+Cg6kLP389dzaGjrJjsumE9fkObucuQc6DuBiIiIiIiIyBThcLrYklfHv/eUsfFQJW1dzr5r85PDuG5BAlfNTyAqSLPF5NztLm7gqR3FANx/7Ry8bVY3VyTnQiGiiIiIiIiIyCTmchnsKm7gpX3lvHqggtqWrr5rKREBXLswkWsXJJARHeTGKmWycThd/Pe/D2IYcOOiJJakRbi7JDlHChFFREREREREJhnDMDhY1sRL+8t5eV855faOvmvhAd5cNc9skHJeSpgapMiYePyjIg6VNxHq7819l6uZymSgEFFERERERERkkjhW1cxL+8p5aV85hXVtfeeDfb24ZHYcG+bHsyIzSstKZUxVN3XwyzeOAfDNy2YQqeXxk4JCRBEREREREREPVlTXysv7K3hpXzlHK5v7zvt5W1k3M5YN8xJYMyMaP2+bG6uUqeTHrx6hudPB/OQwPrYkxd3lyChRiCgiIiIiIiLiYSrtHby835xxuK/U3nfe22ZhdVY0G+YnsH5mLIG+etsv42tLbi0v7C3HYoEfXTMHm1XL5ScLfTcRERERERER8QDVzR28frCSl/ZXsKOwHsMwz1stsCIzig3zErh0dhyhAd7uLVSmrC6Hi++8cBCAT52fytykUDdXJKNJIaKIiIiIiIjIBFXV1MHGg5W8eqCC7QOCQ4AlaeFsmJ/A5XPiiQ7WnnPifn96L4/8mlaignz4+iUz3F2OjDKFiCIiIiIiIiITSIW9ndcOVPLawQp2FjUMCg7nJ4dx5dw4rpqXQEKYv/uKFDlBXk0Lv30nF4DvXDmLUH/NiJ1sFCKKiIiIiIiIuFlZYzuvHajg1QMV7C5uHHRtYUoYV86N57I5cSSFB7inQJGTcLkMvv38AbqcLlZlRXPNggR3lyRjQCGiiIiIiIiIiBuU1Lfx2sEKXj1Qyd6SxkHXFqeGc/nceC6fE6cZhzLhPbOrhG0F9fh72/jxtXOwWNRMZTJSiCgiIiIiIiIyTorqWnm1Z6ny/gFdlS0WWJIWwRVz4rhsTjxxoX5urFLk9NU0d/LjV44AcM/FWSRHaLbsZKUQUURERERERGSMGIbBsaoWXj9UyeuHKjlU3tR3zWqBZemRXDE3jktnxxETouBQPM8PXjpEU4eDOYkhfGZFmrvLkTGkEFFERERERERkFLlcBntKGnj9UBVvHKqksK6t75rVAsunRXLF3HgumRWnrsri0d45WsXL+yuwWuBn18/Dy2Z1d0kyhhQiioiIiIiIiJyjLoeLrfl1vH6okjcPV1HT3Nl3zcfLysrMKC6dHcv6mbFEBik4FM/X2ungv/99CIA7V6YzJzHUzRWNAZcLKvZAxDTwD3N3NW6nEFFERERERETkLLR2OtiUU8Prhyp592g1zZ2OvmvBvl5clB3DpbPjWD0jmiBfvf2WyeWXbxyjrLGdpHB/vnZxlrvLGV2OTtj7D3j5q+bj5GVw5xtuLWki0HcxERERERERkdNU19LJ20eqef1QJe/n1tLlcPVdiw725eJZsVw6O47lGZH4eGlpp0xO+0oaeWRLAQA/unYOAT6TJF5yueDgs/D85wafT1zsnnommEnyX1lERERERERkbJTUt/HG4SpeP1TJzsJ6XEb/tbTIAC6dHccls+NYmByG1WpxX6Ei46DT4eQbz+7DZcA1CxJYMyPG3SWNjvxN8Nr/g5qjg89f8iNY/iW3lDTRKEQUERERERERGcDpMthb0sjbR6p4+0g1OVXNg67PSQzh0llmcJgVG4TFouBQpo7fvZPLsaoWIgN9+N6G2e4u59xVHYY3/xty3xp8Pn01XPsHCE10T10TkEJEERERERERmfJaOx28f7yWt49U8W5ONbUtXX3XbFYLi1PDe2YcxpIUHuDGSkXc52CZnd9vygPg/mvnEBHo4+aKzkFHE7z3AGz93eDzVm+4/k8w+3rQHwgGUYgoIiIiIiIiU1KFvZ23jlTz9pEqtuTVDdrfMNjPizUzYlg/M4bVWdGEBXhwWCIyCrocLu59Zh9Ol8EVc+O4Ym68u0s6O4YBB5+DjfdBa/Xga0v/A9Z+B/wmYafpUaAQUURERERERKYEl8vgYLm9Lzg8VN406HpKRADrZ8ayfmYMS9Ij8LapMYpIr99vyuVoZTPhAd788Jo57i7n7FQfgVe/AYXvDz4fPx+u+jUknueWsjyFQkQRERERERGZtDq6nXyYW9sXHFY3d/Zds1hgUUo463qCw8wY7W8oMpzD5U387p1cAH5wzRyignzdXNEZ6mw2ly5v+e3g8zYfs3HKks+C1eae2jyIQkQRERERERGZVEob2tiUU8OmnGo+yK2lo7t/mXKgj41VWdGsmxnLRTOiifS0MERknHU7XXzj2X04XAaXzIplwzwPWsZsGHDoeXj9v6C5YvC12dfBpT+FEA/6fNxMIaKIiIiIiIh4tC6Hi51F9WzKqeHdo9Ucr24ZdD0xzJ91M2NYNzOW8zMi8PXSjCOR0/Wn9/I4VN5EqL83P7pujufM1q3JgVfvhYLNg8+Hp8EVv4Tp691SlidTiCgiIiIiIiIep6qpg0051bx7tIYPcmtp6XT0XbNZLSxKCWdNdjRrsmKYGR/sOcGHyASSU9nMg28fB+D7V88iJtjPzRWdhs4W2Pxz+PDBodcuvBdW3Qve/uNf1ySgEFFEREREREQmPIfTxd6SRt7tCQ4PVwxuihIV5MPqrBguyo7mwsxoQgO83VSpyOTQu4y522mwLjuGaxckurukkzMMOPSvnqXL5YOvpa6Eq34F0TPcU9skoRBRREREREREJqTalk42H6vh3ZwaNh+rwd7e3XfNYoH5SWFcNMMMDuckhGK1arahyGj53Tu57C+1E+LnxY+vmzuxZ/PW5JhdlwveG3w+ON5snDLnBvObhpwThYgiIiIiIiIyITicLvaV2tl8zGyKsr/MjmH0Xw/192Z1VjQXZUezarqaooiMlb0ljfzuXbMb8/3XziEudIIuYx6p6zLABV+B1d8E3+Dxr2uSUogoIiIiIiIiblPW2M7mY+ZMww9za2nqcAy6PjshpG+24YLkcGyabSgyptq7nNzz9F6cLoMN8xO4ZiIuYzYMOPgcvPGdoV2XM9bA5b+A6Cy3lDaZKUQUERERERGRcdPW5WBbfj3vHavh/eM15NW0Droe6u/NyswoVmdFs2ZGNDEhE3QGlMgk9bPXjpBf20psiC/3XzPb3eUMVXUYXvsmFL4/+HxoMlz6E5i5QUuXx4hCRBERERERERkzhmFwpKKZzcfN0HBHQQNdTlffdZvVwoLkMFZNj2ZVVhTzksI021DETd4/XsOjW4sA+MWN8wkL8HFzRQO01cN7P4dtfxh67cJ74cKvg0/A+Nc1hShEFBERERERkVFV29LJB8dre4LDWmqaOwddTwzzZ1VWNKuzolg+LYpQf3VSFnE3e1s333hmPwC3LU9lVVa0myvq4eiCHX+FN78Lru7B1+bcCOu+C+Gp7qltilGIKCIiIiIiIuek0+Fkd1Ej7x+vYfPxGg6WNQ267u9tY/m0SFZNj2JVVjTpUYETu9OryBT03y8cpLKpg4yoQO67fKa7yzH3PTz6Mrz+bWgsHnwt+Xy49MeQtNg9tU1RChFFRERERETkjLhcBocrmvgwt5YP8+rYXlBHR7dr0JhZ8SGsyjKXKC9KDcfXy+amakXkVF7aV86L+8qxWS386pYF+Pu4+eu1bLcZHhZvHXw+LAUu+RHMvFr7HrqBQkQRERERERE5peK6Nj7IreXD3Fq25NXS0DZ4WWF0sC8rM6NYlRXFysxoooN93VSpiJyJSnsH3/n3QQD+86JMFiSHua+YujzY9FM48Mzg815+sO57sOSz4DWB9mmcYhQiioiIiIiIyBB1LZ1syavjw9xaPsitpbShfdD1IF8vzs+I4IJpUaycHsX0mCAtURbxMC6Xwb3P7MPe3s28pFC+vDbTPYXYS82mKbsfHXpt7X/Dsi+Ab9D41yWDKEQUERERERER2rocbC+o7wkN6zhSMXhfQ2+bhYUp4ayYFsXK6ZHMSwrD22Z1U7UiMhr+/H4+H+TW4u9t41c3Lxj/r+mWatj8P7D9T0OvrfoGLP8S+IeNb00yIoWIIiIiIiIiU1C308X+0kY+zK3jg9xa9hQ30O00Bo2ZGR/CysxILsiMYmlaBIG+egspMlnsK2nkf17PAeD7V88iM2YcZ/q11cMHv4Itvx16bfmXYOXXIDBq/OqR06KfACIiIiIiIlOAw+niYHkTW/Pq2Jpfx87Cetq6nIPGJIb5c+H0KC7IjOKCaZFEBWlfQ5HJqKXTwVee2oPDZXDl3HhuXpw8Pi/cVAGbfw47Hxp6bfX/g6Wfh8DI8alFzphCRBERERERkUnI6TI4UtEfGu4oqKe50zFoTHiAN8unRbIiM4qVmVGkRARoX0ORKeC7/z5IUV0biWH+/OT6uWP/dd9QCK9+A46/MfTaxT+ExXeAb/DY1iDnTCGiiIiIiIjIJOByGeRUNfeFhtvy62jqGBwahvh5sSwjkuUZkSyfFsmM2GCsVoWGIlPJv/aU8vyeMqwWePBjCwj19x67F6vJgX/cbIaIJ7ryV7DgE+DtN3avL6NKIaKIiIiIiIgHMgyD49UtbM2r46N882ho6x40JsjXi6XpEX2h4cz4EGwKDUWmrKK6Vr7zr4MAfHV9FovTIkb/RQwDjm2EJz829JrVC27+O2RdClbb6L+2jCmFiCIiIiIiIh7AMAzyalr5KL9/pmFtS9egMQE+NpakRbB8WiTnZ0QyJyEEL3VQFhGgy+HiK0/uobXLydL0CP7zoszRfQFHJ7z5Xdj2x6HXYufC9X+C2Nmj+5oyrhQiioiIiIiITEBOl0FOZTPbCurYXlDP9oJ66loHh4Z+3lYWp/aHhvOSQvFWaCgiw/jVm8fYV2on1N+bX9+yYPRmJdcXwCNXQlPZ0Gvn3Qbrvq9mKZOEQkQREREREZEJoNvp4mCZvS8w3FFYP2RPQ18vKwtTwlieEcXyaZHMTw7F10tLAkXk5D7MreVPm/MAeOCGuSSE+Z/bE7pcsPV38OZ/D3/95r/DzA2gRk2TikJEERERERERN+jodrKvpNEMDQvr2VXUQFuXc9CYQB8bi9MiWJoewbL0COYmKTQUkTNT3dTB3U/txTDg48tSuGxO/Nk/WdlueOImaKsdei1hIdz6FATHnf3zy4SmEFFERERERGQctHY62F3cwLZ8c6bh3pJGupyuQWPCArxZkmYGhkvTI5gVrz0NReTsOZwuvvzkHmpbOsmOC+a/r5x15k/SUgPv/gh2PTL89fXfhxVf1azDKUAhooiIiIiIyBiwt3Wzo9CcZbitoJ6DZXacLmPQmOhgX5al94aGkUyPCcKq7skiMkp+9eYxthXUE+Trxe8/cR7+Pqc5k7mtHg48C699Y/jriYvh5scgNHH0ipUJTyGiiIiIiIjIKChvbGdnUQM7C+vZUdjA0comjMGZIUnh/n1Lk5emR5IWGYBFs3dEZAy8e7Sa328y90H82Q1zyYgOOvkHtNXDkZfMfQ477MOPuf6vMOcGsGqG9FSkEFFEREREROQM9XZO3lVkBoa7ihooa2wfMi4jOrBvafLS9EgSz7WZgYjIaShrbOdr/9wLwKeXp3LVvIThB7bWwdGXYPtfoOrg8GPm3gwX/wBCRngOmTIUIoqIiIiIiJxCW5eDvSWN7CpsYEdRA3uKGmjuHNw52Wa1MCs+hMVp4SxONYPD6GBfN1UsIlNVl8PFfz6xm8a2buYnhfLtK2cOHlCXBzmvweEXoHT78E+SuBjWfRfSLtSsQ+mjEFFEREREROQE1c0d7Cps6FuefKi8CccJ+xkG+tg4L9UMDBenhbMgOYxAX73FEhH3+ulrR9hb0kiInxe/+/h5+FqB4o8g51UzPKw9NvwH+keYweGc68EvdFxrFs+gn3AiIiIiIjKlGYZBXk0LOwsb2FHYwM6ieorq2oaMiwvxY3FaOEvSIliUGk52XLA6J4vIhPLagQoe/rCQINr4+wXtJG++F45thLa6kT/ogq/Agk9ATPb4FSoeSSGiiIiIiIhMKR3dTg6W2ftmGe4qaqChrXvQGIsFZsQGDwoNE8P81QRFRCYml4vyIx9x/NlHedpnL0usx7FucY48fta1MO8WmH4x2LzHrUzxbAoRRURERERk0jIMg3J7B7uLGthd3MDu4kYOl9vpdg5emuznbWVBcljf0uSFKeGE+uuNtYhMYM2VkPcO5L6NkfcuCe11fMUCjPS3joyLYN7NkH0V+IWMZ6UySShEFBERERGRSaOj28mhcju7ixp7QsMGqpo6h4yLCvJhUao5y3BxWgSz4kPw8dLSZBGZwDrsULQVCt+H/Peg6kDfpRHnSCecB3NvMvc5DI4blzJl8lKIKCIiIiIiHqu8sd0MC3tCw8PlTXQ5XYPG9HZNPi8ljPNSwzkvJZykcC1NFpEJrrO5PzQsfB8q9oHhOvXHRWTA3JvN8DAqc+zrlClDIaKIiIiIiHiEToeTg2VN7OmZYbi7qJHKpo4h46KCfFiYYoaF56WEMS8pDH8fmxsqFhE5Ay3VULLN7KRc/BGU7wHjJPsaDlBqRFGfegXzLrkdEs8zN3YVGWUKEUVEREREZEKqsLcPWpZ8qGz4WYYz44N7AkPzSI7QLEMRmeBcLqg5CiUfQcl2MzRsKBg6zi8MHB3mcQJHSDL/aD6PZzsWkz5vJb/+2EKFhzKmFCKKiIiIiIjbdTqcHCpvYndRA3uKzeCwwj70TXNkYM8sw9QwzksJZ15SKAE+elsjIhOYYUBTmTmzsGx3/22n/YSBFoiZCcHx0FYHnU3QWAwuR/+Q8DSYdS1d2Vdz8wvt7G23kx0XzM9umK8/nsiY009bEREREREZV4ZhUFjXxt6SBvYWN7K3pJHDFU1DOibbrBay43pmGfaEhikRAXqjLCITl2FASxWU7zXDwvKe0LC1ZuhY7wBIXATJy8Db3xxT+CHkvT14XPRMyL4CZl4N8fPBYuF7zx9gb2klof7e/PlTi7Vlg4wLhYgiIiIiIjKm6lu72FfSyJ4SMzDcV9KIvb17yLiIQB/OSwnr289wXlIogb56yyIiE1RXG9QcgapDUHUYqg5C9WFzFuGJLDaImQWJCyFhoXm/vRFy34J9T0FT6YCxVkhZDjOuMMPDiIxBT/Xk9mKe3F6MxQIPfmwBKZEBY/t5ivTQT2QRERERERk1Hd3msuTesHBvSSPF9W1Dxvl4WZmTEMKC5HAWpISxIClMexmKyMTU2Qy1x6EuD+qOQ3VPcFifDxhDx1usEDXDDAt7j7g50FQOx9+Eo6/AxvsG73PoHQDT1kL2lTD9UgiMHLaUHYX1fPeFgwDce8kM1syIGYNPWGR4ChFFREREZGIxDHP/p+52cHSab7KcXeBymuf7jhMeG85hzp3w5q4voLIMeGwZes1iBZs3WL3MW5sPWL3B5tVz23P03rd6mWNsPubjKRKEuVwGBXWtfUuS95U2cmSYZckA06IDmZ8cxsLkMBYkhzMjLhgfL6sbqhYRGYajE+yl/UFh7XGoyzVvWypH/rjAaIidDTGzIXaWeT8621ye3NUKhR/A/qfh+c9CQ+Hgjw1JhMz15ozDjNXmx5xEaUMbX/j7LrqdBlfOjeeuNdPO/fMWOQMKEUVERETkzBiG+WarqxW6WnqOVnOmRlfr4POdPde6eq51d/R3mXR0mM8zMCzsPQzXqeuYqCw2841g3xEAXn7m7aDzJ1zzDT7hCAHfoP7HPkFgde+eV7UtnX2zC3tnGjZ1OIaMiwryYUFyGPOTwliQEsa8pDBC/b3dULGISA9nN9hLzEYljcXQUNR/v7EImitO/vGBMRA1HSKnmbMMY2ebR9CAmYCOLijbBR/+BgreM7suuwZs3WD1htTlkHkxTL/YDBtP849OrZ0OPvfYLupau5idEMIvbpqnmdsy7hQiioiIiExFTge0N0CHHToaew67uT9Th33A+RHOuYYGR2PG5gtevmaAZvUyD4tt8GOr1/CPLVb6lpqdOCvRMIa51nPrcppv/JyOntueY7j7rhP29jOc/SHqaPMJ6g8UfYPBLwT8w3uOCAiIGHA74Jxf6BkHkB3dTg6W2fsCw70ljZQ2tA8Z5+tlZW5iKAuSzcBwflIYSeFaliwi48TlgvZ6MwRsqjBv+45Kcwlxc2VPY5Nhlh4P5B0A4ekQlQmR03tCw57g0D9s+Ncu3wsFm83QsGgrdLcOHhOaAtPXm8Fh+oXm9+4z/hQNvv7PfRypaCIqyIc/37ZYXenFLfR/nYiIiIinMwwz3GurN98o2UvNDdrtA47GEnM2oDvMvt7cC8onyJx95+U34PDtmYk38LF//3kv34m/NLh3+bWz21x27eiA7jZzhuWgo+0k11rNWZudzT0zOpv773c09QeVZx1OWsw3wCOEjU6/MCq7Azje7MOheis7qi3srrHQ5PKhb7k35n+KadFBZmDYc8yIC8bbpmXJIjIKDKPn+54dOpvMP3a11poBYFudeb+ttue2rv/WcJ7e83v5QVhKz5Fq3oan9j8OiDz5zxxHJ1Tsg+KPeo4tZo0DBURC2oXm8uT01WZTlHP8Ofbrt4+z8VAlPjYrf/rUIhLDTr7sWWSsKEQUERERcSfDMEOljibzDVNHE3TazVt7Sf+eTHW5PbMoPNCiT0PGGndXMXYslv49EhmjDpmOzp5QsWlw2NhhN9/AttebIfKg+/XQ1tATHhs91xqA/CFPbwMSe441vSd9oAsv2myhOH3D8AqKJCAsGu+gSDOAdIRDVQQ0nTDz0T8cvHzG5t9BRCYewzD/QNLVZv5BpKv1hPs9R+/PuhNntg88OpvOfjuLwGgIjoPghJ7beAiJN297j8CoMwv02hvMJcnFW6F4m7lU2dk5eIxPMKStgPRVZmgYMwuso/eHlVf2V/Cbt48D8OPr5rAoNWLUnlvkTClEFBERERktLpcZALbVmzMj+m5POOoLoOaI++rsfaMVGGPOyhjUJKSnQYjVq2cpsMV8w9XbgGTYW8w3fX2HYS4H7n0ckui+z3Wy8OpZ0h0YdUYf5nIZFNXYySkoorCklPLKcuprKvF3NhFOM+GWFsJoIczSQpS1lVjvNsItLQQ47dhc3fjgwMfZ+/9uHlSf5gv7BEPAyZZZ9xx+YT33w8z7Ch9FTs7lPGE7BceAx47B2ywMeuwY+nG9+9L2HQP2qj3x1tk59HxXW0842Dr6+9havXu+L4RCQJT5vS8wqv9+QJTZvXjg43P9/uHohKqDUL7HPEp3Df+zOiASks+HlPMhZTkkLOj5I9LoO1hm5+vP7AXgsyvTuWlx8pi8jsjpUogoIiIicjKGYc6MaK4yuzO2VJtLhlsqe85VmefaepdUjXFDEJsvRGZCRDqEp5lHWCqEJplvuHqbddh8Jv4yYBlVhmFQ2tDO/lI7+8saOVBq50CZneZBjU8SgAT8vW3MSQxhbmIY8UmhZCWFkh4ZiNXaGwr3zJDtm9HYc9veYM5uHHKu934jYPQ00mk2GxacCe/A/lDRP9wMEAY9Dut/7Bva33jGJ6in8YyWVU8pvVsJ9AVkw3RtH3I4z3C8oyeMG64z/AjPMdrjB4aBp9rTz928/MAn0Pxa9gnouR/Q8zUaYDaM8gs94QgbcL/nupff2P4Mc3RB9SFzP8Pe0LD6yNA9bsH8mZtyfn9wGJk5Lj9fK+0d3PnoDjq6XazOiua+K2aO+WuKnIpCRBEREZm6HJ3mhuv2UmgqM29bqnpCwp6AsLkKHEObSYwOi7nsKXqG+aYkJB6CYnuOGHOmoLffGL22eDLDMKiwd7C/1M6BssaeWzuNbUPfAPt6WZmVEMK8xFDmJoUxLymUadFB2KwneRNssZhv/n0CIewMZr64nP1LrAcFkCcGj409jX16b5sAw5zR1N1q7ul5Nk5sPOMbZM6K7Ls/YF/OM7ntnanb17BnggX0LpcZNhnOYYKo4R73NA4abkxfuHY24dfA5x7mdZ0jvOaI40/x3J7cxX00WU+YTd732Ovk5wfuSzvwtreZ1aDzA+/79HeV7/0+0XvfzR3khzAM82d79RGoPtx/W3PU3MP2RAGRkLAQ4heYt8nLICh63Mtu7XRw56M7qGrqJDMmiN/cuvDk37NFxolCRBEREZmcXC5orR7cXKQ3KOy931I1Nq8dkti/F1Pf/YTBtz5jtHeeTErVTR09MwztHCht5ECZndqWoW+AvW0WZsaHMDcxlHlJocxNDGN6bND4NT6x2swlywERZjfT09UbPvaGiieGjO2NPV3CBzzu3SOyq4W+buFj1RX7RIO6gA84bN79XcItpwpTTjGjzDAGhIKukwSCjlM/11RjsQ397zGoi7s3I3Z1t53437X3uvcojT/bmk4SFE60UNsdXC7z53pdrhkQ9gWGR0duKuYf3h8WJiw0lyWHJrv939PpMrj7qT0cKm8iMtCHh29fQqj/2CyXFjlTChFFRETEMxk9jSIaCoc/msqHX5Z0rrz8zaXDYcnmm43Q5P77YclmQDhGeyPJ1FDX0tkTFtr7ZhpWNXUOGWezWpgRG2yGhUmhzEsMIysuCF+vCTYT6HQMDB/PVG9Th86W/lCxs7m/AU1fp+uegLG7vadL9ki3Hebs497b3oByoL7wboKznBhWWfsDzr4wa4Tw6kzDrjEJ7M7yNRSqTU7ObvNne2MR1OVBfZ65x3BdHjQUmF+/w7F6QVQWxMzsOWaZR3jahPx/5UevHOatI9X4eln5y6cXkxyhPzrKxDEmIWJ7ezt33303r7/+Ok6nk49//OM88MADWE74Ag0KCiI0NBRvb/MX7SVLlvDMM8+MRUkiIiLiiZzdZofi3mCwvmBAUFhkNjEZbd4Bg/caDEs2Q8PQZAhLMZc6TcA3HeKZGtu6OFDWExb2LEkuaxy6fN5qgekxwWZYmBTK3MRQZsaH4OftgYHhaLNYevYC9R+bZYe9+9ENWY47YInvoCXAA2YLnvJ7xSmu9wVmwwVnAx5bbMOP0fcq8RSGYW53YC8ZsGqgZPBqguZKTjrr1upl/uyOzu4JCntCw4hpHtO06bGthTz8YSEAv7p5AeelhLu3IJETjEmI+PWvfx2Xy0VeXh6tra2sX7+e3/3ud3z5y18eMvaDDz4gPT19LMoQERERT2AY5rLi2uNQd9ycUdB7v6HIXM432oIT+oPC8LTBTUoCo/XGW8ZEc0c3B3pnGPbcFte3DRlnsUBGVCDzksL6liXPSgghwEeLiNzC1jNjTkROn8tlzvztsJv7oLbUQGuNuc1Iaw201ppNyVpr+h+fzuoBm4/5R72IDHPLhIhpEJlhPg5N8eiv1XePVvP9Fw8B8I1LZ3DlvHg3VyQy1Kh/hbW0tPDoo49SUlKCl5cXoaGh3Hfffdx///3DhohhYWGjXYKIiIhMRF2t5l5FdblQm2uGhLU9oeFI+xWdLYvVnEUYOa2nk3EGhPcEhWEpalYiY66108HhiqaeGYaN7C+zk1/TOuzY1MgA5iWF9TQ+CWV2QgjBfloSPyH0dv91dpmzDZ3dPV1yu8wZis6uAQ1NnMPsV+gcptnJgMeGc+j40/04w2VOyjJcgNGzh2LvfdcIj43Bj085tkfvH1YsFsAy4NY6zLnhbof72AG3fTMpbf33B86utFhHuHY653qWcZ/WOdsJr3Wyc7YBz+F1wut6yB+i+v7/7v3/2tG/tL+7bYTb3vtt5jYBHfYBR2P//c7ms2t8ExjTM/u/ZwVA3/1E83FAFJOxC/uRiia+9I/duAy4eXESd605gz1lRcbRqIeIu3btIj09nYiI/v1Mli1bxsGDB3E6ndhs/UsurFYroaGho12CiIiIuFNnC9Tm9GxofqRng/OjZ99t9WRCEntmI2T2B4aRmWaA6CFLl8TzdXQ7OVzRNGgPw9zqFlzDrLpLDPMftIfh3MRQQgMUGPaFF84u89bRAY7e+53g7DRvex8PvD/oWlf/85wq/DudMWOxr6pMAZYBAahtcBB5uudgcJDbu4x32HMnPAYzwBsYDrq6+5fd954fj309bT5mA5PAGAiMgqAYc8Z/YFTPuWhzG4LAnsPLd+xrmmDKGtu5/eHttHY5WZ4RyY+unTtkKziRiWLUQ8SKigpiY2MHnYuJicHhcGC32weFixaLhWnTpuHt7c2FF17I/fffT0JCwrDP29nZSWdn/4bSTU1No126iIiInInudqg9dkJYeBgai0f+GJuP+eblTDqJegdCdBZEzYCo6f2BYUQG+ASe86chciY6HU5yKpv79jDcX2bnWFUzzmESw7gQv56w0AwN5yaGEhnkwW+QHZ39HZE7e5qVdLWaM5K62vpnJ3W395wfMGNp4PUTx3a3j822BWOltytub6fcQfsUDtiXcMg+hSe7fsI4y6k+zmqGTQNnA4742DL89ZN+7IBZgn0zFgeGWCfOfDTO4Jah5wfNvHT1z9A0Bs7MdPXPxuy7PtK5gbM5Rzg36PpJzo107aQMz2m+cyKLzfzZ2rvPqHfAgNuAwef8QsAvFHx7bv3Cem4HHJr5f1L2tm5uf2g7VU2dTI8J4o+fXISP1+SbaSmTx6iHiA6HA8MY/EuU02l+kz0xTW9oaMBqtWK32/nOd77Dhg0b2Llz57Cp+09/+lN+8IMfjHa5IiIiciqGYTYyqTxgHtWHzaOhcOSlSn6h5huRvjeahvmmq6tl5NcJiILoGWYHxYG3IYmeszRMJpVup4tjVc2D9jA8WtlEt3NoYBgV5DNoD8O5iaHEhEyQN8+GYQZ27Q3Q3mje9i437GwaHAoOOk447+wan3qtXuDlZ/7RwcvPnJnk5WfOLu59bPMdcH6Ya70hn82nP+zrvT/osVfPrU9P99/TGKPvRwJm2DkovDxViHli2OkcEJg6hp7rbboz6P83y6CbwecsQx/3Bt59na29GdSVe6RrMi46up187u87OV7dQlyIH4/esVQz02XCG/UQMSIigtra2kHnampq8PPzG7J02dqzl0FoaCgPPvggISEh5OfnM23a0PX/9913H/fcc0/f46amJpKTk0e7fBERkanN0WnOKuwNDCsPQNVBM0wYjl+oOSPhxJkp7Q0jz9QITjC7JUbP6AkLe24DIoYfLzIOHE4XeTWt7C9t7OuWfLiiiS7H0KA8PMCbuQP2MJyXFEpciN/4LD9zdJoNCFproK3W7GY6KBzsuT3x3GgGgD5B4Bts3voEDpi11DNTySdg8Kwln8AT7vubM4y9/c2xXv4DAkFfhRjiGaxWsGrbDDk7LpfBPf/cy/aCeoJ9vXjkjiUkhPm7uyyRUxr1EPG8884jJyeHhoYGwsPNduRbtmxh2bJlfaHhcFwuFy6XCx+f4b8R+/r64uvrwcs/REREJpq2+sFhYeUBcy/D4ZZf2XzMfQattv5ZFk6HGWJ0VAz//H6hEDPbDAxjZ0HMLPO+f/jYfl4ip+ByGeTXtnKgrLFvWfKh8ibau4cG38F+Xj0zC8P6ZhgmhfuPXmDo7DYDwZaqnnCw1vy6Gnjbd7/u3JoQWb3BP8z8GvQLM5ci+gb3HAPvB4983idIIZ+IyDkwDIMfvnyYVw9U4mOz8qfbFpEdF+LuskROy6iHiHFxcVx22WV8+9vf5re//S2NjY38+Mc/5oc//OGgcXl5eTidTrKysujs7OSee+5hyZIlml0oIiIyFjrsUL4XyvdA+W7zdqS9C/3DIWjw/sZ0t5tdlYfby9DLz5xJGDOr/4idBcHxWvYnbmcYBkV1bT3Lkc3Q8FB5Ey2dQ8PyQB8bc3qXI/fMNEyNDDi7wLCrFZoroaUaWiqhuWrAbc/RXAltdZzRHqFgLj8MiDS3AAiMNL9mew+/sAGPwwaf9wnU16SIiJv95f18HtlSCMD/3DyfC6ZFubcgkTMw6iEiwN/+9jfuvPNO4uPjCQwM5N577+Xaa6/l8ccfZ8eOHTz44IPU19dz66230t7ejq+vL+vWrePZZ58di3JERESmlq5Wc1Zh2e7+0LAud/ixYanmzKKBS4/b6swmKcMJioO4uYOPiAzNTJIJwTAMShva+5YjHyhr5ECpnaaOoYGhn7eVOQn9y5HnJoaRERWI1XqKkM0wzFm8TWXQVG52HW8qNw97KTRXmEHhmcwYtNj6O5MG9oaDA+9HDT7nF6YwUETEA72wt4yfvGr+jvWdK2dy9fzhG8uKTFQW48QuKB6iqamJ0NBQ7HY7ISGa+isiIlOUs9vcs7BsF5TtMUPDmiPDNzwJTTFnJvV23zRcUF8w/H6HFqvZ2CRuLsTO6Q8Mg2LG/FMSOR2GYVDZ1DGoS/KB0kYa2rqHjPXxsjIrPqRvOfK8pDCmRQfiZRtmq50OuzlL115qHr0BYVNZf3Do6Di9Ir0DzFm9wXHm105QHATHmrdBsf33AyIUxIuITHKbcqr57KM7cbgM7liRznc3zHJ3SSLAmeVrYzITUURERMZISzWUbIfS7VCywwwNHe1DxwXFmjOXLBb6OjXai83jRF5+ZkAYP78/LIyZZTY9EJkgqps7ONgzw7D3qG3pHDLO22YhOy7EnGHY0/gkKzYYb5vVnEXY0QiNBXCs2AwLBx72YjNEPB2B0Wbn8JBECEmA0AH3e8NCnyDNGBQREXYV1fOFx3fhcBlsmJ/Ad66c6e6SRM6KQkQREZGJqneWYcmOntBwOzQWDR3nF2bOcrJY6QsMWyqh+tDQsTafnsBwASQsNI/obLDpVwKZOOpbuzgwYA/DA2V2KuxDZ//ZrBayYoMHdUmeEeWNb1MJNBRA/fuwr2hwUDhSp/GBAiIhNAlCknrCwQTzfkhC/+Glhn8iInJqRyqa+MzDO+jodrE6K5pf3jT/1FtniExQescgIiIyUbTWQcm2AbMMd0N32wmDLBCabC597J1l2NEItceGPp/VG2Jn94eFCQsgeiZ4+Yz95yJymuxt3Rws79/DcH+pndKGobNrLRaYHhPE3MQwFsVaWBjcyDRbFT72w2ZgeKQQthSYS45PJTDa/DoKSxlwpEJYsnneN2j0P1EREZlyiupaue2h7TR1OFiUGs4fP7kIH69httIQ8RAKEUVERNzFXgpFW6HoQyjeOnwzE98Q8+hblmyAvYQh3VytXhAzc0BguNBckqzZUjKBNHd0c6i8adAehoV1JwblpjlRFi6KtLMoqI7pXpXEdpfj1VgABQVwuOHkL+QbAuFpEJFu3vaFhCnmDEOfwFH/3ERERAaqburgU3/bTk1zJ9lxwTz06SX4+2j/W/FsChFFRETGg2GYHZKLPjSDw+It5tLKEwVG9zQ+6Vma3Nlkdn89UWgKJC2GpCXmETcXvP3G/NMQOV1tXQ4e21rE4x8VMTM+hPyaFvJrWxnY0s8LB+mWGpaG1LMsuJ6Z3pUkOMsIbi3E2lINLSd5gaBYCE/vCQoH3maYjUq0F6GIiLiJva2bT/1tO8X1baREBPDYHUsJDfB2d1ki50whooiIyFhwOaHygDnDsOhDKP4IWmuGjrNYzVmENh9zifJwY7wDIfG8/tAwcbHZtEFkguh0ODla0cz+AXsYHqtqxmUAGLQ3VJJhqWCxtYL5ftXM9q0hxSgjtKMMq+GATszjREGxEDkdojIhYlp/UBiepiXHIiIyIbV1OfjMI9vJqWomJtiXx+9cRkyI/tArk4NCRBERkdHgcpmNTAreh4LNULQFOk+jy6vhAmeXefSKyuqZYdgTGkbPVOMTmTC6nS6OV7VwoKyRfaV2DpTaOVrZRLfTGDL2Me+fMt+aR6hlwJJlJzBwBbOXP0RmmkFh5HSImm4+jpwGfqFj/vmIiIiMlo5uJ599dCe7ixsJ8fPisTuXkhIZ4O6yREaN3pGIiIicDcOA2uNQ8J4ZGhZ+AO31Z/48vqGQvASSlpqhYeJ54B8++vWKnAWXyyC/toX9pfaeo5FD5U10OlxDxoYHeDM3KYz5SaHMTQxlfnIYsU//EsraAIvZtCTyhKAwajoEJ4BVm8yLiIhn63Q4+cLju9iSV0egj41H7lhKdlyIu8sSGVUKEUVERE6HYUBDYU9g2DPbsKXqzJ8nNAVSzu8/omcqQJEJwTAMiuvb+sLC/aV2DpbZae1yDhkb7OvFnMRQ5iWHMi8xjHlJoSSF+2M5cR/CK34BXn7mPoXe/uP0mYiIiIyvbqeLrzy5h005Nfh5W3no9iWcl6I/CsvkoxBRRERkJK21kL8J8t41Q0P7MI1QTsoCcXMgeUBoGJo0FpWKnBHDMKiwd/TsX9jYN9PQ3t49ZKyft5U5CaHMSzLDwnlJoaRFBmK1nkbjksRFY1C9iIjIxOF0Gdzzz328fqgKHy8rf7ltMcsyIt1dlsiYUIgoIiLSq7sDSj6CvHfM4LBy/5l9vJe/uSS5NzBMWqI93WRCqG3p7Jtd2HvUtgztZOJjszIzPph5SWHM7QkMM6OD8LJptqyIiMiJXC6D//fcfl7aV46X1cIfPnEeF06PdndZImNGIaKIiExdhgHVh/tDw6It4Gg//Y/3D4fUFZCy3AwN4+aBl8/Y1StyGlo6HRwotbOvtJF9JeZRbu8YMs5mtZAVG2zuYZhkLkueEReMj5cCQxERkVMxDIPvvniQZ3eVYrNa+O2tC1k3M9bdZYmMKYWIIiIytTRXQf67ZmiY/+6Z7WvoHwFpKyDtQjM8jJml/QzFrbqdLnIqm9nbExbuK23keHULxgmNki0WmBYdxLxEc3bh3KQwZieE4Odtc0/hIiIiHswwDO5/+QiPf1SMxQK/vGk+l8+Nd3dZImNOIaKIiExuTgeU7oDcN+H4m2e2RDkganBoGJ2t0FDcxjAMiura2Ffa2BcajtQpOTHMn/nJocxPCutbmhzkq1/7REREzlVvgPjQhwUA/Oz6uVy7MNHNVYmMD/02KSIik09LNeS+BcffMJcqd9hP7+MCoyFtpXmkroToGeYULhE3qG3p7FuOvLfUzr6SxmEbn4T4eTE/OYwFyWFmaJgcSkywnxsqFhERmdwMw+CHLx/m4Q8LAfjJdXO5ZUmKe4sSGUcKEUVExPO5nFC6s2e24RtQse/0Pi4w2pxlmLbSvI2artBQ3KKta+A+hnb2ljRS1jh0f04fLyuzE0KYn9QTGiaHkRYZgEX/34qIiIwpwzD4wUuHeWRLIWAGiB9fpgBRphaFiCIi4plaaszZhrlvmrMN2xtO/TE+wWZgmLEa0ldDzEyFhjLuHE4Xx6pa+hqf7C1p5FhVM64R9jE0A8NQFiSHq/GJiIiIG5wYIP7s+rl8bKkCRJl6FCKKiIhncLmgfA8cf92cbVi+59QfY/OF5KU9oeEaSFgINv3ok/FV1dTBnuIG9hQ3sqe4kf1ljXR0D93HMC7Ez9zHMDmMBUlhzEkKJcTP2w0Vi4iISC/DMPj+i4d4dGsRFosZIGoJs0xVeiclIiITV1cr5G+CnNfM4PBUnZQtVjMoTF9tBofJy8Dbf1xKFQHo6HZyqLzJDA1LGtlT1EC5vWPIuGBfL+b1ND6Z37OXYVyo9jEUERGZSAzD4HsvHuKxngDxgevncfOSZHeXJeI2ChFFRGRisZfBsY3mkf8eODtPPj46uz80TF0B/mHjUqaIYRiUNrSbYWFxA7uLGzlcbqfbOXhdstUCWbHBLEwJ57yUMBamhJERFYTVqqX0IiIiE5XLZfBf/z7Ik9uLzQDxhnncvFgBokxtChFFRMS9XC6o2GuGhjmvQeX+k48PiIJpF8G0tZBxEYTEj0uZIm1dDvaX2tk9YGlybcvQkDsy0IeFKeEs7AkM5yWFEeSrX7lEREQ8hcPp4hvP7udfe8qwWuDnN87nxkVJ7i5LxO30G62IiIy/rjYoeM8MDY++Am21I4+1+UDKcjM0nLYWYueAVY0lZGwZhkFBbSu7ixv79jPMqWrGeUL3Ey+rhdkJIf2hYXI4yRH+6pYsIiLiobocLr7y5B42HqrEy2rhf29ZwIb5Ce4uS2RCUIgoIiLjo6UGjvWEhsc2nnxs9Mz+0DD1AvAJGJ8aZcpq6XSwt7iRXUUN7ClpYG9JI41t3UPGxYf69YWF56WGMTshFD9vmxsqFhERkdHW0e3kC4/vYlNODT42K//3ifO4eFasu8sSmTAUIoqIyNipzzdDw/1PQ+WBkcf5BEPWpT3B4UUQor/2ytgxDIOyxnZ2FTWwq6iBnYUNHK1s4oRJhvh6WZmXFGrOMkwOY0FKGPGhatQjIiIyGbV0Ovjsozv4KL8eP28rf7ltMRdOj3Z3WSITikJEEREZPYYBFfvg6Mvw/i/BcI08Nu3C/tmGcfO0RFnGTLfTxZGKJnYWNvQFh5VNQzsmJ4b5syg1nEWp5tLk7LgQfLz0/6WIiMhkZ2/r5vZHtrOnuJEgXy8eun0JS9Mj3F2WyISjEFFERM6NsxuKtpizDfc+MfI4qzcsuh2mXwxpK8EncNxKlKnF3tbN7uKeWYZF9ewrsdPe7Rw0pncvw0WpEX3BYVyon5sqFhEREXepbenktr9t53BFE6H+3jx2x1LmJ4e5uyyRCUkhooiInLmuVsh9Gzb/4uTdlBMXwdybIPNiiJwGajYho8wwDArr2npmGNazs7CB49UtQ8aF+nv3hYWLUsOZnxSGv4/2MhQREZnKSurbuO2h7RTUthIV5MPf71zGzPgQd5clMmEpRBQRkdPTWgsHnoGN3zr5uIWfgplX98w2VEMUGV0Op4tD5U3sKKxne0E9u4sbqG3pGjIuPSqQRanhLO4JDadFB2G1KsQWERERU05lM7c9tI2qpk4Sw/z5+51LyYgOcndZIhOaQkQRERmZvRTeewB2PzbyGJ8guOi/zMYokdPGrzaZEjq6newpbmRHYT07CuvZVdRAW9fgpck+XlbmJYayKC2cRSlmaBgZ5OumikVERGSi21VUz2ce3kFTh4Os2CAeu2OZtjUROQ0KEUVEZLDKA/DyPVC6feQxaRfCiq9C2grwVrdaGT1NHd3sKmxge89Mw/2ljXQ7B7dNDvHzYml6BEvSIlicFsGcxBB8vbQ0WURERE7t3aPVfPGJXXR0u1iUGs7fPr2YsAAfd5cl4hEUIoqICORshBfugra6kcdc8GVYfAdEZIxfXTLp1TR39i1N3l5Qz5HKJozBmSGxIb4sSYtgWXoES9IjyIoJ1tJkEREROWPP7y7lG8/ux+kyuGhGNL//xCLtkSxyBhQiiohMRc5u2P5neP3bI4+x+cCGB2H29eCt5R1y7gzDoKS+ne2F9ewoqGd7YT0Fta1DxqVFBvTNNFyaHkFKRAAWNeURERGRc/DX9/P50StHALhuYSI/v3Ee3jarm6sS8SwKEUVEpoqWGnjvZ7DjryOPiZ5pBofJS9VJWc6ZYRgU1LbyUX49H+XXsb2gnsqmjkFjLBbIjgthaVo4S9IjWJoWQUyIQmsREREZHS6XwQMbj/KnzfkA3Lkynf+6YqZWNYicBYWIIiKTlWFAxV546weQ/+7I47Kvgst+BmHJ41aaTE6GYVBU18bW/Do+6jmqmjoHjfG2WZibGMqSdHN58qLUCEL9vd1UsYiIiExmHd1O7n1mHy/vrwDgG5fO4K4107TCQeQsKUQUEZlMuloh9y144zvQWDzyuAu+Aqu/Cb7B41ebTDqGYVBc38ZH+XVszavjo/yhMw19bFYWpoRxfkYkyzIiWJgcrr2HREREZMw1tnXxH4/tYnthPd42Cz+/cR7XLUxyd1kiHk0hooiIp6svgCMvwZv/ffJxV/0vzP+49jeUs9a7p2HvLMOt+XVU2AeHht42CwuTwzl/WiTnZ0RwXko4ft4KDUVERGT8lNS38emHt5Nf00qwrxd/+tQiLsiMcndZIh5PIaKIiKdxOqBkGxx6/uT7G4amwBU/h8z1YNNyUTk7ZY3tbMmtZWt+Hdvy6ylrbB903dtmYUGyOdNweUYkC1M001BERETcZ39pI3c8spPalk7iQ/145DNLmRGn1Tcio0EhooiIJ+iwQ+7bcOAZyHl15HEZa+DCeyH1ArAqyJEz19jWxda8Oj7IrWVLXt2Q7sleVgvzk8NYnhHJ+RmRLEpVaCgiIiITwztHq/jPJ/bQ3u1kZnwID9++hLhQrcIRGS0KEUVEJqqGQsjZCHufgMr9I49b+Ck47zZIXAxW67iVJ5NDR7eTHYX1fJhbx4e5tRwst2MY/detFpiXFMYF0yJZPs0MDQN89OuDiIiITCx//6iI771wEJcBF06P4vefOI9gP63GERlNehcgIjJRuFxQtsucabj7MWirHXnsiq/C7Osgfj6ou5ycAYfTxYEyO1vy6vjgeC27ihvocrgGjcmMCWJlZhQXTItkWUakuieLiIjIhOVwuvjRK0d4ZEshADctSuIn18/F26Y/rouMNoWIIiLu1NUKee/Csddgz+Mjj/Pyh5Vfg1lXQ3S2gkM5bYZhkFfTwoe55hLlj/LraO5wDBoTF+LHiswoVmRGsiIzitgQLfsRERGRia+po5sv/WMPm4/VAPDNy2bwxdXTsOh3ZZExoRBRRGS82cvg2EbzOP7GyOMiMsxlyjOvhshp41efeLyG1i7ez61l87EaPjheS2XT4A7KIX5eLJ8W2RMcRpERFahftkVERMSjFNe1ccejO8itbsHf28b/3jKfy+bEu7sskUlNIaKIyFgzDKjYBzmvmTMOK/aNPDZxMcy5AWZugLDk8atRPJrD6WJPSSObj9Ww+VgN+8sG72vo42VlSVo4F0yLYmVmFHMSQ7FZFRqKiIiIZ9peUM/n/76ThrZu4kL8+OunFzMnMdTdZYlMegoRRUTGQncHFGw29zc89jo0l488Nn0VzLoGsq+C4Ljxq1E8Wkl9G5uPm6Hhltw6mjsHL1GeERvMqqwoVmVFsyQtAj9vdVAWERERz/fsrlLue34/3U6DuYmh/PXTi7UVi8g4UYgoIjJaWqrNwPDYRsh9GxztI4/NvNjc33DGlRAYOX41isdq63KwLb+e93pmG+bXtg66HhbgzcpMMzRcNT2auFD9Mi0iIiKTh9Nl8PPXj/Kn9/IBuGJuHL+8aQH+PvpDqch4UYgoInK2DAOqj/TMNtwIpTtOMtgC2Vea+xtmXQr+YeNVpXgowzA4WtlsLlE+XsOOgga6nP1dlG1WCwuTw8zQMCuauVqiLCIiIpOUva2bLz/V30Dly2sz+dr6LKz63UdkXClEFBE5E85uKNpiBoc5r0Jj8chjvQPNwHDW1ebMQ9+g8atTPFJbl4MtuXW8k1PNu0erqbAPboiSGObPqqxoVmdFsXxaFKH+3m6qVERERGR8HKtq5nOP7aSorg0/bys/v3E+V89PcHdZIlOSQkQRkVPpbIbct+Doq3D8deiwjzzWPwJmXGE2RslYA95aUionV1LfxjtHq3nnaDVb8+vocvTPNvTztrI8I7JvtqG6KIuIiMhUsvFgJV//515au5wkhvnz59sWMTtBDVRE3EUhoojIcJoq+mcbFmwGZ9fIY4MTYOZVZnCYcgHY9K1VRtbtdLGrqKEvOMytbhl0PSncn7XZMVyUHcPyjEg1RBEREZEpx+Uy+PXbx/nN28cBWJ4Ryf994jwiAn3cXJnI1KZ3uiIiMGB/w1fMGYflu08+PiLD3N9w5gZIOA+s1vGpUzxSXUsnm3JqeCenms3Hamju6O+kbLNaWJQaztrsGNZlx5AZE6TZhiIiIjJlNXd087Wn9/LWkWoA7liRzrevyMbLpt+3RdxNIaKITF1OB5R8ZIaGOa9AQ+HJx8fNhewNZnAYMxMU9MgIDMPgcEUT7xyp5u2j1ewrbcQw+q9HBPqwJiuai7JjWDU9mtAA7W0oIiIiklvdzOf/vou8mlZ8vKz89Lq53LAoyd1liUgPhYgiMrV0tULu2z0dlV+H9vqTj09eZoaG2VdBRPr41CgeqdvpYlt+PW8eruStI9WUNbYPuj47IaRvmfL8pDB1UhYREREZ4MV95Xzruf20dTmJD/XjT59axLykMHeXJSIDKEQUkcmvuQqOvWbOOMzfBM7OkcdavSDtwp7g8EoIjhu3MsXzNHd0symnhjcPV/FuTvWgZcr+3jZWTo9iXU9wGBuiJjsiIiIiJ+pyuPjxK4d5dGsRABdMi+TBjy0kOtjXzZWJyIkUIorI5FRzDI6+bM44LN0JGCOP9fKDaevM4DDrUgiIGLcyxfNU2Nt563AVbxyu4qP8Orqd/f9vRQX5sC47lotnxbJyepSaooiIiIicRHljO3c9sZu9JY0AfOmiTL52cZZWbIhMUAoRRWRycDmhdAccfcUMDutyTz7eN8QMDGdugMz14BM4PnWKxzEMg5yqZt44VMWbh6s4UGYfdD0jOpCLZ8VyyaxYFiSH65deERERkdOw+VgNdz+1h4a2bkL8vPjfWxawbmasu8sSkZNQiCginqurzVyenPMK5GyEttqTjw+IMpcoz7wa0i8ELy2RkOEZhsH+UjuvHaxk48EKCuva+q5ZLLAwOYyLZ8Vx8axYMmOC3FipiIiIiGdxuQx++04uv377GIYBcxJD+MMnFpEcEeDu0kTkFBQiiohnaa2FYxvN/Q3z3gFH+8nHhyabTVFmboCU88Gq5aUyPJfLYFdxA68dqOT1Q5WDGqP4eFm5MDOKi2fFsm5mrPboERERETkLtS2d3PPPfWw+VgPArUtT+N6GWdoCRsRDKEQUkYmvPt9cpnz0FSjZBobr5OOjsszQcOYGiF9gTh0TGYbD6WJbQT2vHazg9UNV1DT3N90J8LFx0YwYLpsTx0XZMQT56kemiIiIyNnaklvL3U/vpaa5E18vKz++bi43Lkpyd1kicgb0jkhEJh7DgMr9Zmh45GWoPnTqj4lf0B8cRs8Y8xLFc3U5XHyYW8trByt483AVDW3dfdeC/bxYPzOWy+bEsTorWn8VFxERETlHDqeLB98+zu/ezcUwYHpMEP/3ifPIig12d2kicoYUIorIxOByQvFHZkfloy9DY/EpPsACKct7gsOrICxlXMoUz9TtdPFBbi0v76vgjcOVNHc4+q6FB3hzyaw4Lpsbx4ppUfh4Wd1YqYiIiMjkUWFv5+4n97K9sB6Ajy1J5nsbZuPvoz/UingihYgi4j7dHWZjlKMvQc5r0FZ38vFWb8hYbQaHM66AoJhxKVM8U+9S5Zf2lbPxUCWNA2YcxgT7cunsOC6fE8fS9Ai8bAoORUREREbTW4eruPfZfTS2dRPk68VPrp/L1fMT3F2WiJwDhYgiMr467HDsDTM4PP4WdLeefLx3AGSuNzsqZ10CfqHjU6d4JJfLYEdhPS/vr+C1gxXUtnT1XYsK8uGKufFcNS+BxanhWK3aK1NERERktHU6nDzwWg4PfVgAwNzEUH5760LSogLdXJmInCuFiCIy9por+xujFGwGV/fJx/uFQtbl5ozDaWvBJ2B86hSPZBgGe0oaeXlfBa8cKKeqqb85SliAN5fPiWPDvASWZURiU3AoIiIiMmaOVzVz91N7OVzRBMCdK9P5f5dla7sYkUlCIaKIjI26PHNvwyMvQ+kOwDj5+KBYyL7SDA7TLgSb97iUKZ7rSEUT/95bxsv7KihrbO87H+znxaWz47hqXjwrMqPw1lJlERERkTFlGAaPbS3iJ68eodPhIjzAm1/cOJ/1s2LdXZqIjCKFiCIyOgwDKvb1B4c1R079MWGpPY1RroakJWBV2CMnV97Yzgt7y/n3njJyqpr7zgf42Lh4VixXzUtgVVYUvl7arFtERERkPFQ3d/DNZ/ezKacGgNVZ0fzixnnEhPi5uTIRGW0KEUXk7DkdULy1p6PyK2AvOfXHxMyC7KvM8DBuLli0vFROzt7ezcaDFfxrTxnbCuoxeia1+tisrM2O4eoFCVw0I0Zd/kRERETG2ZuHq/h/z+2nvrULHy8r3748m09fkIZFv+OLTEoKEUXkzHS3Q967ZmiY8yq015/6YxIXmaFh9gaIyhz7GsXjdTlcbMqp5t97y3jrSDVdDlfftaXpEVy3MJEr5sQTGqBl7yIiIiLjra3Lwf0vH+HJ7cUAzIwP4cGPLSArNtjNlYnIWFKIKCKn1t4Ix9+AIy9B7tun7qhssULqCnOZcvaVEJo4LmWKZ3O5DHYVN/CvPWW8eqCCxrb+BjzTY4K47rxErp6fQFK4Gu2IiIiIuMue4ga+/s995Nea7wn+Y1UGX78kS9vJiEwBChFFZHgt1eZswyMv9nRUdpx8vM0HMi4yZxzOuAICI8enTvF4JfVtPLe7lOd2l1JS398gJTbEl2sWJHLNggRmxYdoWYyIiIiIG3U6nPz6reP86b08XAbEhfjxq5vnc0FmlLtLE5FxohBRRPrZy8zZhkdeNPc6NFwnH+8dCFmXmMFh5sXgFzI+dYrHa+9y8trBCp7ZWcrW/Lq+80G+Xlw2J47rFiZyfkYkNquCQxERERF3O1hm5+v/3NfX2O7aBQl8/+rZhAX4uLkyERlPChFFprr6fDj8ohkclu069Xj/cJhxpRkcZqwBb3Vdk9NjGAa7ihp4ZmcprxyooKXTnN1qscCKaVHctDiJS2bFqUGKiIiIyATR7XTxu3dy+b93c3G4DCIDffjxdXO5bE6cu0sTETdQiCgy1RgG1Bw1ZxwefhGqDpz6Y4Lj+zsqp64Am751yOmrsLfz/O4ynttV2rd3DkBKRAA3LkrihkVJJIb5u7FCERERETnR0comvv7PfRwqbwLgirlx3H/NHCKDfN1cmYi4i5IAkanAMKBinznb8PCLUHf81B8TkWGGhjOvhoTzwGod+zpl0ujodvLm4Sqe2VXKB8drcBnm+QAfG1fMjefGRUksTYvAquXKIiIiIhOKw+niT5vz+fVbx+h2GoQFeHP/NXO4al689qgWmeIUIopMVi4XlO4wg8MjL0Jj8ak/JnZuT3B4FcTMMteZipyB3OpmntxewnO7Swd1V16aFsGNi5O4Ym48Qb760SMiIiIyER0qt/P/ntvPwTJz9uH6mbH85Po5xARrCyMRUYgoMrk4HVC8xZxtePRlaK449cckL+tZqnyVOftQ5Ax1dDvZeLCSf2wrZnthfd/5+FA/bjgviRsXJZEWFejGCkVERETkZDq6nfzm7eP8aXM+TpdBiJ8X39swm+vPS9TsQxHpoxBRxNM5uqDgPTj8AuS8Cm11Jx9vsUH6heaMwxlXQkj8+NQpk87xqv5Zh/Z2c9ah1QJrs2P5+LJkVmfFqLuyiIiIyAS3vaCebz23v2/v6ivmxvH9q2dr9qGIDKEQUcQTdbdD7tvmMuWcjdBpP/l4Lz+Yts4MDrMuhYCI8alTJp2ObievHazgH9uK2VHY0Hc+IdSPjy1N4abFScSHqkmKiIiIyETX3NHNzzfm8PePigCIDvbl/mvmqPOyiIxIIaKIp+jugNy34PC/Iec16Go5+XjfEDMwzL4KMteDb9C4lCmT0/GqZv6xvZjnd5f1zTq0WS2szY7h40tTWJUVrVmHIiIiIh7inaNV/Ne/DlJh7wDglsXJfPuKmYQGeLu5MhGZyBQiikxk3R2Q9zYc+pc547Cr+eTjAyIh+0qzo3L6KvDyHZ86ZVJyOF28ebiKR7cW8lF+/16HiWH+fGxJMjctTiYuVMtcRERERDxFdVMHP3z5MC/vN/dOT4kI4KfXz2VFZpSbKxMRT6AQUWSi6QsO/90z4/AUwWFIUn9H5ZTlYLWNS5kyedW2dPLU9mKe2Fbc99fpvlmHy1JYNV2zDkVEREQ8idNl8PhHRfzP6zk0dzqwWuCOFel8/ZIZ+Pvo/YOInB6FiCITQXcH5L3TM+PwNILDyOk9weEGSFgI6pgm58gwDPaWNPLY1iJe2V9Bl9MFQGSgD7cuTeHjy1JICNNehyIiIiKe5mCZnW//6wD7S8191OcnhfLj6+YyJzHUzZWJiKdRiCjiLo5OsznK4X/D0VdPHRzGzYNZV5tLlaNnjEuJMvl1dDt5eX8Fj20t7PvFEmBBchifviCVK+bG4+ulv06LiIiIeJrmjm5++cYxHttaiMuAYD8vvnlZNh9fmqJVJSJyVhQiiownR2fPjMN/Q86r0Nl08vHJy8zQcOYGCE8dlxJlaihtaOOJbcU8tb2YhjazUYqPl5UN8xK4bXkq85PD3FugiIiIiJwVwzB47WAlP3jpEFVNnQBcPT+B71w1k5hg7WctImdPIaLIWDuT4NBig7QVZnCYfRWExI9bmTL5GYbBrqIG/vp+AW8crsRlmOcTQv345PJUblmcTGSQmvGIiIiIeKr8mhZ+8NJh3jtWA0BaZAD3XzuHC6dHu7kyEZkMFCKKjAWnAwreg4PPwZGXodM+8libD2RcZM42nHEFBEaOX50yJTicLjYequSv7xewt6Sx7/yKzEhuW57GuuwYvGxW9xUoIiIiIuekpdPBb985zkMfFNDtNPCxWfnCmmnctWYaft7amkZERodCRJHR4nJByTY4+Kw567CtduSx3gGQud6ccZh1CfhpU2MZfc0d3Ty9o4SHPyykrLEdAB+blesWJnLHynRmxAW7uUIREREROReGYfDivnJ+8uqRvqXLF82I5rsbZpMeFejm6kRkslGIKHIuDAMq9pnB4cF/QVPpyGN9QyDrMrM5yrR14BMwfnXKlFLa0MYjHxby1I4SWjodAEQE+vCp81P55PmpRAdrybKIiIiIpztS0cT3XjzE9oJ6AFIjA/juVbNYNzPWzZWJyGSlEFHkbNQehwPPmuFhXe7I4/wjIPtKmHUNpK8CL4U3Mnb2ljTyl/fz2XiwEmfPhoeZMUHcuTKd6xYmaimLiIiIyCRgb+vmV2/m8PePinAZ4Odt5UsXZfLZCzP0+56IjCmFiCKnq7HE3OPw4LNQeWDkccHxZlOUWVdDygVg05eZjB2Xy+DNI1X8ZXM+O4sa+s6vzIzizgvTWT09GqvV4sYKRURERGQ0OJwuntxezP++dZz61i4Arpwbz7evnElimL+bqxORqUDphsjJtFSb+xsefNbc73AkIUkw+1pzxmHiYrCqSYWMrW6nixf3lvPH9/I4Xt0CgLfNwjULErlzZToz40PcXKGIiIiIjJZNOdX8+JUjfb/3TY8J4gdXz+aCzCg3VyYiU4lCRJETdTTBkZfgwDOQ/+7I44LjYda1MOd6BYcybtq7nDy9o5i/vF/Q1ywl2M+LT52fyu0XpBET4ufmCkVERERktByvauZHrxzhvWM1AIQHeHPPxVncujQFL5vef4jI+FKIKALg6IK8t2H/03DkZXB1Dz8uMMacbTjnekg+X8GhjBt7ezd/31rIwx8WUtezfCUqyJc7V6bzyfNTCPbzdnOFIiIiIjJa6lo6+fVbx/nH9mKcLgNvm4XbL0jjS2unE+qv3/tExD0UIsrUZRhQusMMDg88Cx2Nw48LiISZV5vBYeoKsGqzYhk/1U0d/O3DAp74qLiv03JyhD+fXzWNGxclafNsERERkUmk0+Hk0S2F/PadXJo7zN/9Lp0dy32XzyQtKtDN1YnIVKcQUaae2lw48E/Y9xQ0Fg0/xi8MZm4wg8O0VWqOIuOuuK6NP27O49ldpXQ5XABkxwXzxTXTuHJuvJaviIiIiEwiLpfBS/vL+cXrOZQ2mFvWzE4I4TtXzmL5tEg3VyciYlIyIlNDSzUcfB72PwXle4Yf4xNkLlWefR1krAGblgnI+MutbuF37xznxX3luAzz3KLUcO5aM4212TFYLOq0LCIiIjKZvH+8hp+9dpRD5U0AxAT7cu+lM7jhvCRsVv3uJyITh0JEmby6WuHoq2ZwmPvW8GMsVph7kxkcTlsLXr7jW6NIj9zqZn7zdi4v7S/H6AkPV2dFc9eaaSxNj1B4KCIiIjLJHCyz88DGo7x/vBaAYF8vvrBmGp9ZkUaAj96qi8jEo+9MMrk4HVCwCfb/09zrcCRzbjCDw8z14O0/buWJnOhYVTO/efs4rxyo6AsPL54Vy93rpjMnMdS9xYmIiIjIqCupb+N/3sjhhb3lAHjbLHzy/FS+vHY6EYE+bq5ORGRkYxIitre3c/fdd/P666/jdDr5+Mc/zgMPPDBkJs2ePXv44he/SEVFBYGBgTz44INcfPHFY1GSTGaGARV7zeDwo9+PPK53qfL0S8EnYNzKExlOTmUzv3nnOK8OCA8vnR3LV9ZNZ3aCwkMRERGRyaa2pZP/ezeXxz8qottp/gJ4zYIE7r1kBskRen8iIhPfmISIX//613G5XOTl5dHa2sr69ev53e9+x5e//OW+Mc3NzWzYsIFHHnmE9evX895773HNNddw9OhR4uLixqIsmWwaCmH/M7DpJ2C4hh8z40qzOUrWZeAbNK7liQwnp7KZB98+xqsHKvvOXTY7jq+sm86shBA3ViYiIiIiY8He1s1f3s/noQ8LaOtyArAyM4pvXZ6tlSci4lEshtE7B2Z0tLS0EBsbS0lJCREREQA8//zz3H///ezZ09/Q4s9//jOvvfYa//rXv/rOXX311axbt4677777lK/T1NREaGgodrudkBC98Z4y2urh0L/gvZ9DS+XwY6atg3k3w4wrwE//b8jEUFjbyv++dYwX9/XveXjF3Di+vHY6M+P1/6mIiIjIZNPa6eDhDwv48+Z8mjocAMxLCuXeS2awKivazdWJiJjOJF8b9ZmIu3btIj09vS9ABFi2bBkHDx7E6XRis9kA2Lp1KytWrBj0scuWLWPv3r3DPm9nZyednZ19j5uamka7dJmoutvh2EZ4/5dQeWD4McnL4LzbIPtK8A8f3/pETqKssZ3fvn2cZ3aV4uxpt3z5nDjuXj+d7DiFhyIiIiKTTUe3k8c/KuIPm/Koa+0CYEZsMPdcksUls2LVME9EPNaoh4gVFRXExsYOOhcTE4PD4cBut/eFixUVFaxdu3bIuG3btg37vD/96U/5wQ9+MNrlykTlckHRB/DB/0LeO8OPic6G8++CmRsgIGL4MSJuUt3cwe/fzeMf24rpcprL7S+aEc3XL5mhZSsiIiIik1CXw8U/d5bwu3dyqWzqACA9KpCvrp/OVfMSsFkVHoqIZxv1ENHhcHDiCmmn09z3YeBfXEYaN9JfZe677z7uueeevsdNTU0kJyePVtkyUVQehC2/hf1PDX89IAou+jbMvBqCtARAJp6G1i7+uDmPR7cU0tFthofLMyK599IsFqUq7BYRERGZbLocLp7fXcr/bcqlpL4dgMQwf76yLpMbzkvCy2Z1c4UiIqNj1EPEiIgIamtrB52rqanBz8+P0NDQU44bqamKr68vvr6+o12uTAT2UvjoD7D1dyOPuewBmH0tBKvpjkxMbV0OHvqggD+9l09zp7nnzYLkML5x6QxWZEa5uToRERERGW1dDhfP7irl/97NpazRDA+jgnz50kXTuHVZCr5eNjdXKCIyukY9RDzvvPPIycmhoaGB8HBzb7otW7awbNkyrNb+v8AsWrSILVu2DJpduGXLFm655ZbRLkkmovZG2PUwvPX9kces/z7MvRlCE8epKJEz53C6+OfOUn791jGqm819W2fGh3DvJVmszY7RnjciIiIik0ynw8kzO0v5w6a8vvAwOtiXL6yexseXpuDvo/BQRCanUe/ODHDNNdeQkJDAb3/7WxobG1m7di0//OEPufbaa/vGlJaWMnfuXJ577jnWrl3Lq6++yl133cWhQ4cIDAw85WuoO7MHcnSZy5Rf/PLIYy78Oiy6HcJSxq0skbNhGAZvHK7i5xuPklfTCkByhD/3XjKDDfMSsGrPGxEREZFJpaPbyTM7S/j9pjwq7OaehzG94eGyFPy8FR6KiOdxa3dmgL/97W/ceeedxMfHExgYyL333su1117L448/zo4dO3jwwQdJSkriqaee4q677qK+vp7MzExeeuml0woQxYO4nHD0FXjmdjCcw49ZfCdc8CWIyBjX0kTO1s7Cen762lF2FTUAEB7gzZfXTucT52vZioiIiMhk097l5Kkdxfzpvfy+himxIb58cfU0PrZU4aGITB1jMhNxPGgm4gTWGxw+91lwdg4/Zvb1sO6/FRyKR8mtbuaBjTm8ebgKAD9vK59dmcF/rM4gxM/bzdWJiIiIyGiyt3Xz2NZCHt5SSH1rFwBxIX7cddE0bl6crPBQRCYFt89ElCnI5YJDz8PznwPDNfyYjDVwxS8hKnNcSxM5V/WtXfz6rWM8sa0Yp8vAaoFbliTz1fVZxIb4ubs8ERERERlF1U0d/O2DAp7YVkxLT8O85Ah/Pr9qGjctTtLKExGZshQiytlzOWHXI/DKPSOPSV0BV/0vRM8Yt7JERkuXw8VjWwt58O3jNHeYv0CunxnLty6fQWZMsJurExEREZHRVFTXyp825/PsrlK6HObEiOy4YL64ZhpXzo3Hy2Y9xTOIiExuChHlzHS2wHsPwJbfjDwm7UK48pcKDsVjGYbB64eq+OlrRyiqawPMjsv/feVMLsiMcnN1IiIiIjKajlQ08YdNeby8vxxXz2Zfi1LDuWvNNNZmx2CxqGGeiAgoRJTTUX0UXvsmFLw38pjsq+DyByA0afzqEhkDB8vs/OiVw3yUXw9AVJAv37g0ixsXJWNTx2URERGRSWNnYT2/35THO0er+86tmRHNXWsyWZoe4cbKREQmJoWIMpSjE7b/Gd74zsnHLb7TbI7iHz4+dYmMoermDn6xMYdnd5diGODjZeVzF6bzxTWZBPnqW6WIiIjIZOB0Gbx5uJK/vl/AzqIGAKwWuGJuPF9cM43ZCaFurlBEZOLSO2Mxm6Icew3e/iHUHD352Mt+Bks+CzZ1opXJodvp4tEthfz6reN9G2dvmJ/A/7tsBknhAW6uTkRERERGQ2ung2d2lvDQh4UU15vb1fjYrNywKJHPr5pGWlSgmysUEZn4FCJORc5uOPQveP9XUHPk5GNTlsMlP4akReNTm8g4+jC3lu+9eIjc6hYA5iWF8r0Ns1iUquUrIiIiIpNBhb2dR7YU8o9txX2N8sICvPnU+al86vxUYkL83FyhiIjnUIg42RkGVOyFHX+FPY+ferx3IKz7Liy+A7x8xrw8EXcoa2znx68c5tUDlQBEBPrwzUtncPPiZKza91BERETE4x0otfPXD/J5ZX8Fjp5uKRlRgdyxMp0bzkvC38fm5gpFRDyPQsTJxF4KR16Gwy9A8ZbT+xirN6z+Jiz9nPY2lEmvo9vJXzbn83+bcunodmG1wG3L0/ja+ixCA7REX0RERMSTuVwGbx+t5q/v57OtoL7v/PKMSD57YToXzYjRH4xFRM6BQkRP4OiCxiKoz4fa41C5H8r3QO2xM3+umNlwwZdgzg3g5Tv6tYpMUG8fqeIHLx3u2wNnaXoEP7h6NjPjQ9xcmYiIiIici5ZOB8/vLuXhDwspqG0FwMtqYcP8BO5cmc6cRDVLEREZDQoRJ6qqw/CH5ef2HAnnwfxbYc71EBg1OnWJeJgKezvff/EQrx+qAiA2xJdvXzGTq+cnYLHoL9EiIiIiniq3uoW/by3kud1lfQ3yQvy8+PiyVG6/II24UO13KCIymhQiTlSNxac3LjjebH4yba15hCaObV0iHsLhdPHIlkL+981jtHY58bJauPPCdL6ydjqBvvrWJyIiIuKJnC6Dt49U8djWIj7Ire07nxEdyKeXp3HjoiT9riciMkb03XWimnEZfP59aK2GkCQISwGfAHdXJeIR9hQ38O1/HeRIRRMAi1PD+dF1c8iO09JlEREREU9U39rF0ztKePyjIsoa2wGwWmDdzFg+vTyNFZmRWmUiIjLGFCJOZPHz3F2BiEext3Xz89eP8o/txRgGhAV4c9/l2dy0SF2XRURERDzR/tJGHt1SxEv7y+lyuAAID/DmliUpfGJZCskRmmghIjJeFCKKiMczDIMX95Vz/8uHqW3pAuCG85L49hXZRAapgZCIiIiIJ+nodvLawQoe3VLE3pLGvvNzEkP49PI0NsxPwM/b5r4CRUSmKIWIIuLRyhrb+a9/HWBTTg0A06ID+dG1c1k+LdLNlYmIiIjImcitbuYf20p4fk8pjW3dAHjbLFw5N57bLkhjYXKYliyLiLiRQkQR8Ugul8Hj24p44LWjtHY58bFZ+dLaTD6/OgNfL/1lWkRERMQT9M46fHJbCdsL6/vOJ4T68bGlKdy6NIXoYK0sERGZCBQiiojHya1u4b7n97OjsAGARanhPHDDXDJjgt1cmYiIiIicjuNVzfxjezHP7y7D3m7OOrRaYG12LJ9YlsKqrGhs2tNaRGRCUYgoIh6j2+niz5vzefCt43Q5XQT62PjmZdl86vxUNU4RERERmeA6up28eqCCJ7cX9/0xGCAxzJ9bliRz8+Jk4kL93FihiIicjEJEEfEIB0rtfPO5/RypaAJgzYxofnzdXBLD/N1cmYiIiIicTE5lM0/tGDzr0Ga1sC47hluXpbBqumYdioh4AoWIIjKhdTqc/Obt4/zxvXycLoPwAG++u2EW1y5I1MbaIiIiIhNUY1sXL+4r55mdpf+/vfsOr7us/z/+Oid7772bNl3pTCcdIKsgGwRRRKaIfhXE+eUnCrgXfFFcDEEZypAtssvs3mnTNmnSNHvvnTPu3x8ppw0poSlJPhnPx3X1usjnvnPO+5jbzzl55R7aXdHiuZ4UHqDLF6foUmYdAsC4Q4gIYMzKq2zRd57apf3VbZKkc+cm6I7zZys6mM21AQAAxhqX2+j9A3V6elu53sirUa/LLUnyttt02sxYfWFJqlYx6xAAxi1CRABjjsPl1p/fLtK9aw/I6TaKDPLVzy/M1tlzEqwuDQAAAB9xsK5dT28r17Pby1XT2uO5PjMhVJfmJOuC+YmK4o/AADDuESICGFMKatr0nad2eZa9nDU7Xj+7KJvZhwAAAGNIW7dDL+dW6elt5dpWcuSQlPBAH104P0mfy0lWdlKYhRUCAIYbISKAMcHlNrr/vYP6vzcK1OtyKyzARz+5YLbOn5fI3ocAAABjgMtttL6oXs9tr9B/91Sp29G3XNluk06ZHqtLc5J16sxY+Xl7WVwpAGAkECICsNyh+g59+6md2l7aLEk6dUasfnnxHMWFstk2AACAlYwxyqts1XM7KvTSrkrVth1ZrpwZE6RLF6Xo4gVJiuVzGwBMeISIACxjjNFTW8t050t71dnrUoift3503ixdmpPM7EMAAAALlTV26sVdlXpuR4UKa9s91yMCfXTO3ARdsjBZ81PC+cwGAJMIISIASzR19OrWZ3fr1bxqSdLSjEjd/fn5SgoPsLgyAACAyam5s1cv767S8zsqtOXQkX0O/bztOn1WnC6an6TVWTHy9bZbWCUAwCqEiABG3XsFdfru07tU29YjHy+bvnPmdH1l1RR52flLNgAAwGjqdri0dn+tnt9Robfza+VwGUmSzSYtnxKlCxck6azseIX6+1hcKQDAaoSIAEZNt8OlX7+6Xw+vOySpbx+d31++gJP7AAAARpHD5dYHhfV6aVel3sirUVuP09M2MyFUFy1I1HnzEpUQxgoRAMARhIgARsW+qlZ964mdyq9pkyR9eXmabj17pgJ8Ob0PAABgpDldbm082Kj/5Fbq1bxqNXc6PG0JYf66YH6SLlyQqBnxoRZWCQAYywgRAYwoY4we21iin768T71Ot6KDffXbz83TZ2bEWl0aAADAhOZ2G2051Kj/5FbplT1Vqm/v9bRFB/vq7OwEnTcvUYvSImRnWxkAwCcgRAQwYlo6HfrBM7mew1NOmxGrX39urqKD/SyuDAAAYGIyxmhHWbP+s6tKL++uVE1rj6ctPNBHZ2fH69y5iVqaESlvLw5IAQAcP0JEACNiW0mTbvrXDlU0d8nHy6Zbz56pa1aky2bjr9wAAADDyRijXeUtemV3lf6TW6WK5i5PW4ift86cHa/z5iVoxdRo+RAcAgBOECEigGHldhv99b0i3fV6gVxuo7SoQN37hQWamxxudWkAAAAThstttPVQo17ZU63X8qpV1dLtaQv09dIZs+J07txErc6Klp83e1ADAD49QkQAw6aurUfffmqn3j9QL0k6b16ifnFRtkL8fSyuDAAAYPxzuNzaeLBBr+yp1ut5NapvP7JUOcjXS5+ZEavPzknQZ6bHcngdAGDYESICGBbrCut18xM7Vd/eI38fu+44b7Y+vziF5csAAACfQo/TpQ8O1OuVPdV6c19Nv1OVQ/29dfqsOJ2dnaBV06Ll70NwCAAYOYSIAD4Vt9voz+8U6q43CmSMlBUXrD9+caGy4kKsLg0AAGBc6uhx6r2COr2yp1pr99eqvcfpaYsK8tWZs+N0VnaClk+Jkq83exwCAEYHISKAE9bc2atvP7VLa/fXSpIuzUnWTy7IZvkMAADAENW2deutfbV6Y2+NPiisV6/T7WmLC/XTWbPjdVZ2ghanR3CqMgDAEoSIAE7I7vIWfe3xbSpv6pKft10/vSBbly1OsbosAACAcaOwtl2v763WG3trtLOsWcYcaUuNDNSawzMOF6SEy25nixgAgLUIEQEMiTFG/9pcpjtezFOvy63UyED9+YqFyk4Ks7o0AACAMc3lNtpR2qQ39tbojb01Oljf0a99bnKYzpwVpzNmxSsrLpi9pQEAYwohIoDj1tXr0g+f361nt1dIkk6fGae7LpunsABOXwYAADiWrl6XPiis1xt7q/XWvlo1dPR62ny8bFqeGa0zZsXpjJlxig/zt7BSAAAGR4gI4LiUNHToq49u0/7qNtlt0vfWzNBXV09haQ0AAMBHlDV26u38Wq3dX6sNRQ3qOWp/wxB/b506I1ZnzIrTyVkxCvHnj7EAgPGBEBHAJ3q3oE7f/Od2tXY7FR3sp3u/sEDLM6OsLgsAAGBMcLjc2lbSpLf39wWHB2rb+7UnhQfo9JmxOmNWvJZOiZQPB6MAAMYhQkQAH8sYo/vfO6hfv7pfbiPNTwnXfVfmKC6UpTYAAGBya2jv0Tv5dVqbX6v3CurU1u30tHnZbcpJjdBnZsTq1Bmx7G8IAJgQCBEBHFNXr0vffyZXL+2qlCRdtihZP70wW37eXhZXBgAAMPqMMcqrbO2bbZhfO+A05YhAH50yPVafmRGrk6fFKCyQZcoAgImFEBHAAGWNnfrqo9u0t6pV3nabbj9vlr60LI2/oAMAgEmlrduh9UUNent/rd7Or1VNa0+/9lkJoTp1Rl9wOD8lXF7sFQ0AmMAIEQH0s76wXv/zz+1q6nQoOthXf74iR0syIq0uCwAAYMS53UZ7Klv0XkGd3iuo1/bSJjndR6YbBvh4aeW06L7gcHospykDACYVQkQAkvqW6Px9/SH97OV9crmN5iSF6b4rc5QYHmB1aQAAACOmtrVb7x2o13sFdfqgsF6NHb392tOjAj3LlJdmRMrfh61dAACTEyEiADlcbt3xYp4e31QqSbp4QZJ+cfEcPiQDAIAJp8fp0rZDTXq3oE7vFtRpf3Vbv/ZgP28tz4zS6qwYnTwtRqlRgRZVCgDA2EKICExyLZ0Off2f27SusEE2m3Tr2TP0lVVT2P8QAABMCMYYFdd39C1RPlCvDUUN6nK4+vWZkxSm1VnRWj0tRgvTIuTjZbeoWgAAxi5CRGASK67v0HV/36KD9R0K9PXS7y9foDNmxVldFgAAwKfS1NGr9UUNWlfUt0y5vKmrX3tMiJ9WTYvWyVkxWjk1WlHBfhZVCgDA+EGICExSG4oadONj29TS5VBimL8evGqxZiWGWl0WAADAkHX1urTlUKPWFdbrg8J67a1qlTlyHop8vexalB6h1VkxWj0tRjMTQlh1AQDAEBEiApPQE5tLddvze+R0G81LCdcDX85RbAinCwIAgPHB6XIrt6JF6w7Ua11RvbaXNKvX5e7XZ3pciE6aGqVV06K1bEqUAn351QcAgE+Dd1JgEnG7jX716n7d/95BSdK5cxP0u0vncYAKAAAY04wxKqxt1weF9VpX2KBNBxvU1uPs1ycxzF8rpkZr5bRoLc+M4g+kAAAMM0JEYJLodrh0y5M79cqeaknSzadN07dOn8ZSHgAAMCZVtXRpXWGD1hXWa11hvWrbevq1hwX46KTMKK2YGq0VU6OVHhXI5xoAAEYQISIwCTR29Oorj2zVtpIm+XrZ9dtL5+qC+UlWlwUAAOBR3dKtjQcbtPFggzYcbFBJQ2e/dj9vu5ZkROqkzGitnBqtWYmh8rITGgIAMFoIEYEJrqShQ1c/vEXF9R0K9ffW/V9epGVToqwuCwAATHK1rd3acDg03HiwUcX1Hf3a7TZpTnK4Vk7tm224MDWCLVgAALAQISIwge0sa9Z1f9+iho5eJYUH6O/XLNa0uBCrywIAAJNQbVu3Nh5s9Mw2PFg3MDTMTgrTsilRWj4lSovSIxTi72NRtQAA4KMIEYEJ6o29Nfrmv7ar2+HW7MRQPXz1YsWGssE4AAAYHXVtPdpU3KANRX2hYdFHQkObTZqdGKplGVFanhmlRemRCgsgNAQAYKwiRAQmoEc2HNIdL+bJbaSTs2L0pysWKtiP/7sDAICRU9ncpS2HGrWpuFFbiht1oLa9X7vNJs2MD9XyzCgtmxKlJRmEhgAAjCekCsAEYozR717P15/eLpIkXb44RT+9MFs+XnaLKwMAABOJMUZFdR3acqgvMNxU3KiK5q4B/WYmhGrZlEgtPxwahgf6WlAtAAAYDoSIwAThchvd9vxu/WtzmSTp22dk6ZunTpXNxqmFAADg03G5jfZVtXpmGW451KiGjt5+fbzsNs1ODNWS9EgtzojUkvRIRQQRGgIAMFEQIgITQLfDpW89sVOv5lXLbpN+duEcfXFpqtVlAQCAcarb4VJueYtnefL2kia19zj79fHztmt+SriWZERqSUakFqRGsH0KAAATGO/ywDjX1u3QDY9s04aDDfL1suv3l8/X2XMSrC4LAACMI23dDm0raTq8PLlJO8ub1et09+sT4uetRekRnlmGc5LD5OftZVHFAABgtBEiAuNYfXuPrn54s/ZUtCrI10sPfHmRTpoabXVZAABgjKts7tLWkiZtL2nS1pJG7a1sldv07xMd7KclGRGe5ckz4kPlZWebFAAAJitCRGCcKmvs1JV/26RDDZ2KCvLV369ZojnJYVaXBQAAxhiny619VW3aVtKorSVN2lbSpKqW7gH9UiMDtTg9si84zIhSelQgeysDAAAPQkRgHDpQ06YrHtyk2rYeJYUH6NHrlmhKTLDVZQEAgDGgpcuhHaV9YeG2kibtLGtWZ6+rXx8vu02zEkKVkxahRekRWpQWqfgwf4sqBgAA4wEhIjDO7Klo0ZV/26SmToemx4XokeuWKC6UD/0AAExGxhiVNnZq66EmbStt0rZDTSqobZP5yNLkUH9vLUyL0KK0CC1Mi9D8lHAF+vKrAAAAOH58cgDGkW0lTbr64c1q63ZqXnKY/nHtEoUH+lpdFgAAGCU9Tpf2VLR69jLcVtKs+vaeAf3SowKVkxbpmWk4NSZYdvYzBAAAnwIhIjBOrC+q1/X/2KrOXpcWp0fooasXK8Tfx+qyAADACDHGqLKlWztKm7SjtFk7Spu0p7J1wKnJvl52zUkOU05ahHLSIrQwNUIxIX4WVQ0AACYqQkRgHHh7f61ufGybepxurZoWrfuuzGEJEgAAE0xXr0u7K1qOhIZlTappHTjLMCrI17M0OSctQtlJYfL38bKgYgAAMJmQQgBj3Cu7q3TTEzvkcBmdPjNOf/ziAn5RAABgnDPGqKShUzvKPpxl2Kx9Va1yuvtvZuhtt2lmQqgWpIZrQWq4FqZGKDWSU5MBAMDoI0QExrBnt5fru0/vkttI585N0P99fr58vOxWlwUAAIaorduh3PKjZxk2q7Gjd0C/2BA/LUyN6AsM0yKUnRimAF/+eAgAAKxHiAiMUU9tKdMPns2VMdKlOcn61SVz5cWG6AAAjHlut1FRXbtnSfKO0mbl1ww8MdnXy67spFAtSI3wBIcJYf7MMgQAAGMSISIwBh0dIF65LE13nj+bExUBABij6tp6lFverF1lfTMMd5Y1q63bOaBfckTA4cAwXAtSIzQzIUR+3swyBAAA4wMhIjDGPLmlVD94Zrck6arlabrj/NnMSAAAYIzo6HFqT0WLdpU3a1dZi3aWNauiuWtAvwAfL81NDvOEhvNTwxUb4m9BxQAAAMODEBEYQ57YXKr/fbYvQLz6pHTdft4sAkQAACzicLlVUNOmXWUt2lXWrF3lzSqoadNHzj6RzSZNiw3WvORwzU0J18LUcE2PC5E3+xgDAIAJhBARGCP+ualU/++5vgDxmhXp+vG5BIgAAIwWY4zKGru08/Cy5F1lzdpT2aJuh3tA38Qwf81LCe/7lxyuOclhCvbjYzUAAJjY+LQDjAGPbyrRD5/bI0m6dkWGfnTuTAJEAABGUEN7j3LL+5Yj7zocHDZ1Ogb0C/H31rzkcM33hIZhig1lWTIAAJh8CBEBi/1zU6knQLxuZYZuO4cAEQCA4dTV69Keyr4lyR+GhmWNA/cx9PWya2ZiqOYnh3lmGmZEBXG4GQAAgAgRAUs9vbXMs4T5+pUZ+iEBIgAAn0qvs28fw9zylr4Tk8tbVFDTJtdHNzKUlBkTpHkph2cZJodrBqclAwAAfCxCRMAiL+6q1A+eyZXUd4gKASIAAEPjdLlVVNehXeXN2l3eotyKFu2ralWvc+A+hrEhfp4lyfNT+vYxDPX3saBqAACA8YkQEbDAq3uqdcuTO+U20heWpHIKMwAAn8DtNipu6OgLCw/PMsyrbFWXwzWgb1iAj+Ymh2lOUpjmJodpfkqE4sPYxxAAAODTIEQERtnb+2v1zX9tl8ttdPHCJP38wmwCRAAAjmKMUXlTlycszC1v0Z6KFrX1OAf0DfL1UnZS3x6GH4aGqZGBvLcCAAAMM0JEYBStK6zXVx/bJofL6Jy5CfrNJXPZrB0AMKkZY1TT2tNvSfLu8mOflOzvY9fsxCMzDOcmh2tKNAefAAAAjAZCRGCUbC5u1PX/2Kpep1unz4zTPZ+fL28vu9VlAQAwqurbe7S7vKVfaFjX1jOgn4+XTTMTQvvCwqS+PQynxQbz3gkAAGARQkRgFOSWN+vav29Rl8Ol1Vkx+tMVC+TDL0EAgAmupdOh3Iq+5ci7Dy9NrmzpHtDPy25TVlyI5iaFaU5ymOYlhysrPpiTkgEAAMYQQkRghBXWtumqhzarvcepZVMidd+XcvilCAAw4bT3OLWnouXILMOKFpU0dA7oZ7NJmTHBmnt4SfKc5HDNSghVgC/vjQAAAGMZISIwgiqau3Tl3zarqdOhuclhevCqxfySBAAY97p6Xdpb1XJkhmFFi4rq2mXMwL7pUYGakxzumWWYnRSmYD8+ggIAAIw3fIIDRkh9e4+ufHCTqlq6lRkTpL9fs4RfmgAA4063w6V9Va3aXdHiOSW5oKZN7mMEhknhAX2HnqQc3scwKUxhgT6jXzQAAACGHYkGMALauh26+uHNOljfoaTwAD12/VJFBvlaXRYAAIPqdbqVX92m3IrDh56U9wWGzmMkhnGhfppzOCjsW5YcpuhgPwuqBgAAwGggRASGWbfDpev/sVV7KloVFeSrR69booSwAKvLAgCgH4fLrQM17dr94cEnFS3aX9WmXpd7QN+oIF/P/oUfLkuOC/W3oGoAAABYhRARGEZOl1vf+OcObSpuVLCft/5x7RJNiQm2uiwAwCTnchsV1rYr9/CBJ7nlLdpX1aoe58DAMDzQ58jswqRwzU0OU0KYv2w2mwWVAwAAYKwgRASGiTFGtz67W2/uq5Gft10PXrVI2UlhVpcFAJhk3G6jg/UdR2YYlrcor7JVXQ7XgL4h/t6esPDD4DA5IoDAEAAAAAMQIgLD5O43CvT0tnJ52W364xcXatmUKKtLAgBMcMYYlTR0KreiRbvL+0LDvMpWtfc4B/QN8vVStmf/wr5lyamRgbLbCQwBAADwyQgRgWHw+KYS3bu2UJL08wuzdcasOIsrAgBMNMYYlTd1Kbe8xXPwye6KFrV1DwwMA3y8NDsxVHOSjyxLnhIdRGAIAACAEzakEDE9PV0lJSXHbHM4HPL29tY999yjP/7xj+rq6tKSJUv04IMPKipq4Iysc889Vxs2bFBISIjnWlFRkby8vIb4EgBrvbG3Rj96fo8k6VunT9PlS1ItrggAMN4ZY1TV0n34wJMjB580dzoG9PXztmtWYujhA0/6liVnxgTJ28tuQeUAAACYqIY8E3Hbtm3KysryfO1yuRQeHi5Jeuqpp/TII49o8+bNCgsL0ze+8Q3dcMMNeuaZZ475WL/73e90zTXXnFjlwBiwraRJ3/zXdrmNdPniFN182jSrSwIAjEM1rd2eoHD34cNP6tt7B/Tz8bJpZkJov4NPpsUFy4fAEAAAACNsyCFiYGCggoOPnDbrdB5ZQnPPPffo9ttvV2RkpCTppz/9qRISEtTY2Oi5drQPw0dgPCqqa9f1/9iibodbp86I1c8uzGYjegDAJ6pv79Hu8pZ+swxr23oG9PO225QVF3J4D8MwzU0KV1Z8sPy8WbUBAACA0TeseyJu3bpVK1as8HwdHR2t9PR07d69WyeffPKA/kMJEXt6etTTc+QDdmtr66eqFfg0atu6ddVDm9XU6dC85DD98YsLWDYGABigqaO3b3ZhRYtyy/v2Maxs6R7Qz26TsuJCPDMMs5PCNDMhVP4+BIYAAAAYG4YtRKyurpbL5VJ0dHS/67GxsWpoaBjQ32az6corr5S3t7dmz56tO+64Q4sXL/7Yx//lL3+pO++8c7jKBU5YZ69T1/59i8qbupQeFai/Xb1Ygb6cUQQAk11Ll0N7Ko7MMNxd0aKyxq4B/Ww2KTMm+PAehn2h4cyEUN5LAAAAMKYN+6dVY0y/JZ0ul+uYSzxfeOEF2e12ORwOPf7441qzZo127dqllJSUYz7urbfeqm9/+9uer1tbWz+2LzBSXG6jm/61U3sqWhUV5Kt/XLtE0cF+VpcFABhlbd0O5VW29i1LPryP4aGGzmP2zYgOOmoPwzDNTgpTsB+BIQAAAMaXYfsEGxISImOMmpqa+u1/WFdXp/j4+AH97fa+pZ8+Pj66+uqr9eSTT+r111/Xddddd8zH9/Pzk58fYQ2s9Yv/7tOb+2rk623X/V9epLSoIKtLAgCMsM5ep/ZWtnoOPsktb9bB+g4ZM7BvamTg4f0L+2YZzk4MU1iAz+gXDQAAAAyzYQsRg4KCNH36dK1fv17nnnuuJKmqqko1NTWaN2/eJ36/0+mUr6/vcJUDDLtHNxzS3z4oliTdfdk85aRFWFwRAGC4dTtc2lvV2u/gk8LadrmPERgmhQdozlFLkrMTwxQRxGcZAAAATExDDhE7OzvV3t7u+drlcnn++4YbbtCdd96plStXKjAwULfeequ+8pWvKDAwsN9jdHd3a+PGjTrllFMkSY888ohyc3O1Zs2aE3wZwMh6O79Wt7+YJ0n63prpOnduosUVAQA+rR6nS/nVbX1h4eFlyQU1bXIdIzGMC/XTnKRwz0nJc5LC2M4CAAAAk8qQQ8ScnJyPbbv55ptVUVGhrKwseXt764ILLtCvfvUrSVJeXp5uvvlmvfLKKzLG6Lvf/a7KysoUEBCgmTNn6vXXX1dsbOyJvxJghOyratU3Ht8ut5E+l5Osr5+SaXVJAIAhcrjcKqhpO2oPwxbtr26VwzUwMIwO9tXc5PB++xjGhvpbUDUAAAAwdtiMOdaOPmNfa2urwsLC1NLSotDQUKvLwQRV29qtC/+0TpUt3Vo+JUr/uHaJfL3tVpcFABiE0+VWYV17vxmG+6pa1et0D+gbEeijOcnh/U5Kjg/1P+ahcAAAAMBEM5R8jaMBgY/R1evS9Y9sVWVLt6bEBOmvX8ohQASAMcbtNjrU0KFd5c3aVdZ38EleZYu6HQMDwxB/78MzC8M9MwyTIwIIDAEAAIDjQIgIHIMxRt9/Jle55S2KCPTRw1cvVlggp2sCgNXq2nq0q6xZu8qbtbOsWbvKmtXa7RzQL9jPW9lJoYcPPumbaZgWFUhgCAAAAJwgQkTgGP70dqFe2lUpb7tNf/lSjtKigqwuCQAmnY4ep/ZUtHhmGe4sa1ZFc9eAfn7edmUf3r9wXnK45iSHKSMqSHY7gSEAAAAwXAgRgY94Pa9av3u9QJL0kwuytWxKlMUVAcDE53S5VVDTfjgw7JtlWFDTpo8elGyzSdNigzUvOVzzUsI1PyVc0+ND5OPFdhMAAADASCJEBI6yv7pV33pypyTpy8vT9MWlqdYWBAATkDFGFc1dnuXIH+5l2OVwDegbH+qv+Sl9geG8lL59DEP82V4CAAAAGG2EiMBhDe09uv4fW9XZ69JJmVH60bmzrC4JACaElk5Hvz0Md5U3q769d0C/YL++g08+nGE4Lzlc8WH+FlQMAAAA4KMIEQFJvU63vvb4dpU3dSktKlB/vmIhS+MA4AR0O1zaV9XqWZK8q7xFxfUdA/p5222amRCqeSl9+xguSA3XlOhg9jEEAAAAxihCREDSnS/laXNxo4L9vPXglxcpPNDX6pIAYMwzxqi8qUvbS5u0o7RZO0qbtLeqVQ6XGdA3LSrQM7twXkq4ZieGyt/Hy4KqAQAAAJwIQkRMek9sLtXjm0pls0m/v3y+psWFWF0SAIxJnb1O5Za3HBUaNqu+vWdAv8ggX81LDtP8lAjPTMOIIP44AwAAAIxnhIiY1HaUNunHL+RJkr5zRpZOmxlncUUAMDYYY3SooVPbS5q0o6wvNNxf3SbXR45L9rbbNDsxVAtSI7QgNVwLUiKUEhkgm41lyQAAAMBEQoiISauurUdfe2y7el1unTkrTl8/ZarVJQGAZdq6HX2zDEuatKOsb2lyU6djQL/4UH8tTOsLCxekhis7KYxlyQAAAMAkQIiIScnhcut//rld1a3dyowJ0l2XzWMzfwCThtttdLC+XdtLmj2zDPNr2mQ+spWhr7ddc5LCtCAlXAtSI7QwLVwJYQHWFA0AAADAUoSImJR+8d99noNU7rtykUL8fawuCQBGTEunQzvLmz2zDHeWNqm12zmgX3JEQN+y5JRwLUyL0MyEEPl5M8sQAAAAACEiJqHndpTr4XWHJEl3XTZPU2ODrS0IAIaRMUYH6zu0raRJ2w41aVtpkwpr2wf08/exa25yuBakhmvh4eAwNtTfgooBAAAAjAeEiJhU8ipbdOuzuyVJ3zx1qtbMjre4IgD4dLodLu2paNHWkiZtPdSk7aVNauzoHdAvPSqwb0lyat/S5OnxIfLxsltQMQAAAIDxiBARk0Zrt0Nff3y7uh1unTI9Rt86PcvqkgBgyOrbe/pmGZY0aeuhRu2paFWvy92vj5+3XfOS+5YkL0qL0MK0CEUG+VpUMQAAAICJgBARk4IxRt9/OlclDZ1KCg/QPZ+fLy8OUgEwxrndRkV17Z5ZhttKGnWooXNAv+hgPy1Ki1BOWoRy0iOUnRgmX29mGQIAAAAYPoSImBQeWndIr+ZVy8fLpj9fsVDhgczIATD2dPW6tKu82TPLcHtps1q6HAP6ZcUFKyctUovSIrQoPUKpkYGy2fjDCAAAAICRQ4iICW97aZN++d99kqTbzpmleSnh1hYEAIfVt/doS3GjthyeZZhX2Sqn2/Tr4+9j1/yUcC1Ki1ROeoQWpkQoLJAT5QEAAACMLkJETGhNHb36xuPb5XQbnTMnQV9enmZ1SQAmKWOMypu6tLm4UVsONWpzcaMO1ncM6BcX6tcXGB6eZTgzIZQDUAAAAABYjhARE5bbbXTLUztV2dKtjOgg/eqSOSz3AzBq3G6jwrp2bSpuPDzbsFFVLd39+ths0vS4EC1Oj9Si9L49DZPCA7hXAQAAABhzCBExYf3l3SK9k18nP2+7/vTFhQrxZ/kfgJHjcLmVV9mqzcUN2lzcpK0ljWru7L+fobfdpjnJYVqSHqklGZFalBbJ0mQAAAAA4wIhIiakDUUNuuv1fEnSTy6YrVmJoRZXBGCi6ep1aUdZk7YUN2nzoQZtL2lWl8PVr0+Aj5cWpoVr8eHQcEFKhAJ8vSyqGAAAAABOHCEiJpzatm7d9MQOuY10ycJkXbYoxeqSAEwALZ0ObS1p1OZDfcuTd1e0yOHqfwhKWICPFqdHaElGpBanRyo7KYz9DAEAAABMCISImFBcbqNvPbFTdW09yooL1k8vnM3eYgBOSHNnrzYVN2rjwQZtPNio/dWtMv0zQ8WH+mtxRqSWpEdoSUaUpsUGy27nngMAAABg4iFExITy13eLtL6oQYG+XvrzFQsV6MsQB3B8jic0zIgO0pL0yMPBYaRSIjkEBQAAAMDkQMKCCWNbSZPufqNAknTn+bM1NTbE4ooAjGXHExpOiw3WsilRWjqlb0/D2BB/a4oFAAAAAIsRImJCaO126OYndsjlNjpvXqI+l5NsdUkAxpjmzl5tLm7UxoN9weG+Y4SGU2ODtWxKZF9wmBGlmBA/a4oFAAAAgDGGEBHjnjFGP3xuj8qbupQcEaCfX5TN8kIAhIYAAAAAMIwIETHu/XtbuV7aVSkvu01/+MIChfr7WF0SAAt09Di1+VCjNhQ1aF1hvfZWDQwNM2OCtGxKlJZnRrE8GQAAAACGgBAR49rBunbd/mKeJOnbZ2RpYWqExRUBGC29Trd2lDZpfVGD1hfVa0dps5zu/qnhh6Hhh/saEhoCAAAAwIkhRMS41eN06aYndqiz16VlUyJ148mZVpcEYAS53EZ7K1u1vqhe64oatKW4UV0OV78+SeEBWjE1SiumRmv5lCjFhhIaAgAAAMBwIETEuPW71/K1p6JV4YE+uufzC+RlZx9EYCIxxqiorkMbiuq1rrBBGw42qKXL0a9PVJCvlmf2hYYrMqOVEhnAnqgAAAAAMAIIETEuvZNfqwfeL5Yk/eaSuYoPY7YRMBFUNnf1LU8urNf6ogZVt3b3aw/289bSjEidNDVaJ2VGaXpciOz8AQEAAAAARhwhIsadhvYefffpXEnSlcvSdObseIsrAnCi2rod2niwUR8cqNP7B+p1sL6jX7uvl105aRFaMTVKyzOjNTc5TD5edouqBQAAAIDJixAR44oxRv/vud2qb+9RVlywfnjOTKtLAjAELrdRbnmz3j9Qrw8O1Gt7aVO/w1DsNmlOcrhOyozSisxoLUqPkL+Pl4UVAwAAAAAkQkSMM89sr9BreTXy8bLp7svmEy4A40BZY2dfaFhYp3WFA/c1TIsK1Kpp0Vo5NUbLM6MUFuBjUaUAAAAAgI9DiIhxo7ypU3e8mCdJ+tbpWcpOCrO4IgDH0tbt0IaiBn1QWK/3D9Sr+CNLlEP8vbUiM1qrsqK1amqMUqMCLaoUAAAAAHC8CBExLrjdRt99epfae5zKSYvQjSdnWl0SgMOcLrdyK1r0wYF6vX+gTttLm+U6aomyl92mBSnhWjUtRiunRWtecpi82dcQAAAAAMYVQkSMCw+tK9bGg40K9PXS3ZfNkxensQKWqm7p1rsFtXonv07rCuvV2u3s154eFahV02K0alq0lmVGKdSfJcoAAAAAMJ4RImLMK6hp029ey5ck3XbOLKVFBVlcETD5OFxubT3UpHcKavVufp32V7f1aw/199aKqdGe4DAlkiXKAAAAADCRECJiTOt1uvWtJ3aq1+nWqTNi9YUlKVaXBEwalc1deie/Tu8W1GpdYYPae47MNrTZpHnJ4TpleoxWZ8VoXnI4M4QBAAAAYAIjRMSY9vu3CrS3qlURgT761SVzZLMRUgAjpdfp1tZDjXqnoE7v5NeqoKa9X3tUkK9WZ8XolOkxWjUtRpFBvhZVCgAAAAAYbYSIGLO2lTTqL+8USZJ+cdEcxYb4W1wRMPGUN3Xqnfw6vZNfp/VF9ersdXna7DZpfkq4Tpkeq1Omxyg7MUx2ZhsCAAAAwKREiIgxqavXpe88tUtuI128IElnz0mwuiRgQvhwtuHa/bV6p6BOhbX9ZxtGB/vp5KwYnTw9RqunRSs8kNmGAAAAAABCRIxRd72er0MNnYoP9dft58+2uhxgXGto79E7+XVau79W7xXUqe2ovQ297DYtTA3XyVkxOmV6rGYlhDLbEAAAAAAwACEixpxtJY3627piSdIvL56jsAAfiysCxhdjjPJr2vTWvlq9ta9GO8qaZcyR9uhgX50yPVafmR6rlVOjFRbI/8cAAAAAAIMjRMSY0u1w6Xv/zpUx0sULk/SZGbFWlwSMC90OlzYcbNDafbVau79WFc1d/dpnJYTqtJmxOm1mnOYmsbchAAAAAGBoCBExpvzfmwU6WNeh2BA/3X4uy5iBwdS0duvt/bV6c1+t1hXWq8tx5FAUP2+7Vk6N1qkzY3XqjFglhAVYWCkAAAAAYLwjRMSYsaO0SQ+8d1CS9POL5rDEEvgIt9toT2WL3jo823B3RUu/9vhQf506M1anzYjVSZnRCvD1sqhSAAAAAMBEQ4iIMaHH6dL3/50rt5EumJ+oM2bFWV0SMCb0Ot3acLBBr+dV6429Napt6+nXPi8lXKfNiNVpM/sORbHZWKYMAAAAABh+hIgYE/7w1gEdqG1XdLCv7jiPZcyY3Fq7HXonv06v51Xrnfw6tR91mnKgr5dWTYvWaTPjdMr0GMWG+FtYKQAAAABgsiBEhOV2l7for+/2LWP+2YXZigjytbgiYPRVt3Trjb3Ven1vjTYebJDDdeQ45ZgQP50+M05nzo7T8ilR8vdhmTIAAAAAYHQRIsJSvU63vvfvXXK5jc6Zm6CzshOsLgkYFcYYHaht9yxT3lXef3/DzJggnTErXmfOjtP85HBOUwYAAAAAWIoQEZa6790i7a9uU2SQr35yPsuYMbG53EbbS5s8weGhhk5Pm80mLUgJ15mz43XGrDhlxgRbWCkAAAAAAP0RIsIyRXXtundtoSTp9vNmKSrYz+KKgOHX43RpXWG9Xt1Trbf21aqho9fT5utt14rMKJ05O16nzYxlf0MAAAAAwJhFiAhLuN1G/+/Z3ep1uXVyVozOn5dodUnAsOnqdendgjq9sqdKa/fVqu2og1FC/b112sw4nTErTquzYhTsx20YAAAAADD28dsrLPH0tjJtKm5UgI+XfnZhtmw29nvD+Nbe49Ta/bV6dU+V3t5fpy6Hy9MWF+qns2bHa83seC3OiJSPl93CSgEAAAAAGDpCRIy6urYe/fzlfZKkb5+RpZTIQIsrAk5MS6dDb+6r0St7qvXegTr1Ot2etqTwAJ2dHa+z5yRoQQoHowAAAAAAxjdCRIy6n/xnr1q7ncpOCtU1K9KtLgcYkob2Hr2xt0b/3VOt9YX1crqNpy0jOqgvOMxOUHZSKDNsAQAAAAATBiEiRtXb+2v10q5K2W3Sry6eK2+WdWIcqGnt1mt51Xpld7U2FTfoqNxQ0+NCdFZ2vM6eE6/pcSEEhwAAAACACYkQEaOmo8ep257fI0m6bmWGspPCLK4I+Hi1bd16ZXe1/pNbqa0lTTJHBYfZSaE6OztBZ2XHKzMm2LoiAQAAAAAYJYSIGDV3v1GgiuYuJUcE6JYzsqwuBxigsaNXr+yp0n92VQ2YcbggNdyzVJl9PAEAAAAAkw0hIkbF7vIWPbyuWJL0swuzFejL0MPY0NLp0Gt51Xopt1LrixrkOio5nJ8SrnPnJuicuQlKCAuwsEoAAAAAAKxFkoMR53Ib3fb8brmNdP68RJ0yPdbqkjDJtXU79MbeGv0nt0rvH6iTw3UkOMxOCtW5cxN1zhxmHAIAAAAA8CFCRIy4f20u1a7yFoX4eeu2c2daXQ4mqY4ep97cV6OXc6v0TkGdep1uT9uM+JDDMw4TlREdZGGVAAAAAACMTYSIGFH17T36zav7JUnfXTNdsSH+FleEyaTb4dLa/bX6T26l1u6vVbfjSHCYGROkc+cm6rx5CZoaG2JhlQAAAAAAjH2EiBhRv/zvfrV2OzU7MVRfWpZmdTmYBFxuo/VF9Xp+R6Vey6tWe4/T05YWFahz5ybo3LmJmhEfIpvNZmGlAAAAAACMH4SIGDGbDjbome3lstn6DlPxshPYYGQYY5Rb3qIXdlbqpdxK1bX1eNqSwgM8wWF2UijBIQAAAAAAJ4AQESPC4XLrRy/skSRdvjhVC1IjLK4IE1FxfYde2FmhF3dW6mB9h+d6eKCPzpmToAsXJCknNUJ2AmwAAAAAAD4VQkSMiIfXFaugpl2RQb76/prpVpeDCaS2rVv/2VWlF3ZWaFd5i+e6v49dZ8yK14XzE7VqWox8ve0WVgkAAAAAwMRCiIhhV9XSpXvePCBJ+t+zZygiyNfiijDetXU79FpejV7YWaF1hfVym77rXnabVkyN1oXzE3Xm7HgF+3FLAwAAAABgJPAbN4bdT/+zV529Li1Ki9DnFiZbXQ7GKYfLrXfz6/Tczgq9ubdGPc4jJyvPTwnXhfMTdc7cRMWE+FlYJQAAAAAAkwMhIobV+wfq9N/d1fKy2/TTC7PZiw5DYoxRXmWrntlerhd3Vqqho9fTNiUmSBfOT9L58xKVHh1kYZUAAAAAAEw+hIgYNg6XW3e+tFeSdOWyNM1MCLW4IowXta3den5nhZ7ZVqH8mjbP9ehgX50/L0kXLUjiZGUAAAAAACxEiIhh88iGEhXW9h2mcssZWVaXgzGu2+HS63tr9My2cr1/oM6zz6Gvl11nzIrTJTlJWj0tRt5eHJACAAAAAIDVCBExLOrbe3TPGwWSpO+vma6wAB+LK8JYZIzR1pImPbOtXC/nVqmtx+lpy0mL0MULk3TunESFBTJ+AAAAAAAYSwgRMSx++2q+2nqcmpMUpksXpVhdDsaYssZOPbO9XM9ur1BpY6fnelJ4gC5emKSLFyYrg30OAQAAAAAYswgR8antKmvWU9vKJEl3nD9LXhymAkkdPU69vLtK/95ars2HGj3Xg3y9dPacBF2yMFlLMyI5fAcAAAAAgHGAEBGfitttdMdLeTJGunhBknLSIq0uCRYyxmh7abOe3lqml3ZVqqPXJUmy2aSVU6N18cIkrZkdr0Bfbj0AAAAAAIwn/CaPT+X5nRXaUdqsIF8v/eDsGVaXA4vUt/foue0VenJrmQpr2z3X06MCdemiFF28MEkJYQEWVggAAAAAAD4NQkScsPYep375yn5J0jdOnaa4UH+LK8JocrrceregTk9tLdNb+2rlPHy8sr+PXZ+dk6DPL0rRkoxI2WwsVwYAAAAAYLwjRMQJ++PaQtW19Sg9KlDXrky3uhyMkuL6Dj29tUzPbC9XTWuP5/r8lHBdtihF581LUIg/pysDAAAAADCRECLihJQ1duqhD4olSbedM0t+3l4WV4SR1Nnr1Cu7q/Xk1jJtLj5ySEpkkK8uWpCkyxalaHp8iIUVAgAAAACAkUSIiBPy61f3q9fl1oqpUTptZqzV5WCE7Klo0T83l+rFnZVq73FKkuw26eSsGF22KEWnzYyTr7fd4ioBAAAAAMBII0TEkG0radJ/cqtks0k//Ows9rybYDp6nHppV6X+ublUueUtnuupkYG6bFGyLslJ5pAUAAAAAAAmGUJEDIkxRj/9z15J0mU5KZqVGGpxRRgueZUt+uemUr1w1KxDHy+bzspO0BeWpGhZRpTsdgJjAAAAAAAmI0JEDMlLuVXaWdasQF8vfefMLKvLwafU0ePUf3Ir9c9Npdp11KzDjOggfWFJii5ZmKyoYD8LKwQAAAAAAGMBISKOW7fDpV+/sl+S9LWTMxUb6m9xRThReZUt+tfmUj2/o/+swzWz4/XFpalaPiWKZeoAAAAAAMCDEBHH7aF1xapo7lJCmL+uXzXF6nIwRJ29H+51WKZdZc2e6+lRgfrCklRdkpOsaGYdAgAAAACAYyBExHGpa+vRn98ukiR9/6zpCvD1srgiHK/C2jY9uqFEz26vUNtRsw7PnB2vK5akatkU9joEAAAAAACDI0TEcfm/NwvU3uPU3OQwXTAvyepy8AmcLrfe2FujRzeWaH1Rg+d62uFZh59j1iEAAAAAABgCQkR8ovzqNj2xuVSS9MPPzmTW2hhW29qtf20u0782l6q6tVuSZLdJp82M05XL0rRyajQ/PwAAAAAAMGSEiPhEP//vPrmNdNbseC2dEmV1OfgIY4w2Fzfq0Y0lenVPtZxuI0mKCvLV5UtS9MWlaUoKD7C4SgAAAAAAMJ4RImJQ6wrr9V5BnXy8bPrfs2dYXQ6O0t7j1PM7KvTYxhLtr27zXM9Ji9CXl6fprOx4+XmzdyUAAAAAAPj0CBHxsdxuo1+9sl+SdMXSNKVHB1lcEaQjB6U8s71C7YcPSgnw8dKFCxL1pWVpmp0YZnGFAAAAAABgohlSiJienq6SkpJjtjkcDnl79z3cxo0bde2112rt2rWKj48/Zv+GhgbdeOON2rRpk2w2m2666SZ95zvfGWL5GEn/3VOl3RUtCvL10jdOnWp1OZOa2230dn6tHl53SB8U1nuuZ0QH6UvL0vS5nGSFBfhYWCEAAAAAAJjIhjwTcdu2bcrKyvJ87XK5FB4eLkkqKirS//zP/6ioqEiFhYWDPs6VV16ppUuX6qmnnlJVVZVOOukkZWVl6bzzzhtqSRgBDpdbv30tX5J0w+pMTvK1SFu3Q09vLdc/NhxSSUOnpCMHpXx5eZpWZHJQCgAAAAAAGHlDDhEDAwMVHBzs+drpdHr+u7W1VZ/73Of0pS99SQEBH3+QQ0FBgbZu3aoXX3xRNptNiYmJuummm/TQQw8RIo4RT2wuVUlDp6KDfXX9qgyry5l0DtV36O/rD+nf28o9S5ZD/b11+ZJUXbksTSmRgRZXCAAAAAAAJpNh3RNxwYIFWrBgwSf227Bhg5YsWeJZ/ixJS5cu1b333juc5eAEdfQ49fu3DkiSbj5tmoL82DpzNBhjtK6wQQ+vK9ba/FqZvkOWlRkTpKtXZOiShUkK9OVnAQAAAAAARp8liURVVZXi4uL6XYuNjVVDQ8PHfk9PT496eno8X7e2to5YfZPdg+8Xq769V+lRgbp8SarV5Ux4Xb0uPbejQn9fX6yCmnbP9c9Mj9HVKzK0aipLlgEAAAAAgLUsCRGdTqfMh9OsDnO5XLLZPj4o+eUvf6k777xzpEub9Brae3T/e0WSpO+umS4fL7vFFU1cFc1demTDIT2xuUwtXQ5JUqCvly7NSdZVJ6VrSkzwJzwCAAAAAADA6LAkRIyMjNTmzZv7Xaurq/vYk5wl6dZbb9W3v/1tz9etra1KSUkZsRonq3vXFqqj16U5SWH6bHaC1eVMOMYYbStp0kPrivVaXo1c7r4wPSUyQFctT9eli1I4ZRkAAAAAAIw5loSIOTk5uvPOO+V2u2W39810W79+vZYvX/6x3+Pn5yc/P04IHkmlDZ16fFOJJOl/z57BEtph5HS59VpejR54/6B2ljV7ri+fEqVrVqTrtJlx8uJ/bwAAAAAAMEYNOUTs7OxUe/uRfdtcLteQn3TJkiVKSEjQr3/9a/3gBz/QoUOH9Oc//1nPPvvskB8Lw+fuN/LlcBmtmhatFVOjrS5nQujoceqprWV6aF2xyhq7JEm+3nZdND9JV69I18yEUIsrBAAAAAAA+GRDDhFzcnJO6Iny8vJ0880365VXXpGPj4+effZZXXvttbr77rsVERGh3/3udyf82Pj08qvb9MKuSknSD86aYXE1419ta7f+vv6QHttYotZupyQpItBHVy5L05XL0xUTwqxaAAAAAAAwftjMR084GSdaW1sVFhamlpYWhYYym+vTuvHRbXo1r1qfnROvP19BmHui8qvb9MD7B/XCzgo5XH3/18qIDtK1KzP0uYXJCvD1srhCAAAAAACAPkPJ1yzZExFjy+7yFr2aVy2bTbrl9Cyryxl3jDH6oLBeD7xfrPcK6jzXF6dH6PpVU3Q6+x0CAAAAAIBxjhARuuuNfEnSRfOTNC0uxOJqxo9ep1sv7arUA+8f1P7qNkmS3SadnZ2g61dlaEFqhMUVAgAAAAAADA9CxElu66FGvZNfJy+7TTefPs3qcsaFtm6HHt9UqofXFaumtUeSFOjrpcsWpei6lRlKiQy0uEIAAAAAAIDhRYg4yd31eoEk6bJFyUqLCrK4mrGtrq1HD68r1qMbS9R2+LCU2BA/Xb0iXVcsSVNYoI/FFQIAAAAAAIwMQsRJbH1hvTYcbJCvl13fOJVZiB+ntKFT979fpKe2lqvX6ZYkTY0N1ldXT9EF85Pk6223uEIAAAAAAICRRYg4SRlj9LvX+/ZC/OLSVCWFB1hc0dizt7JVf323SP/JrZT78Bnm81PC9fVTMnX6zDjZOSwFAAAAAABMEoSIk9Tb+bXaXtosfx+7vv6ZTKvLGTOMMdpyqEl/eadQb+cfOWn55KwYfe2UTC3NiJTNRngIAAAAAAAmF0LEScjtNp69EK86KV2xIf4WV2Q9t9to7f5a/eXdIm0raZLUd9LyOXMT9dXVU5SdFGZxhQAAAAAAANYhRJyEXsurVl5lq4L9vHXj6sk9C9HhcuulXZX667tFKqhplyT5ett1aU6yblg9hcNmAAAAAAAARIg46bjcRne/0TcL8dqVGYoI8rW4Imv0OF16emu5/vJOkSqauyRJIX7e+tLyNF2zgtmZAAAAAAAARyNEnGT+u7tKB2rbFervretWZlhdzqjr6nXpiS2luu/dg6pu7ZYkRQf76rqVU3TFslSF+vtYXCEAAAAAAMDYQ4g4ibjdRveuPSBJun7VFIUFTJ7ArKPHqcc2luiB9w+qvr1XkhQf6q8bT56iy5ekyt/Hy+IKAQAAAAAAxi5CxEnklT3VKqhpV4i/t646Kd3qckZFa7dDj6w/pL99UKymTockKTkiQF87JVOfy0mWnzfhIQAAAAAAwCchRJwkjp6FeO2KjAk/C7G5s1cPfVCsh9cfUlu3U5KUER2kr5+SqQsXJMnHy25xhQAAAAAAAOMHIeIk8freau2vblOIn7euXTFx90Ksb+/RA+8f1GMbStTR65IkTYsN1jdOnapz5ybKy26zuEIAAAAAAIDxhxBxEnC7jX7/VqEk6eoV6QoLnHizEGtau3Xfuwf1z80l6na4JUkzE0J106lTtWZ2vOyEhwAAAAAAACeMEHESeHNfjfZVtSrYb+KdyFzT2q0/v12of20pU6+zLzyclxymb546TafNjJXNRngIAAAAAADwaREiTnDGGP3+rb69EK86KU3hgb4WVzQ8atu69Zd3ivT4plJPeLg4PULfPHWaVk2LJjwEAAAAAAAYRoSIE9xb+2qVV9mqQF8vXb9yitXlfGp1bT26790iPbbpyLLlxekRuuX0LC3PjCI8BAAAAAAAGAGEiBOYMUZ/OHwi85eXpysiaPzOQmxo79H97x3UIxtK1OXoOzBlYWq4bjkjSyunMvMQAAAAAABgJBEiTmDv5Ncpt7xFAT5e+sqq8bkXYlNHr+5//6D+sf6QOg+ftjwvJVy3nD5NJ2fFEB4CAAAAAACMAkLECeroWYhXLk9TVLCfxRUNTXNnrx58v1gPrytWx+HwcE5SmG45Y5o+M50DUwAAAAAAAEYTIeIEtfFgo3aUNsvP266vrBo/eyG2dDn0tw+K9fAHxWrrcUqSZiWE6pYzsnQ6py0DAAAAAABYghBxgvrzO4WSpMsWpSgmZOzPQuzsderhdYd037tFau3uCw9nxIfoW6dnac3sOMJDAAAAAAAACxEiTkC55c16/0C9vOw23bB6bM9C7HG69MTmMt27tlD17T2SpKy4YH3r9CydNTtedjvhIQAAAAAAgNUIESegP79dJEm6YH6iUiIDLa7m2Jwut57bUaF73jygiuYuSVJqZKC+fUaWzpuXKC/CQwAAAAAAgDGDEHGCOVDTplfzqmWzSV8/JdPqcgYwxuiVPdW66/V8FdV1SJJiQ/x002nTdNmiFPl62y2uEAAAAAAAAB9FiDjB/OXdvlmIa2bFa2psiMXVHGGM0XsH6vW71/K1u6JFkhQe6KOvnZypLy9PV4Cvl8UVAgAAAAAA4OMQIk4gZY2demFnpSTp658ZO7MQtx5q1G9ey9fm4kZJUpCvl65bNUXXr8pQqL+PxdUBAAAAAADgkxAiTiD3v3dQLrfRqmnRmpscbnU5yqts0V2vF2jt/lpJkq+3XVcuS9PXT8lUVPDYPzEaAAAAAAAAfQgRJ4jatm49ubVMkvQ/n5lqaS1ljZ367Wv5enFX36xIL7tNly1K1jdPnabE8ABLawMAAAAAAMDQESJOEH/7oFi9TrcWpoZraUakJTU0dvTq3rUH9NjGEjlcRpJ07twEffuMLE2JCbakJgAAAAAAAHx6hIgTQEuXQ49tKJHUNwvRZrON6vN39br00Lpi/fWdIrX1OCVJK6dG63/PnqHspLBRrQUAAAAAAADDjxBxAnh8U4k6el2aHheiU2fEjtrzutxG/95Wpv9744CqW7slSTMTQnXr2TO0Oitm1OoAAAAAAADAyCJEHOd6nC49vO6QJOmG1VNGZRaiMUZr99fqV6/s14HadklSUniAvrsmSxfMS5LdProzIQEAAAAAADCyCBHHuRd2VKqurUfxof46b17iiD/fjtIm/fKV/dpc3ChJCgvw0Tc+M1VXLk+Tv4/XiD8/AAAAAAAARh8h4jjmdhvd//5BSdJ1KzPk620fsecqru/Qb1/br//urpYk+Xrbdc2KdH395KkKC/QZsecFAAAAAACA9QgRx7G1+2tVWNuuED9vXb4kZUSeo7GjV79/s0CPbyqV021ks0mXLEzWt8/IUmJ4wIg8JwAAAAAAAMYWQsRx7P73+mYhfnFZqkL8h3c2YI/TpUfWl+gPaw+orbvvxOXPTI/RD86eoRnxocP6XAAAAAAAABjbCBHHqR2lTdp8qFE+XjZduyJj2B7XGKNX91Trl6/sV2ljpyRpVkKobjtnpk6aGj1szwMAAAAAAIDxgxBxnPpwFuIF85MUF+o/LI+5q6xZP3t5r7YcapIkxYb46btrpuuShcny4sRlAAAAAACASYsQcRw6VN+hV/P6Dji5YfWUT/14lc1d+u1r+XpuR4Ukyd/HrhtWZ+qrq6coyI8hAgAAAAAAMNmREI1DD35wUMb07VGYFRdywo/T0ePUfe8W6f73D6rb4ZYkXbwgSd9dM51DUwAAAAAAAOBBiDjO1Lf36Omt5ZKkG1ZnntBjuNxGz2wr129fz1ddW48kaUl6pG47d6bmJocPV6kAAAAAAACYIAgRx5lHN5Sox+nWvOQwLZsSOeTvX19Yr5++vE/7qlolSamRgfp/n52hNbPjZbOx7yEAAAAAAAAGIkQcR7odLj22sUSS9JXVU4YU+pU1durnL+/z7KUY4u+tm0+bpiuXp8nP22tE6gUAAAAAAMDEQIg4jry4q1INHb1KDPPXWbPjj+t7Onud+ss7RbrvvYPqdbrlZbfpiqWp+tbpWYoM8h3higEAAAAAADARECKOE8YYPfRBsSTpqpPS5e1l/8T+L+VW6Zf/3aeqlm5J0kmZUbr9vNmaHn/ih7EAAAAAAABg8iFEHCfWFzVof3WbAn29dPni1EH77qlo0U9e2qvNhxolSUnhAbrtnJk6K5t9DwEAAAAAADB0hIjjxIezED+Xk6ywQJ9j9mns6NXvXs/XvzaXyhjJ38eur58yVTesniJ/H/Y9BAAAAAAAwIkhRBwHDta16639tZKka1ZkDGh3utx6bGOJ7n6jQK3dTknSefMSdevZM5QYHjCqtQIAAAAAAGDiIUQcB/6+/pAk6bQZscqIDurXtq6wXne+lKeCmnZJ0syEUN1x3iwtnRI12mUCAAAAAABggiJEHONaOh16emu5JOm6lUdmIZY1durnL+/Tq3nVkqSIQB99d810Xb44VV529j0EAAAAAADA8CFEHOOe2FKqLodLM+JDtDwzSt0Olx5476D++HahepxuedltunJZmm45Petj90oEAAAAAAAAPg1CxDHM6XLrH4eXMl+7MkPvFNTpjhfzVNLQKUlaNiVSd56frenxIRZWCQAAAAAAgImOEHEMezWvWpUt3ZKkl3Or9G5BnSQpNsRPt507S+fNTZDNxtJlAAAAAAAAjCxCxDHsL+8Uef773YI6edttunZlhm46bZqC/fjRAQAAAAAAYHSQRI1RO8ualVfZ6vl6+ZQo/eSC2ZoWx9JlAAAAAAAAjC5CxDGquqXL899/+MICli4DAAAAAADAMoSIY9Sa2fF64X9WaGpssIJYugwAAAAAAAALkU6NUTabTfNSwq0uAwAAAAAAAJDd6gIAAAAAAAAAjG2EiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAGRYgIAAAAAAAAYFCEiAAAAAAAAAAG5W11ASfKGCNJam1ttbgSAAAAAAAAYPz5MFf7MGcbzLgNEdva2iRJKSkpFlcCAAAAAAAAjF9tbW0KCwsbtI/NHE/UOAa53W5VVlYqJCRENpvN6nJGRGtrq1JSUlRWVqbQ0FCry8EYx3jBUDFmMFSMGQwVYwZDxZjBUDFmMFSMGQzVRB8zxhi1tbUpMTFRdvvgux6O25mIdrtdycnJVpcxKkJDQyfkQMXIYLxgqBgzGCrGDIaKMYOhYsxgqBgzGCrGDIZqIo+ZT5qB+CEOVgEAAAAAAAAwKEJEAAAAAAAAAIMiRBzD/Pz8dPvtt8vPz8/qUjAOMF4wVIwZDBVjBkPFmMFQMWYwVIwZDBVjBkPFmDli3B6sAgAAAAAAAGB0MBMRAAAAAAAAwKAIEQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAMihBxBKWnp8tmsx3zn9Pp9PTbuHGjZs2aperq6o99rIaGBl166aVKTU1VWlqa7rrrrn7tb775pubNm6fU1FQtWrRI27dvH7HXhZFzPGPmnnvu0dSpU5WUlKSLLrpIDQ0NAx7ngQceUHp6er9/UVFRmjNnjiSpvr5eNptNaWlpnvZbbrllVF8rhsdwjRlJOvfccxUVFdVv3LhcLk8795mJYTjHzNNPP61FixYpIyNDM2fO1FNPPdWvPTg4WElJSZ7xdOmll47468Po6Orq0g033KC0tDQlJyfr+9//vo51Vt+OHTu0bNkypaWladasWXrjjTf6tR/vWMP4dzxjxuFw6Cc/+YnmzJmjlJQUrVq1Sjt37vS0b926VV5eXv3epz76mRgTx/HeZz7pvYb7zORxPGPmuuuuG/B7UlBQkL75zW9Kkv7973/Lz8+vX/uTTz5pxcvBKDDG6JFHHtHy5cs/tg+fZT7CYMSkpaWZbdu2mba2Ns+/5uZmI8k4HA5TWFho1qxZY6ZOnWokmaqqqo99rLPPPtvccccdxu12m4qKCpOWlmZefPFFY4wxxcXFJi4uzuzatcsYY8zjjz9ukpKSTFdX16i8TgyfTxozTz75pFmwYIFpaGgwTqfT3Hjjjebiiy8+rsdes2aNeeCBB4wxxtTV1RmbzWZcLtdIvhyMguEcM+ecc4556KGHjtnGfWbiGM4xc+2115ry8nJjjDFbt2414eHhZvfu3Z72oKAgc/DgwVF5XRhdX/va18x1111nHA6HaW5uNosWLTJ/+MMf+vVpbW01SUlJ5o033jDGGPPOO++YsLAwz+edT/OehvHneMbMnj17zI9+9CPT3t5ujDHmr3/9q0lOTja9vb3GGGO2bNliUlNTR712WON4xowxg7/XcJ+ZXI53zBytra3NxMfHm/379xtjjHn66afN6tWrR6NcWOyVV14x2dnZJjMz00yfPv2YffgsMxAh4ghKS0sz+/bt63fN4XB4flHbvn27eeCBB0xXV9egIWJ+fr6JiYkxDofDc+2uu+4yF154oTHGmFtvvdV861vf6vc9c+bMMc8///wwvyKMtE8aM8uXL+/3c62rqzPe3t6moaFh0Md97733zLRp0zxjqK6uzoSGhg7/C8CoG84xc84555hnn332mM/DfWbiGKn7jDHGXHTRReZPf/qT5+ugoCDT2Ng4fMVjTGhrazOBgYH9xsQzzzxj5s+f36/ffffd5/ms8qHzzjvP3HPPPcYY86nGGsaX4x0zxxIREWHy8vKMMX0h4ty5c0esTowdQxkzg73XcJ+ZPE70PvOTn/zEXHPNNZ6vn376aXP++eePWJ0YO/7973+bl19+2bz99tsfGyLyWWYgljNbaMGCBbr++uvl7+8/aL8NGzZoyZIl8vb29lxbunSpZ3nHhg0btGLFin7fc3Q7Jo6tW7f2+1lHR0crPT1du3fvHvT7fvrTn+q2227rN4bCw8NHqkyMIUMdMx83LrjPTB4nep+RpLq6OoWFhXm+ttvt/b7GxLBt2zZlZGQoMjLSc23p0qXas2dPvy0QBrtvOJ3OTzXWML4c75j5qM7OTnV2dva7j/D5ZXIYypj5uPca7jOTy4ncZ9rb23XvvffqRz/6Ub/r3Gcmh0suuUSf/exnB+3DZ5mBCBHHgaqqKsXFxfW7Fhsb61lr/0ntmBiqq6vlcrkUHR3d7/on/axzc3O1e/duXX755QMeLz09XbNmzdItt9yilpaWEakb1hnqmLHZbLryyiuVnp6uc845R1u2bPG0cZ+ZHE70PiNJL7zwggoKCnTeeed5rtlsNmVmZiorK0vXXXedKisrR6RujK6Pux84nc5+7yWD3Tfq6+tPeKxh/DneMfNRP/zhD3XKKacoKSnJc23r1q1KS0vT3Llzdeedd6qnp2fE6oZ1hjJmPu69hvvM5HIi95mHH35YK1euVEZGRr/rzz//vFJTU5WTk6N77733mHtxYnLgs8xAhIjjgNPpHHDjcrlcstlsx9WOiWWoP+sHH3xQX/3qV+Xr6+u5Fh0dre7ubh06dEhvv/22ysvLdc0114xYzbDW8Y6ZF154QeXl5Tpw4IAuvfRSrVmzRmVlZZK4z0w2Q/1Z33PPPfra176mF154QaGhoZ7rTU1NKi4u1pYtWxQYGKjzzjuPD+ITwMfdDyT1GyeD3Tc+PMSH+8rkcLxj5kMdHR266qqr9O677+rRRx/1XM/JyVFHR4dKSkr0wgsvaO3atbr11ltHtnhYYihj5uPea7jPTC5Dvc9Ifb8n3XTTTf2uXXLJJWppaVFpaan+/ve/669//avuvffekSkaYx6fZQYiRBwHIiMjVV9f3+9aXV2d4uPjj6sdE0NISIiMMWpqaup3fbCfdW9vr/75z3/qiiuuGND24Y0tLi5Of/zjH/XSSy/x1/wJZqhjxm7ve0vw8fHR1VdfraVLl+r111+XxH1mshjqmOns7NRFF12kp556SuvXr9eyZcv6tX84psLCwvT73/9e+fn5Onjw4Mi9AIyKj7sf+Pv791tSONh9IyIiYsjvaRi/jnfMSFJRUZEWL14sHx8fffDBB4qJifG0Hf1LWUZGhn7zm9/o6aefHtniYYmhjJmPe6/hPjO5DGXMSH2zmhsaGnTyySf3u370fWbOnDn68Y9/zH1mEuOzzECEiONATk6ONm3aJLfb7bm2fv16zzHkOTk5Wr9+fb/vObodE0NQUJCmT5/e72ddVVWlmpoazZs375jf89///leJiYmaNm3aoI/tdDrl5eUlLy+vYa0Z1jqRMXM0p9PpmcHKfWZyGOqY+fznP6+wsDC99957Sk9PH/Sx3W633G53v1nRGJ8WLlyo/Pz8fh+a169fr6VLl3p+mZcGv2982vsTxpfjHTPNzc069dRTdcstt+jBBx9UYGDgoI979PsUJpbjHTMfdfR7DfeZyWWoY+axxx7TxRdf/IkzxrjPTG58ljmG0TvDZfJJS0sz27ZtM21tbZ5/zc3NnhMwj6ZBTmd2u91m3rx55he/+IVxuVymqKjIpKammq1btxpj+k6qi46ONrm5ucbtdpv777/fLFiwwLjd7hF/jRhenzRm7r77brNo0SLT1NRkenp6zFVXXTXgxNyjffWrXz1m+65du0x5ebkxxpjm5mZz0UUXmS9/+csj9rowcoZrzHR1dZm3337b8/U//vEPExsba2pqaowx3GcmkuEaMwUFBSY4ONj09PQc83kKCwtNfn6+McaY7u5u8/Wvf92sXr16RF8bRs/5559vbrzxRuNwOExdXZ2ZM2eOee655/r1KSsrM+Hh4eatt94yxhjz8ssvm7S0NNPe3m6MMUN+T8P4djxj5v777zdnnnnmxz7Gxo0bPSdeVlVVmRUrVpgf//jHI1k2LHQ8Y+aT3mu4z0wuxzNmPjR9+vR+p+p+6N133/W8Tx04cMBMnz7dPPTQQyNZNiw22OnMfJYZiBBxBKWlpRlJx/z3SSHinj17zGmnnWZ6e3uNMcYUFRWZk08+2URHR5tp06aZp556qt/3P/LIIyY1NdXExsaaNWvWmJKSkpF/gRh2nzRmXC6X+c53vmNiYmJMQkKCufHGG013d7cxZuCYMcaY+fPnm0ceeWTA87z00ksmJSXFJCUlmczMTPO9733PcyPE+DJcY6azs9Pk5OSY2NhYk5aWZs466yyzc+fOfs/FfWZiGK4x8/LLLxsfHx+TlpbW79+1115rjDFm8+bNJjMz0yQmJpqMjAxz/fXXm9raWitfOoZRXV2dOf/88010dLRJS0sz9957rzHGmEcffdTcdNNNnn6vvvqqmT59uomJiTHLly83ubm5nrbBxhomnuMZM9/73vdMSEjIgPvK/fffb4zpCxkTEhJMSkqKycrKMj//+c8HfKbGxHE8Y+aT3mu4z0wux/ve1NTUZCSZ0tLSAY9x++23m9jYWJOSkmJmz55t7rvvvlGrH9b4aIjIZ5nB2Yxhh3MAAAAAAAAAH489EQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAMihARAAAAAAAAwKAIEQEAAAAAAAAM6v8DH/Vg5bFwkHQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(x.iloc[2000:,0], y.iloc[2000:], label = 'real')\n",
    "plt.plot(x.iloc[2000:,0], pred, label = 'prdict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(tf.keras.layers.Dense(32, input_shape=(2,)))\n",
    "model_2.add(tf.keras.layers.Dense(64, activation='sigmoid'))\n",
    "model_2.add(tf.keras.layers.Dense(128, activation='sigmoid'))\n",
    "model_2.add(tf.keras.layers.Dense(64, activation='sigmoid'))\n",
    "model_2.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model_2.compile(loss = 'mse', optimizer = adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 32)                96        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,849\n",
      "Trainable params: 18,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.7915\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1267\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1231\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1113\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.1022\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1015\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.1058\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1018\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1020\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1036\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 839us/step - loss: 0.1008\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 800us/step - loss: 0.1038\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 839us/step - loss: 0.1005\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0987\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1008\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1009\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.1061\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 767us/step - loss: 0.1052\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1056\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1000\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1022\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1016\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1047\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0999\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0990\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1019\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1003\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0980\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1040\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0983\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0967\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0980\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 762us/step - loss: 0.0983\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0966\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1005\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0981\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0948\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0946\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0956\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0930\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0868\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.0783\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0705\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0618\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0397\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0181\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 770us/step - loss: 0.0059\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.0016\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0012\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0010\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.2620e-04\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.4319e-04\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.4212e-04\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.4409e-04\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.6720e-04\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.9287e-04\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.1028e-04\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.6207e-04\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 741us/step - loss: 2.1955e-04\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.4367e-04\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 754us/step - loss: 2.7294e-04\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3464e-04\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.2979e-04\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.8070e-04\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.4660e-04\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.4893e-05\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.0832e-04\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.1905e-04\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 8.6685e-05\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.6513e-04\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.1040e-04\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.5777e-04\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.1520e-04\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 771us/step - loss: 1.8589e-04\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.1307e-04\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.4550e-04\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.1892e-04\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.6762e-04\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 2.3130e-04\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.5885e-04\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.2997e-04\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5411e-04\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.8236e-04\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.9094e-04\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.0656e-04\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.7158e-04\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 740us/step - loss: 9.6648e-04\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.6378e-04\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 4.4004e-04\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.6909e-04\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.7783e-04\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.6603e-04\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 756us/step - loss: 2.2071e-04\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.1410e-04\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.0331e-04\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.3759e-04\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.6423e-04\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.9659e-04\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 4.7134e-04\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.0896e-04\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.8459e-04\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.6563e-04\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.1324e-04\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.1231e-04\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.6434e-04\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.2304e-04\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.4382e-04\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 952us/step - loss: 0.0018\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 9.2124e-04\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.1022e-04\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.0213e-04\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0015\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.9173e-04\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.7348e-04\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.5744e-04\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.2136e-04\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3266e-04\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.6641e-04\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 839us/step - loss: 1.3614e-04\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.9820e-04\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.4470e-04\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 9.9618e-04\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.3371e-04\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5994e-04\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.1709e-04\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3321e-04\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 1.6244e-04\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.4868e-04\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.7725e-04\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 2.3820e-04\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.5082e-04\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.5958e-04\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0014\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.5082e-04\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.1226e-04\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2826e-04\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.3769e-05\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.9095e-04\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.5196e-04\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 3.6340e-04\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0019\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.7239e-04\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.5229e-04\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.4798e-04\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 1.4189e-04\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.2269e-04\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.5814e-04\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 7.6117e-04\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.2225e-04\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 839us/step - loss: 1.5095e-04\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.1021e-04\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 5.8024e-04\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.3358e-04\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0023\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0026\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.1464e-04\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.2060e-05\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.8923e-05\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.3648e-05\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 7.0993e-05\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.0633e-04\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 4.4115e-04\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.6603e-04\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.6343e-04\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 750us/step - loss: 8.7453e-05\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.8371e-05\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 766us/step - loss: 1.0478e-04\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2821e-04\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 903us/step - loss: 1.0328e-04\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.4036e-04\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.9194e-05\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.1431e-04\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.4371e-04\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5268e-04\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.1832e-04\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.2302e-04\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.9611e-04\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.4166e-04\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.9747e-04\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 5.9216e-04\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 771us/step - loss: 2.3313e-04\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.4719e-04\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.4270e-05\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 4.3918e-04\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.6091e-04\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.9897e-04\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.0920e-04\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.0635e-04\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.7421e-04\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 9.1740e-05\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.5629e-05\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 6.3718e-05\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 749us/step - loss: 1.4895e-04\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.3034e-04\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 757us/step - loss: 1.2380e-04\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.0375e-04\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.0489e-04\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.1874e-04\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.0117e-04\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.1295e-04\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.4240e-04\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 1.8001e-04\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 8.0178e-04\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.5662e-04\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 8.3801e-04\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.0020e-04\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.2671e-04\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.0060e-04\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.1960e-05\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.0350e-04\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 2.6891e-04\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 756us/step - loss: 3.2654e-04\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 4.2736e-04\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.0691e-04\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2714e-04\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.6362e-05\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.0543e-05\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.1791e-04\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 743us/step - loss: 3.6101e-04\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0011\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.0016\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.4096e-04\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 7.0909e-04\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.6807e-05\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 871us/step - loss: 1.0686e-04\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2141e-04\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.3129e-04\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.7592e-05\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.3266e-04\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.5383e-04\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 4.9039e-04\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.0208e-04\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2068e-04\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 4.1781e-04\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3718e-04\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 8.2404e-05\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.1818e-05\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3588e-05\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.2223e-05\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3702e-05\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.9153e-05\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.4921e-04\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2869e-04\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0042\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.0010\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 736us/step - loss: 3.7016e-04\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.5750e-05\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 767us/step - loss: 6.9361e-05\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.1629e-04\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 7.8642e-05\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3201e-05\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 3.2662e-05\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.1629e-05\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 755us/step - loss: 1.1529e-04\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.0262e-04\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2780e-04\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.7203e-04\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.4541e-04\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2949e-04\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5812e-04\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 4.5304e-05\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 5.4725e-05\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.9302e-05\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3776e-04\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0014\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.8795e-04\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 9.2072e-05\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 992us/step - loss: 6.7237e-05\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 6.1701e-05\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5037e-04\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 5.6117e-04\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.9641e-04\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 3.8090e-04\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.0013\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.1362e-04\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 4.0018e-05\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.5167e-05\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.7367e-05\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.2200e-05\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.3864e-05\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.2358e-05\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.3637e-05\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 5.3667e-05\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.8974e-04\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.3325e-04\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 3.2490e-04\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.8537e-04\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.4455e-04\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.7829e-04\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.6623e-04\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 7.3597e-05\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.6926e-04\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.7289e-04\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 727us/step - loss: 7.9918e-05\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.0391e-05\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.5183e-04\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 7.3861e-04\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 1.4652e-04\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2433e-04\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 741us/step - loss: 9.9718e-04\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.1565e-04\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.8264e-04\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5826e-04\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.2793e-04\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.9609e-04\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.0520e-04\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.1292e-04\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.1641e-04\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 896us/step - loss: 3.3566e-04\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 760us/step - loss: 2.8183e-04\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.2915e-04\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.7566e-04\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.0257e-05\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.9356e-05\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 745us/step - loss: 4.0474e-05\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5768e-04\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5273e-04\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.0838e-05\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.6239e-04\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 7.0387e-05\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5698e-04\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.0759e-04\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 1.3264e-04\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 5.5744e-04\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0018\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0018\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.0483e-04\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.7144e-05\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.7534e-05\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.8924e-05\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.7953e-05\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.2164e-05\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.4183e-05\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.9100e-05\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 3.6198e-05\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 4.7649e-05\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.4305e-05\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.5723e-05\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.7062e-05\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.0960e-05\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.0929e-04\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.7278e-05\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.2418e-05\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.6343e-04\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 791us/step - loss: 2.8237e-04\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 903us/step - loss: 1.1736e-04\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.8548e-05\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2547e-04\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 761us/step - loss: 0.0014\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0014\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.6277e-04\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.9750e-04\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.1572e-04\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.8850e-05\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 6.3652e-05\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.9970e-05\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 753us/step - loss: 4.7134e-05\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 9.1051e-05\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.1525e-04\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 743us/step - loss: 4.4283e-05\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.3590e-05\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.2371e-05\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.9168e-05\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 3.8693e-05\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 2.1941e-04\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.9492e-04\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 3.0252e-04\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.7072e-05\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2642e-04\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.7971e-04\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.0013\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0035\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.9175e-04\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.7780e-04\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.3755e-05\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 8.2335e-05\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.3925e-05\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 9.5491e-05\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 887us/step - loss: 4.5770e-05\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.1862e-05\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 740us/step - loss: 6.3553e-05\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.4932e-04\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.4736e-04\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.3209e-04\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.8924e-05\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 2.5942e-04\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.0144e-04\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.2512e-04\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.3647e-05\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.2500e-05\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.5263e-05\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.8531e-05\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5384e-04\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.6396e-04\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.4865e-04\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 8.2249e-05\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0018\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.2331e-04\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.7707e-04\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.6281e-04\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.2710e-04\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.4413e-05\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 6.6782e-05\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.8959e-05\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.4959e-05\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 6.1401e-05\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.3157e-05\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 871us/step - loss: 7.5027e-05\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 754us/step - loss: 2.9209e-05\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.4852e-05\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.0676e-05\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.4324e-04\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.8168e-04\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5009e-04\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.7975e-05\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 9.1037e-05\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.8975e-04\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.7629e-04\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.2682e-04\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.7122e-04\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.9031e-04\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.3190e-04\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5925e-04\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.6000e-05\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.5946e-04\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.1293e-04\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.0998e-04\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3139e-04\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.9082e-04\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.7281e-04\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.1408e-04\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3488e-04\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.3681e-05\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.7669e-05\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 743us/step - loss: 2.8666e-05\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 744us/step - loss: 9.0392e-05\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 933us/step - loss: 7.3234e-05\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 9.6077e-05\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.4545e-04\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.1178e-04\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.4702e-04\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 1.3187e-04\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3706e-04\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.1183e-04\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.4420e-04\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.4090e-05\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 789us/step - loss: 2.9696e-04\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0017\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 721us/step - loss: 2.9711e-04\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.1388e-05\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.4361e-05\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.9384e-04\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.0842e-04\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.9638e-05\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.2989e-04\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.1178e-04\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 2.9567e-04\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.1718e-04\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.5999e-04\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.1044e-04\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.3557e-05\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.1154e-05\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 887us/step - loss: 9.3662e-05\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 778us/step - loss: 8.3421e-05\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 726us/step - loss: 2.6692e-04\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 774us/step - loss: 4.5819e-04\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 823us/step - loss: 3.0649e-04\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.7411e-04\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.0387e-05\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.5405e-05\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.3753e-04\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.1275e-05\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 5.5901e-05\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.5198e-05\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 1.1180e-04\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.0802e-05\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.4560e-05\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.7009e-04\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.7398e-04\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 7.5878e-04\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 8.0951e-04\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 4.3333e-04\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 5.2906e-04\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.7274e-05\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 4.1672e-05\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 8.5882e-05\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.1683e-04\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 968us/step - loss: 5.2245e-05\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 2.8502e-05\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.3246e-05\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 3.8569e-05\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 6.4373e-05\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 9.8577e-05\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 742us/step - loss: 3.1771e-04\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.9637e-04\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 6.6233e-04\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.2090e-04\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 790us/step - loss: 1.0720e-04\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 2.2017e-04\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 758us/step - loss: 1.5994e-04\n"
     ]
    }
   ],
   "source": [
    "dnn = model_2.fit(x_tr, y_tr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b210170910>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dnn.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 613us/step\n"
     ]
    }
   ],
   "source": [
    "pred_2 = model_2.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = pred_2.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(x.iloc[2000:,0], y.iloc[2000:], label = 'real')\n",
    "plt.plot(x.iloc[2000:,0], pred_2, label = 'prdict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = 0, 0\n",
    "w = 0.5\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "from math import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xt(x, t):\n",
    "    return -2*beta*x[1] + np.exp(beta*x[1]) - np.exp(-beta*x[1]) + kb*x[1] - np.sign(v[i])*((ka-kb)/alfa)*(np.exp(-alfa*(np.sign(v[i])*(x[1]-uj)+2*u0))-np.exp(-2*alfa*u0)) + np.sign(v[i])*f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=128, activation=tf.nn.tanh)\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(units=128, activation=tf.nn.tanh)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.hidden_layer_1(inputs)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINN(2, 1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "ephoch = 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_tr, y_tr))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = PINN(2, 1)\n",
    "\n",
    "x_tr = tf.constant(x_tr, dtype=tf.float64)\n",
    "y_tr = tf.constant(y_tr, dtype=tf.float64)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "for epoch in tqdm(range(ephoch)):\n",
    "    for x_batch, y_batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss_value = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLIED DISPLACEMENT TIME HISTORY\n",
    "# dt = 0.001\n",
    "# t = np.arange(0, 3 + dt, dt)\n",
    "# a0 = 1\n",
    "# fr = 1\n",
    "# u = a0 * np.sin(2 * np.pi * fr * t[:len(t)])\n",
    "# v = 2 * np.pi * fr * a0 * np.cos(2 * np.pi * fr * t[:len(t)])\n",
    "# n = len(u)\n",
    "\n",
    "# uj_list = []\n",
    "\n",
    "# # Set the four model parameters\n",
    "# ka = 5.0\n",
    "# kb = 0.5\n",
    "# alfa = 5.0\n",
    "# beta = 1.0\n",
    "\n",
    "# # Compute the internal model parameters\n",
    "# u0 = -(1 / (2 * alfa)) * np.log(10 ** -20 / (ka - kb))\n",
    "# f0 = ((ka - kb) / (2 * alfa)) * (1 - np.exp(-2 * alfa * u0))\n",
    "\n",
    "# # Initialize the generalized force vector\n",
    "# f = np.zeros(n)\n",
    "\n",
    "# # CALCULATIONS AT EACH TIME STEP\n",
    "# for i in range(1, n):\n",
    "#     # Update the history variable\n",
    "#     uj = u[i-1] + 2*u0*np.sign(v[i]) + np.sign(v[i])*(1/alfa)*np.log(np.abs(np.sign(v[i])*(alfa/(ka-kb))*(-2*beta*u[i-1]+np.exp(beta*u[i-1])-np.exp(-beta*u[i-1])+kb*u[i-1]+np.sign(v[i])*((ka-kb)/alfa)*np.exp(-2*alfa*u0)+np.sign(v[i])*f0-f[i-1])))\n",
    "#     uj_list.append(uj)\n",
    "#     # Evaluate the generalized force at time t\n",
    "#     if (np.sign(v[i])*uj-2*u0 < np.sign(v[i])*u[i]) or (np.sign(v[i])*u[i] < np.sign(v[i])*uj):\n",
    "#         f[i] = -2*beta*u[i] + np.exp(beta*u[i]) - np.exp(-beta*u[i]) + kb*u[i] - np.sign(v[i])*((ka-kb)/alfa)*(np.exp(-alfa*(np.sign(v[i])*(u[i]-uj)+2*u0))-np.exp(-2*alfa*u0)) + np.sign(v[i])*f0\n",
    "#     else:\n",
    "#         f[i] = -2*beta*u[i] + np.exp(beta*u[i]) - np.exp(-beta*u[i]) + kb*u[i] + np.sign(v[i])*f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "\n",
    "f = -2*beta*u + sp.exp(beta*u) - sp.exp(-beta*u) + kb*u - sp.sign(v)*((ka-kb)/alfa)*(sp.exp(-alfa*(sp.sign(v)*(u-uj)+2*u0))-sp.exp(-2*alfa*u0)) + sp.sign(v)*f0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_df_du(u, v, beta, kb, ka, alfa, u0, f0, uj):\n",
    "    # Define the function inside the GradientTape context so that TensorFlow can track the operations on the tensor u\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(u)  # Ensure that TensorFlow is tracking operations on u\n",
    "        f = -2*beta*u + tf.exp(beta*u) - tf.exp(-beta*u) + kb*u - tf.sign(v)*((ka-kb)/alfa)*(tf.exp(-alfa*(tf.sign(v)*(u-uj)+2*u0))-tf.exp(-2*alfa*u0)) + tf.sign(v)*f0\n",
    "\n",
    "    # Compute the gradient of f with respect to u\n",
    "    df_du = tape.gradient(f, u)\n",
    "    df_du = tf.cast(df_du, dtype=tf.float32)\n",
    "    \n",
    "    return df_du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_true = tf.expand_dims(y_true, axis=-1)\n",
    "\n",
    "    u, v = tf.split(x_tr, 2, axis=-1)  # Assuming that x is passed as a function argument or is available in the scope\n",
    "\n",
    "    # Define the physical loss as the difference between the predicted derivative and the computed derivative\n",
    "    df_du = compute_df_du(u, v, beta, kb, ka, alfa, u0, f0, uj)\n",
    "    df_du = tf.expand_dims(df_du, axis=-1)\n",
    "    physics_loss = tf.reduce_mean(tf.square(y_pred - df_du))\n",
    "\n",
    "    # Define the data loss as the mean squared error\n",
    "    data_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "    return physics_loss + data_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss at step 0: 6.193304061889648\n",
      "Training loss at step 32: 6.474438667297363\n",
      "Training loss at step 64: 6.769858360290527\n",
      "Training loss at step 96: 7.076380252838135\n",
      "Training loss at step 128: 7.398453712463379\n",
      "Training loss at step 160: 7.7052764892578125\n",
      "Training loss at step 192: 7.937284469604492\n",
      "Training loss at step 224: 8.027162551879883\n",
      "Training loss at step 256: 7.81976318359375\n",
      "Training loss at step 288: 7.2004852294921875\n",
      "Training loss at step 320: 6.564018726348877\n",
      "Training loss at step 352: 6.181344985961914\n",
      "Training loss at step 384: 6.04113245010376\n",
      "Training loss at step 416: 6.0483598709106445\n",
      "Training loss at step 448: 6.13625431060791\n",
      "Training loss at step 480: 6.2344560623168945\n",
      "Training loss at step 512: 6.33372688293457\n",
      "Training loss at step 544: 6.4394402503967285\n",
      "Training loss at step 576: 6.605851650238037\n",
      "Training loss at step 608: 6.844889163970947\n",
      "Training loss at step 640: 7.134407997131348\n",
      "Training loss at step 672: 7.421065330505371\n",
      "Training loss at step 704: 7.633237361907959\n",
      "Training loss at step 736: 7.69038200378418\n",
      "Training loss at step 768: 7.352119445800781\n",
      "Training loss at step 800: 6.690366268157959\n",
      "Training loss at step 832: 6.120553970336914\n",
      "Training loss at step 864: 5.81783390045166\n",
      "Training loss at step 896: 5.725793361663818\n",
      "Training loss at step 928: 5.744071006774902\n",
      "Training loss at step 960: 5.782440185546875\n",
      "Training loss at step 992: 5.7964653968811035\n",
      "Training loss at step 1024: 5.801893711090088\n",
      "Training loss at step 1056: 5.819690704345703\n",
      "Training loss at step 1088: 5.877015590667725\n",
      "Training loss at step 1120: 5.994986534118652\n",
      "Training loss at step 1152: 6.1247944831848145\n",
      "Training loss at step 1184: 6.21414041519165\n",
      "Training loss at step 1216: 6.20714807510376\n",
      "Training loss at step 1248: 6.031344413757324\n",
      "Training loss at step 1280: 5.541727066040039\n",
      "Training loss at step 1312: 5.023393630981445\n",
      "Training loss at step 1344: 4.778149604797363\n",
      "Training loss at step 1376: 4.816050052642822\n",
      "Training loss at step 1408: 4.978254318237305\n",
      "Training loss at step 1440: 5.160399913787842\n",
      "Training loss at step 1472: 5.34452486038208\n",
      "Training loss at step 1504: 5.538171768188477\n",
      "Training loss at step 1536: 5.768362045288086\n",
      "Training loss at step 1568: 6.0662946701049805\n",
      "Training loss at step 1600: 6.447709083557129\n",
      "Training loss at step 1632: 6.894792556762695\n",
      "Training loss at step 1664: 7.3541717529296875\n",
      "Training loss at step 1696: 7.722442626953125\n",
      "Training loss at step 1728: 7.896981239318848\n",
      "Training loss at step 1760: 7.603137493133545\n",
      "Training loss at step 1792: 6.693734645843506\n",
      "Training loss at step 1824: 5.693969249725342\n",
      "Training loss at step 1856: 4.962606906890869\n",
      "Training loss at step 1888: 4.5149760246276855\n",
      "Training loss at step 1920: 4.245547294616699\n",
      "Training loss at step 1952: 4.058638572692871\n",
      "Training loss at step 1984: 3.9360551834106445\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at step 0: 5.2222514152526855\n",
      "Training loss at step 32: 5.186559677124023\n",
      "Training loss at step 64: 5.180335521697998\n",
      "Training loss at step 96: 5.193530082702637\n",
      "Training loss at step 128: 5.229410171508789\n",
      "Training loss at step 160: 5.271252632141113\n",
      "Training loss at step 192: 5.280301570892334\n",
      "Training loss at step 224: 5.220822811126709\n",
      "Training loss at step 256: 4.998891353607178\n",
      "Training loss at step 288: 4.601674556732178\n",
      "Training loss at step 320: 4.34259033203125\n",
      "Training loss at step 352: 4.358973979949951\n",
      "Training loss at step 384: 4.556282043457031\n",
      "Training loss at step 416: 4.798627853393555\n",
      "Training loss at step 448: 5.038872718811035\n",
      "Training loss at step 480: 5.278608322143555\n",
      "Training loss at step 512: 5.521061897277832\n",
      "Training loss at step 544: 5.78510856628418\n",
      "Training loss at step 576: 6.105790138244629\n",
      "Training loss at step 608: 6.499042510986328\n",
      "Training loss at step 640: 6.947002410888672\n",
      "Training loss at step 672: 7.38266134262085\n",
      "Training loss at step 704: 7.706133842468262\n",
      "Training loss at step 736: 7.808960437774658\n",
      "Training loss at step 768: 7.351961135864258\n",
      "Training loss at step 800: 6.3886237144470215\n",
      "Training loss at step 832: 5.454311847686768\n",
      "Training loss at step 864: 4.8012375831604\n",
      "Training loss at step 896: 4.389591693878174\n",
      "Training loss at step 928: 4.103076457977295\n",
      "Training loss at step 960: 3.8760740756988525\n",
      "Training loss at step 992: 3.6708672046661377\n",
      "Training loss at step 1024: 3.4917426109313965\n",
      "Training loss at step 1056: 3.3312766551971436\n",
      "Training loss at step 1088: 3.1853368282318115\n",
      "Training loss at step 1120: 3.0523548126220703\n",
      "Training loss at step 1152: 2.9436423778533936\n",
      "Training loss at step 1184: 2.867753744125366\n",
      "Training loss at step 1216: 2.825585126876831\n",
      "Training loss at step 1248: 2.8323559761047363\n",
      "Training loss at step 1280: 3.0100350379943848\n",
      "Training loss at step 1312: 3.4863181114196777\n",
      "Training loss at step 1344: 4.186861991882324\n",
      "Training loss at step 1376: 4.876543998718262\n",
      "Training loss at step 1408: 5.354889869689941\n",
      "Training loss at step 1440: 5.597148895263672\n",
      "Training loss at step 1472: 5.733427047729492\n",
      "Training loss at step 1504: 5.858670711517334\n",
      "Training loss at step 1536: 6.054965972900391\n",
      "Training loss at step 1568: 6.32832145690918\n",
      "Training loss at step 1600: 6.685122489929199\n",
      "Training loss at step 1632: 7.102282524108887\n",
      "Training loss at step 1664: 7.511294364929199\n",
      "Training loss at step 1696: 7.822652339935303\n",
      "Training loss at step 1728: 7.935585021972656\n",
      "Training loss at step 1760: 7.587128639221191\n",
      "Training loss at step 1792: 6.652505874633789\n",
      "Training loss at step 1824: 5.664453506469727\n",
      "Training loss at step 1856: 4.9621195793151855\n",
      "Training loss at step 1888: 4.549018859863281\n",
      "Training loss at step 1920: 4.304347515106201\n",
      "Training loss at step 1952: 4.131878852844238\n",
      "Training loss at step 1984: 4.024321556091309\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at step 0: 4.845179080963135\n",
      "Training loss at step 32: 4.66725492477417\n",
      "Training loss at step 64: 4.570123672485352\n",
      "Training loss at step 96: 4.506420612335205\n",
      "Training loss at step 128: 4.47498893737793\n",
      "Training loss at step 160: 4.46517276763916\n",
      "Training loss at step 192: 4.449369430541992\n",
      "Training loss at step 224: 4.394613265991211\n",
      "Training loss at step 256: 4.237887859344482\n",
      "Training loss at step 288: 3.9879567623138428\n",
      "Training loss at step 320: 3.903567314147949\n",
      "Training loss at step 352: 4.0770158767700195\n",
      "Training loss at step 384: 4.391857147216797\n",
      "Training loss at step 416: 4.725826740264893\n",
      "Training loss at step 448: 5.022066116333008\n",
      "Training loss at step 480: 5.2902936935424805\n",
      "Training loss at step 512: 5.546031951904297\n",
      "Training loss at step 544: 5.81594181060791\n",
      "Training loss at step 576: 6.124505996704102\n",
      "Training loss at step 608: 6.488431930541992\n",
      "Training loss at step 640: 6.9012861251831055\n",
      "Training loss at step 672: 7.3007354736328125\n",
      "Training loss at step 704: 7.594876766204834\n",
      "Training loss at step 736: 7.683122634887695\n",
      "Training loss at step 768: 7.249922752380371\n",
      "Training loss at step 800: 6.355293273925781\n",
      "Training loss at step 832: 5.50700569152832\n",
      "Training loss at step 864: 4.932792663574219\n",
      "Training loss at step 896: 4.563650608062744\n",
      "Training loss at step 928: 4.26426362991333\n",
      "Training loss at step 960: 4.009533882141113\n",
      "Training loss at step 992: 3.769650936126709\n",
      "Training loss at step 1024: 3.5406572818756104\n",
      "Training loss at step 1056: 3.3424062728881836\n",
      "Training loss at step 1088: 3.1751198768615723\n",
      "Training loss at step 1120: 3.03106427192688\n",
      "Training loss at step 1152: 2.9158735275268555\n",
      "Training loss at step 1184: 2.8371517658233643\n",
      "Training loss at step 1216: 2.797559976577759\n",
      "Training loss at step 1248: 2.8141415119171143\n",
      "Training loss at step 1280: 3.007718086242676\n",
      "Training loss at step 1312: 3.4777257442474365\n",
      "Training loss at step 1344: 4.127108097076416\n",
      "Training loss at step 1376: 4.733623504638672\n",
      "Training loss at step 1408: 5.1273674964904785\n",
      "Training loss at step 1440: 5.341497421264648\n",
      "Training loss at step 1472: 5.483791351318359\n",
      "Training loss at step 1504: 5.655114650726318\n",
      "Training loss at step 1536: 5.871306419372559\n",
      "Training loss at step 1568: 6.153790473937988\n",
      "Training loss at step 1600: 6.512984275817871\n",
      "Training loss at step 1632: 6.927588939666748\n",
      "Training loss at step 1664: 7.3565354347229\n",
      "Training loss at step 1696: 7.6933674812316895\n",
      "Training loss at step 1728: 7.83574104309082\n",
      "Training loss at step 1760: 7.523229122161865\n",
      "Training loss at step 1792: 6.626821994781494\n",
      "Training loss at step 1824: 5.667686939239502\n",
      "Training loss at step 1856: 4.985546112060547\n",
      "Training loss at step 1888: 4.572699069976807\n",
      "Training loss at step 1920: 4.315073490142822\n",
      "Training loss at step 1952: 4.12396764755249\n",
      "Training loss at step 1984: 3.9977924823760986\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at step 0: 4.441548824310303\n",
      "Training loss at step 32: 4.133144378662109\n",
      "Training loss at step 64: 3.9447848796844482\n",
      "Training loss at step 96: 3.802720069885254\n",
      "Training loss at step 128: 3.6951613426208496\n",
      "Training loss at step 160: 3.616196632385254\n",
      "Training loss at step 192: 3.5509376525878906\n",
      "Training loss at step 224: 3.48103404045105\n",
      "Training loss at step 256: 3.3850340843200684\n",
      "Training loss at step 288: 3.315636396408081\n",
      "Training loss at step 320: 3.467182159423828\n",
      "Training loss at step 352: 3.850799322128296\n",
      "Training loss at step 384: 4.303324222564697\n",
      "Training loss at step 416: 4.691232681274414\n",
      "Training loss at step 448: 4.992475509643555\n",
      "Training loss at step 480: 5.252567291259766\n",
      "Training loss at step 512: 5.507501602172852\n",
      "Training loss at step 544: 5.7849836349487305\n",
      "Training loss at step 576: 6.107872486114502\n",
      "Training loss at step 608: 6.489720344543457\n",
      "Training loss at step 640: 6.916221618652344\n",
      "Training loss at step 672: 7.324863433837891\n",
      "Training loss at step 704: 7.623341083526611\n",
      "Training loss at step 736: 7.711153030395508\n",
      "Training loss at step 768: 7.268812656402588\n",
      "Training loss at step 800: 6.35700798034668\n",
      "Training loss at step 832: 5.492844104766846\n",
      "Training loss at step 864: 4.913003921508789\n",
      "Training loss at step 896: 4.541440963745117\n",
      "Training loss at step 928: 4.245904922485352\n",
      "Training loss at step 960: 3.9941248893737793\n",
      "Training loss at step 992: 3.7731881141662598\n",
      "Training loss at step 1024: 3.5478076934814453\n",
      "Training loss at step 1056: 3.3451051712036133\n",
      "Training loss at step 1088: 3.1753854751586914\n",
      "Training loss at step 1120: 3.0312747955322266\n",
      "Training loss at step 1152: 2.9176392555236816\n",
      "Training loss at step 1184: 2.840553045272827\n",
      "Training loss at step 1216: 2.8024892807006836\n",
      "Training loss at step 1248: 2.819786787033081\n",
      "Training loss at step 1280: 3.0076658725738525\n",
      "Training loss at step 1312: 3.4464635848999023\n",
      "Training loss at step 1344: 4.041967391967773\n",
      "Training loss at step 1376: 4.607600212097168\n",
      "Training loss at step 1408: 4.976521968841553\n",
      "Training loss at step 1440: 5.192465782165527\n",
      "Training loss at step 1472: 5.387225151062012\n",
      "Training loss at step 1504: 5.57930850982666\n",
      "Training loss at step 1536: 5.811067581176758\n",
      "Training loss at step 1568: 6.1106061935424805\n",
      "Training loss at step 1600: 6.485084533691406\n",
      "Training loss at step 1632: 6.908386707305908\n",
      "Training loss at step 1664: 7.340524673461914\n",
      "Training loss at step 1696: 7.676111698150635\n",
      "Training loss at step 1728: 7.819388389587402\n",
      "Training loss at step 1760: 7.511346340179443\n",
      "Training loss at step 1792: 6.622286796569824\n",
      "Training loss at step 1824: 5.669135093688965\n",
      "Training loss at step 1856: 4.988007068634033\n",
      "Training loss at step 1888: 4.571373462677002\n",
      "Training loss at step 1920: 4.311093330383301\n",
      "Training loss at step 1952: 4.119640827178955\n",
      "Training loss at step 1984: 3.9908227920532227\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at step 0: 4.210724830627441\n",
      "Training loss at step 32: 3.8312392234802246\n",
      "Training loss at step 64: 3.5944526195526123\n",
      "Training loss at step 96: 3.409118175506592\n",
      "Training loss at step 128: 3.2606453895568848\n",
      "Training loss at step 160: 3.1490461826324463\n",
      "Training loss at step 192: 3.069974899291992\n",
      "Training loss at step 224: 3.0131216049194336\n",
      "Training loss at step 256: 2.9786949157714844\n",
      "Training loss at step 288: 3.0567822456359863\n",
      "Training loss at step 320: 3.3814146518707275\n",
      "Training loss at step 352: 3.8934502601623535\n",
      "Training loss at step 384: 4.391717910766602\n",
      "Training loss at step 416: 4.761258125305176\n",
      "Training loss at step 448: 5.021020412445068\n",
      "Training loss at step 480: 5.252161979675293\n",
      "Training loss at step 512: 5.50425910949707\n",
      "Training loss at step 544: 5.7826828956604\n",
      "Training loss at step 576: 6.10730504989624\n",
      "Training loss at step 608: 6.489429950714111\n",
      "Training loss at step 640: 6.913740634918213\n",
      "Training loss at step 672: 7.318303108215332\n",
      "Training loss at step 704: 7.6120405197143555\n",
      "Training loss at step 736: 7.696463584899902\n",
      "Training loss at step 768: 7.2565813064575195\n",
      "Training loss at step 800: 6.355555534362793\n",
      "Training loss at step 832: 5.5062055587768555\n",
      "Training loss at step 864: 4.944659233093262\n",
      "Training loss at step 896: 4.583661079406738\n",
      "Training loss at step 928: 4.312664985656738\n",
      "Training loss at step 960: 4.07689094543457\n",
      "Training loss at step 992: 3.861103057861328\n",
      "Training loss at step 1024: 3.6541879177093506\n",
      "Training loss at step 1056: 3.4261295795440674\n",
      "Training loss at step 1088: 3.233031988143921\n",
      "Training loss at step 1120: 3.0681886672973633\n",
      "Training loss at step 1152: 2.932248592376709\n",
      "Training loss at step 1184: 2.843708038330078\n",
      "Training loss at step 1216: 2.799267053604126\n",
      "Training loss at step 1248: 2.8090004920959473\n",
      "Training loss at step 1280: 2.973046064376831\n",
      "Training loss at step 1312: 3.377213954925537\n",
      "Training loss at step 1344: 3.9549527168273926\n",
      "Training loss at step 1376: 4.518364906311035\n",
      "Training loss at step 1408: 4.899372577667236\n",
      "Training loss at step 1440: 5.159857749938965\n",
      "Training loss at step 1472: 5.381521224975586\n",
      "Training loss at step 1504: 5.586911678314209\n",
      "Training loss at step 1536: 5.8225417137146\n",
      "Training loss at step 1568: 6.126730918884277\n",
      "Training loss at step 1600: 6.500850677490234\n",
      "Training loss at step 1632: 6.922990322113037\n",
      "Training loss at step 1664: 7.341442108154297\n",
      "Training loss at step 1696: 7.670901775360107\n",
      "Training loss at step 1728: 7.8149824142456055\n",
      "Training loss at step 1760: 7.508655071258545\n",
      "Training loss at step 1792: 6.621587753295898\n",
      "Training loss at step 1824: 5.668679237365723\n",
      "Training loss at step 1856: 4.978423118591309\n",
      "Training loss at step 1888: 4.550580024719238\n",
      "Training loss at step 1920: 4.279175281524658\n",
      "Training loss at step 1952: 4.0776143074035645\n",
      "Training loss at step 1984: 3.9457297325134277\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at step 0: 4.072502136230469\n",
      "Training loss at step 32: 3.652437210083008\n",
      "Training loss at step 64: 3.3992550373077393\n",
      "Training loss at step 96: 3.2073307037353516\n",
      "Training loss at step 128: 3.0560662746429443\n",
      "Training loss at step 160: 2.9441781044006348\n",
      "Training loss at step 192: 2.8716557025909424\n",
      "Training loss at step 224: 2.8343863487243652\n",
      "Training loss at step 256: 2.8490443229675293\n",
      "Training loss at step 288: 3.0189332962036133\n",
      "Training loss at step 320: 3.4292876720428467\n",
      "Training loss at step 352: 3.9837453365325928\n",
      "Training loss at step 384: 4.466150760650635\n",
      "Training loss at step 416: 4.795950889587402\n",
      "Training loss at step 448: 5.026451110839844\n",
      "Training loss at step 480: 5.252079963684082\n",
      "Training loss at step 512: 5.506336688995361\n",
      "Training loss at step 544: 5.785261631011963\n",
      "Training loss at step 576: 6.108625411987305\n",
      "Training loss at step 608: 6.487297534942627\n",
      "Training loss at step 640: 6.904380798339844\n",
      "Training loss at step 672: 7.301953315734863\n",
      "Training loss at step 704: 7.589850425720215\n",
      "Training loss at step 736: 7.670693874359131\n",
      "Training loss at step 768: 7.237039089202881\n",
      "Training loss at step 800: 6.3561859130859375\n",
      "Training loss at step 832: 5.532261848449707\n",
      "Training loss at step 864: 4.988132476806641\n",
      "Training loss at step 896: 4.651501178741455\n",
      "Training loss at step 928: 4.397471904754639\n",
      "Training loss at step 960: 4.183138847351074\n",
      "Training loss at step 992: 3.9833624362945557\n",
      "Training loss at step 1024: 3.7926418781280518\n",
      "Training loss at step 1056: 3.5897579193115234\n",
      "Training loss at step 1088: 3.3834729194641113\n",
      "Training loss at step 1120: 3.2077102661132812\n",
      "Training loss at step 1152: 3.05413818359375\n",
      "Training loss at step 1184: 2.942937135696411\n",
      "Training loss at step 1216: 2.8718347549438477\n",
      "Training loss at step 1248: 2.8456075191497803\n",
      "Training loss at step 1280: 2.953179121017456\n",
      "Training loss at step 1312: 3.31632924079895\n",
      "Training loss at step 1344: 3.896803855895996\n",
      "Training loss at step 1376: 4.48594856262207\n",
      "Training loss at step 1408: 4.904943466186523\n",
      "Training loss at step 1440: 5.205007553100586\n",
      "Training loss at step 1472: 5.432465553283691\n",
      "Training loss at step 1504: 5.631166458129883\n",
      "Training loss at step 1536: 5.867265701293945\n",
      "Training loss at step 1568: 6.16948127746582\n",
      "Training loss at step 1600: 6.542303085327148\n",
      "Training loss at step 1632: 6.964102745056152\n",
      "Training loss at step 1664: 7.381213188171387\n",
      "Training loss at step 1696: 7.700265884399414\n",
      "Training loss at step 1728: 7.83038854598999\n",
      "Training loss at step 1760: 7.513730525970459\n",
      "Training loss at step 1792: 6.62209415435791\n",
      "Training loss at step 1824: 5.667378902435303\n",
      "Training loss at step 1856: 4.977530002593994\n",
      "Training loss at step 1888: 4.555282115936279\n",
      "Training loss at step 1920: 4.284967422485352\n",
      "Training loss at step 1952: 4.074326038360596\n",
      "Training loss at step 1984: 3.9326956272125244\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at step 0: 4.023289203643799\n",
      "Training loss at step 32: 3.590735912322998\n",
      "Training loss at step 64: 3.3411333560943604\n",
      "Training loss at step 96: 3.1562681198120117\n",
      "Training loss at step 128: 3.0088367462158203\n",
      "Training loss at step 160: 2.8986778259277344\n",
      "Training loss at step 192: 2.8286287784576416\n",
      "Training loss at step 224: 2.797351837158203\n",
      "Training loss at step 256: 2.830021858215332\n",
      "Training loss at step 288: 3.0359268188476562\n",
      "Training loss at step 320: 3.4753990173339844\n",
      "Training loss at step 352: 4.036473274230957\n",
      "Training loss at step 384: 4.5055670738220215\n",
      "Training loss at step 416: 4.817451000213623\n",
      "Training loss at step 448: 5.030941009521484\n",
      "Training loss at step 480: 5.252621650695801\n",
      "Training loss at step 512: 5.509500503540039\n",
      "Training loss at step 544: 5.7886247634887695\n",
      "Training loss at step 576: 6.11048698425293\n",
      "Training loss at step 608: 6.487234115600586\n",
      "Training loss at step 640: 6.902439117431641\n",
      "Training loss at step 672: 7.297605514526367\n",
      "Training loss at step 704: 7.583500385284424\n",
      "Training loss at step 736: 7.663646697998047\n",
      "Training loss at step 768: 7.232209205627441\n",
      "Training loss at step 800: 6.357669830322266\n",
      "Training loss at step 832: 5.5431623458862305\n",
      "Training loss at step 864: 5.015450477600098\n",
      "Training loss at step 896: 4.700639724731445\n",
      "Training loss at step 928: 4.4615559577941895\n",
      "Training loss at step 960: 4.256467819213867\n",
      "Training loss at step 992: 4.056726455688477\n",
      "Training loss at step 1024: 3.8589441776275635\n",
      "Training loss at step 1056: 3.646848440170288\n",
      "Training loss at step 1088: 3.431264877319336\n",
      "Training loss at step 1120: 3.246978998184204\n",
      "Training loss at step 1152: 3.0918054580688477\n",
      "Training loss at step 1184: 2.979828119277954\n",
      "Training loss at step 1216: 2.905327320098877\n",
      "Training loss at step 1248: 2.87060809135437\n",
      "Training loss at step 1280: 2.9583516120910645\n",
      "Training loss at step 1312: 3.2954931259155273\n",
      "Training loss at step 1344: 3.84476900100708\n",
      "Training loss at step 1376: 4.421130657196045\n",
      "Training loss at step 1408: 4.849161624908447\n",
      "Training loss at step 1440: 5.160750389099121\n",
      "Training loss at step 1472: 5.401485443115234\n",
      "Training loss at step 1504: 5.613996505737305\n",
      "Training loss at step 1536: 5.854408264160156\n",
      "Training loss at step 1568: 6.156782150268555\n",
      "Training loss at step 1600: 6.530055999755859\n",
      "Training loss at step 1632: 6.95052433013916\n",
      "Training loss at step 1664: 7.366192817687988\n",
      "Training loss at step 1696: 7.685718536376953\n",
      "Training loss at step 1728: 7.81842565536499\n",
      "Training loss at step 1760: 7.512907028198242\n",
      "Training loss at step 1792: 6.625194549560547\n",
      "Training loss at step 1824: 5.665126800537109\n",
      "Training loss at step 1856: 4.957369804382324\n",
      "Training loss at step 1888: 4.507023811340332\n",
      "Training loss at step 1920: 4.210343360900879\n",
      "Training loss at step 1952: 3.9868505001068115\n",
      "Training loss at step 1984: 3.841825008392334\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at step 0: 4.018327713012695\n",
      "Training loss at step 32: 3.585122585296631\n",
      "Training loss at step 64: 3.3374390602111816\n",
      "Training loss at step 96: 3.1538960933685303\n",
      "Training loss at step 128: 3.007150411605835\n",
      "Training loss at step 160: 2.8972558975219727\n",
      "Training loss at step 192: 2.8273487091064453\n",
      "Training loss at step 224: 2.7962653636932373\n",
      "Training loss at step 256: 2.829998016357422\n",
      "Training loss at step 288: 3.0389606952667236\n",
      "Training loss at step 320: 3.4821617603302\n",
      "Training loss at step 352: 4.047179698944092\n",
      "Training loss at step 384: 4.530826568603516\n",
      "Training loss at step 416: 4.840499401092529\n",
      "Training loss at step 448: 5.045984268188477\n",
      "Training loss at step 480: 5.252527236938477\n",
      "Training loss at step 512: 5.503480434417725\n",
      "Training loss at step 544: 5.7830657958984375\n",
      "Training loss at step 576: 6.108006477355957\n",
      "Training loss at step 608: 6.487819194793701\n",
      "Training loss at step 640: 6.905636787414551\n",
      "Training loss at step 672: 7.30277156829834\n",
      "Training loss at step 704: 7.589832305908203\n",
      "Training loss at step 736: 7.670071601867676\n",
      "Training loss at step 768: 7.236286163330078\n",
      "Training loss at step 800: 6.356936931610107\n",
      "Training loss at step 832: 5.5371527671813965\n",
      "Training loss at step 864: 5.005680084228516\n",
      "Training loss at step 896: 4.683708190917969\n",
      "Training loss at step 928: 4.434134006500244\n",
      "Training loss at step 960: 4.206031799316406\n",
      "Training loss at step 992: 3.997297525405884\n",
      "Training loss at step 1024: 3.800548553466797\n",
      "Training loss at step 1056: 3.5733230113983154\n",
      "Training loss at step 1088: 3.3618154525756836\n",
      "Training loss at step 1120: 3.174107551574707\n",
      "Training loss at step 1152: 3.0264148712158203\n",
      "Training loss at step 1184: 2.9236557483673096\n",
      "Training loss at step 1216: 2.8597748279571533\n",
      "Training loss at step 1248: 2.8399322032928467\n",
      "Training loss at step 1280: 2.95230770111084\n",
      "Training loss at step 1312: 3.312527656555176\n",
      "Training loss at step 1344: 3.863827705383301\n",
      "Training loss at step 1376: 4.432492256164551\n",
      "Training loss at step 1408: 4.842067241668701\n",
      "Training loss at step 1440: 5.124368190765381\n",
      "Training loss at step 1472: 5.3569488525390625\n",
      "Training loss at step 1504: 5.568187713623047\n",
      "Training loss at step 1536: 5.805049896240234\n",
      "Training loss at step 1568: 6.107431411743164\n",
      "Training loss at step 1600: 6.480443954467773\n",
      "Training loss at step 1632: 6.899620532989502\n",
      "Training loss at step 1664: 7.311864376068115\n",
      "Training loss at step 1696: 7.630269527435303\n",
      "Training loss at step 1728: 7.767317771911621\n",
      "Training loss at step 1760: 7.472312927246094\n",
      "Training loss at step 1792: 6.607529640197754\n",
      "Training loss at step 1824: 5.670560359954834\n",
      "Training loss at step 1856: 4.9766645431518555\n",
      "Training loss at step 1888: 4.531907081604004\n",
      "Training loss at step 1920: 4.232310771942139\n",
      "Training loss at step 1952: 4.006503582000732\n",
      "Training loss at step 1984: 3.8581960201263428\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at step 0: 4.033285617828369\n",
      "Training loss at step 32: 3.6057546138763428\n",
      "Training loss at step 64: 3.358346939086914\n",
      "Training loss at step 96: 3.172441244125366\n",
      "Training loss at step 128: 3.023618221282959\n",
      "Training loss at step 160: 2.9125800132751465\n",
      "Training loss at step 192: 2.8416495323181152\n",
      "Training loss at step 224: 2.8081791400909424\n",
      "Training loss at step 256: 2.8337976932525635\n",
      "Training loss at step 288: 3.0265369415283203\n",
      "Training loss at step 320: 3.459261655807495\n",
      "Training loss at step 352: 4.025742053985596\n",
      "Training loss at step 384: 4.523984909057617\n",
      "Training loss at step 416: 4.8473100662231445\n",
      "Training loss at step 448: 5.0561652183532715\n",
      "Training loss at step 480: 5.2556657791137695\n",
      "Training loss at step 512: 5.500365734100342\n",
      "Training loss at step 544: 5.779158115386963\n",
      "Training loss at step 576: 6.105876922607422\n",
      "Training loss at step 608: 6.488580703735352\n",
      "Training loss at step 640: 6.909866809844971\n",
      "Training loss at step 672: 7.310355186462402\n",
      "Training loss at step 704: 7.59958028793335\n",
      "Training loss at step 736: 7.680325508117676\n",
      "Training loss at step 768: 7.2430009841918945\n",
      "Training loss at step 800: 6.3555426597595215\n",
      "Training loss at step 832: 5.525857448577881\n",
      "Training loss at step 864: 4.979766845703125\n",
      "Training loss at step 896: 4.642458915710449\n",
      "Training loss at step 928: 4.382538795471191\n",
      "Training loss at step 960: 4.1513495445251465\n",
      "Training loss at step 992: 3.9404568672180176\n",
      "Training loss at step 1024: 3.74284029006958\n",
      "Training loss at step 1056: 3.5155858993530273\n",
      "Training loss at step 1088: 3.3055217266082764\n",
      "Training loss at step 1120: 3.1229138374328613\n",
      "Training loss at step 1152: 2.9821484088897705\n",
      "Training loss at step 1184: 2.886439323425293\n",
      "Training loss at step 1216: 2.8307063579559326\n",
      "Training loss at step 1248: 2.822262763977051\n",
      "Training loss at step 1280: 2.9538235664367676\n",
      "Training loss at step 1312: 3.3301830291748047\n",
      "Training loss at step 1344: 3.882190227508545\n",
      "Training loss at step 1376: 4.440557479858398\n",
      "Training loss at step 1408: 4.84170389175415\n",
      "Training loss at step 1440: 5.121086597442627\n",
      "Training loss at step 1472: 5.353639602661133\n",
      "Training loss at step 1504: 5.56804084777832\n",
      "Training loss at step 1536: 5.808206081390381\n",
      "Training loss at step 1568: 6.108372688293457\n",
      "Training loss at step 1600: 6.480180263519287\n",
      "Training loss at step 1632: 6.8974928855896\n",
      "Training loss at step 1664: 7.307247161865234\n",
      "Training loss at step 1696: 7.624341011047363\n",
      "Training loss at step 1728: 7.76113224029541\n",
      "Training loss at step 1760: 7.46372652053833\n",
      "Training loss at step 1792: 6.603854179382324\n",
      "Training loss at step 1824: 5.672698974609375\n",
      "Training loss at step 1856: 4.984179496765137\n",
      "Training loss at step 1888: 4.544072151184082\n",
      "Training loss at step 1920: 4.247199535369873\n",
      "Training loss at step 1952: 4.02232027053833\n",
      "Training loss at step 1984: 3.874433994293213\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at step 0: 4.042214870452881\n",
      "Training loss at step 32: 3.6194229125976562\n",
      "Training loss at step 64: 3.3725335597991943\n",
      "Training loss at step 96: 3.185163974761963\n",
      "Training loss at step 128: 3.0355937480926514\n",
      "Training loss at step 160: 2.9244351387023926\n",
      "Training loss at step 192: 2.8530988693237305\n",
      "Training loss at step 224: 2.818185329437256\n",
      "Training loss at step 256: 2.8390328884124756\n",
      "Training loss at step 288: 3.021843433380127\n",
      "Training loss at step 320: 3.445206880569458\n",
      "Training loss at step 352: 4.007724761962891\n",
      "Training loss at step 384: 4.500240325927734\n",
      "Training loss at step 416: 4.826028347015381\n",
      "Training loss at step 448: 5.047646522521973\n",
      "Training loss at step 480: 5.255519390106201\n",
      "Training loss at step 512: 5.499711513519287\n",
      "Training loss at step 544: 5.778199195861816\n",
      "Training loss at step 576: 6.105473041534424\n",
      "Training loss at step 608: 6.489182949066162\n",
      "Training loss at step 640: 6.911161422729492\n",
      "Training loss at step 672: 7.311990261077881\n",
      "Training loss at step 704: 7.601656913757324\n",
      "Training loss at step 736: 7.682562351226807\n",
      "Training loss at step 768: 7.244553565979004\n",
      "Training loss at step 800: 6.355221748352051\n",
      "Training loss at step 832: 5.5226006507873535\n",
      "Training loss at step 864: 4.975918292999268\n",
      "Training loss at step 896: 4.6352081298828125\n",
      "Training loss at step 928: 4.367273807525635\n",
      "Training loss at step 960: 4.1323561668396\n",
      "Training loss at step 992: 3.9209272861480713\n",
      "Training loss at step 1024: 3.725726842880249\n",
      "Training loss at step 1056: 3.508286714553833\n",
      "Training loss at step 1088: 3.2952747344970703\n",
      "Training loss at step 1120: 3.1132915019989014\n",
      "Training loss at step 1152: 2.9733667373657227\n",
      "Training loss at step 1184: 2.878552198410034\n",
      "Training loss at step 1216: 2.824455738067627\n",
      "Training loss at step 1248: 2.818650007247925\n",
      "Training loss at step 1280: 2.9549715518951416\n",
      "Training loss at step 1312: 3.3346164226531982\n",
      "Training loss at step 1344: 3.884498119354248\n",
      "Training loss at step 1376: 4.434085845947266\n",
      "Training loss at step 1408: 4.833688259124756\n",
      "Training loss at step 1440: 5.126678466796875\n",
      "Training loss at step 1472: 5.359183311462402\n",
      "Training loss at step 1504: 5.566682815551758\n",
      "Training loss at step 1536: 5.8055524826049805\n",
      "Training loss at step 1568: 6.104670524597168\n",
      "Training loss at step 1600: 6.475497245788574\n",
      "Training loss at step 1632: 6.8916826248168945\n",
      "Training loss at step 1664: 7.299107074737549\n",
      "Training loss at step 1696: 7.615035533905029\n",
      "Training loss at step 1728: 7.752480506896973\n",
      "Training loss at step 1760: 7.459766864776611\n",
      "Training loss at step 1792: 6.602312088012695\n",
      "Training loss at step 1824: 5.673652648925781\n",
      "Training loss at step 1856: 4.985730171203613\n",
      "Training loss at step 1888: 4.544422149658203\n",
      "Training loss at step 1920: 4.245561122894287\n",
      "Training loss at step 1952: 4.019233226776123\n",
      "Training loss at step 1984: 3.870598316192627\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at step 0: 4.032419204711914\n",
      "Training loss at step 32: 3.608008623123169\n",
      "Training loss at step 64: 3.362639904022217\n",
      "Training loss at step 96: 3.176563262939453\n",
      "Training loss at step 128: 3.0279178619384766\n",
      "Training loss at step 160: 2.9173707962036133\n",
      "Training loss at step 192: 2.846705436706543\n",
      "Training loss at step 224: 2.8129968643188477\n",
      "Training loss at step 256: 2.8364064693450928\n",
      "Training loss at step 288: 3.023378849029541\n",
      "Training loss at step 320: 3.4491963386535645\n",
      "Training loss at step 352: 4.006306171417236\n",
      "Training loss at step 384: 4.486123085021973\n",
      "Training loss at step 416: 4.812330722808838\n",
      "Training loss at step 448: 5.043968200683594\n",
      "Training loss at step 480: 5.255392074584961\n",
      "Training loss at step 512: 5.499363899230957\n",
      "Training loss at step 544: 5.777271270751953\n",
      "Training loss at step 576: 6.105208873748779\n",
      "Training loss at step 608: 6.489554405212402\n",
      "Training loss at step 640: 6.911219596862793\n",
      "Training loss at step 672: 7.31137228012085\n",
      "Training loss at step 704: 7.600621223449707\n",
      "Training loss at step 736: 7.681271076202393\n",
      "Training loss at step 768: 7.243597984313965\n",
      "Training loss at step 800: 6.355307579040527\n",
      "Training loss at step 832: 5.523987770080566\n",
      "Training loss at step 864: 4.965738296508789\n",
      "Training loss at step 896: 4.622762680053711\n",
      "Training loss at step 928: 4.3626885414123535\n",
      "Training loss at step 960: 4.130193710327148\n",
      "Training loss at step 992: 3.922215700149536\n",
      "Training loss at step 1024: 3.7299718856811523\n",
      "Training loss at step 1056: 3.5282795429229736\n",
      "Training loss at step 1088: 3.316129207611084\n",
      "Training loss at step 1120: 3.132114887237549\n",
      "Training loss at step 1152: 2.9893929958343506\n",
      "Training loss at step 1184: 2.891195774078369\n",
      "Training loss at step 1216: 2.8328709602355957\n",
      "Training loss at step 1248: 2.822261095046997\n",
      "Training loss at step 1280: 2.955063819885254\n",
      "Training loss at step 1312: 3.338308811187744\n",
      "Training loss at step 1344: 3.894930839538574\n",
      "Training loss at step 1376: 4.446260452270508\n",
      "Training loss at step 1408: 4.8509697914123535\n",
      "Training loss at step 1440: 5.152055263519287\n",
      "Training loss at step 1472: 5.374532222747803\n",
      "Training loss at step 1504: 5.576372146606445\n",
      "Training loss at step 1536: 5.812741279602051\n",
      "Training loss at step 1568: 6.110618591308594\n",
      "Training loss at step 1600: 6.481084823608398\n",
      "Training loss at step 1632: 6.897263050079346\n",
      "Training loss at step 1664: 7.307405471801758\n",
      "Training loss at step 1696: 7.629031658172607\n",
      "Training loss at step 1728: 7.766312599182129\n",
      "Training loss at step 1760: 7.467154026031494\n",
      "Training loss at step 1792: 6.604191303253174\n",
      "Training loss at step 1824: 5.673081398010254\n",
      "Training loss at step 1856: 4.985637664794922\n",
      "Training loss at step 1888: 4.546452522277832\n",
      "Training loss at step 1920: 4.249798774719238\n",
      "Training loss at step 1952: 4.025792598724365\n",
      "Training loss at step 1984: 3.879535436630249\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at step 0: 4.029628276824951\n",
      "Training loss at step 32: 3.6057469844818115\n",
      "Training loss at step 64: 3.3617148399353027\n",
      "Training loss at step 96: 3.175555944442749\n",
      "Training loss at step 128: 3.0271387100219727\n",
      "Training loss at step 160: 2.916943311691284\n",
      "Training loss at step 192: 2.8466031551361084\n",
      "Training loss at step 224: 2.8132271766662598\n",
      "Training loss at step 256: 2.8369078636169434\n",
      "Training loss at step 288: 3.0220441818237305\n",
      "Training loss at step 320: 3.4412105083465576\n",
      "Training loss at step 352: 3.9918274879455566\n",
      "Training loss at step 384: 4.4694108963012695\n",
      "Training loss at step 416: 4.799530982971191\n",
      "Training loss at step 448: 5.041317939758301\n",
      "Training loss at step 480: 5.2550530433654785\n",
      "Training loss at step 512: 5.499225616455078\n",
      "Training loss at step 544: 5.77731990814209\n",
      "Training loss at step 576: 6.105144500732422\n",
      "Training loss at step 608: 6.488948822021484\n",
      "Training loss at step 640: 6.909879684448242\n",
      "Training loss at step 672: 7.309554100036621\n",
      "Training loss at step 704: 7.598248481750488\n",
      "Training loss at step 736: 7.678815841674805\n",
      "Training loss at step 768: 7.242060661315918\n",
      "Training loss at step 800: 6.3553266525268555\n",
      "Training loss at step 832: 5.524896621704102\n",
      "Training loss at step 864: 4.974839687347412\n",
      "Training loss at step 896: 4.629272937774658\n",
      "Training loss at step 928: 4.361875534057617\n",
      "Training loss at step 960: 4.130815505981445\n",
      "Training loss at step 992: 3.9236831665039062\n",
      "Training loss at step 1024: 3.732523202896118\n",
      "Training loss at step 1056: 3.5380029678344727\n",
      "Training loss at step 1088: 3.3247392177581787\n",
      "Training loss at step 1120: 3.1392250061035156\n",
      "Training loss at step 1152: 2.9956185817718506\n",
      "Training loss at step 1184: 2.8965065479278564\n",
      "Training loss at step 1216: 2.838070869445801\n",
      "Training loss at step 1248: 2.826280117034912\n",
      "Training loss at step 1280: 2.952660083770752\n",
      "Training loss at step 1312: 3.3238680362701416\n",
      "Training loss at step 1344: 3.8710861206054688\n",
      "Training loss at step 1376: 4.41262149810791\n",
      "Training loss at step 1408: 4.830581188201904\n",
      "Training loss at step 1440: 5.147178649902344\n",
      "Training loss at step 1472: 5.379284381866455\n",
      "Training loss at step 1504: 5.5847649574279785\n",
      "Training loss at step 1536: 5.820684432983398\n",
      "Training loss at step 1568: 6.117206573486328\n",
      "Training loss at step 1600: 6.486874580383301\n",
      "Training loss at step 1632: 6.902911186218262\n",
      "Training loss at step 1664: 7.309413909912109\n",
      "Training loss at step 1696: 7.624473571777344\n",
      "Training loss at step 1728: 7.75912618637085\n",
      "Training loss at step 1760: 7.463313102722168\n",
      "Training loss at step 1792: 6.604265213012695\n",
      "Training loss at step 1824: 5.672186374664307\n",
      "Training loss at step 1856: 4.982763290405273\n",
      "Training loss at step 1888: 4.540799617767334\n",
      "Training loss at step 1920: 4.2415289878845215\n",
      "Training loss at step 1952: 4.015275955200195\n",
      "Training loss at step 1984: 3.8672542572021484\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at step 0: 4.016859531402588\n",
      "Training loss at step 32: 3.5887033939361572\n",
      "Training loss at step 64: 3.346346616744995\n",
      "Training loss at step 96: 3.1632275581359863\n",
      "Training loss at step 128: 3.0158488750457764\n",
      "Training loss at step 160: 2.9060068130493164\n",
      "Training loss at step 192: 2.8362808227539062\n",
      "Training loss at step 224: 2.804514169692993\n",
      "Training loss at step 256: 2.832592248916626\n",
      "Training loss at step 288: 3.026111364364624\n",
      "Training loss at step 320: 3.451563596725464\n",
      "Training loss at step 352: 4.002352714538574\n",
      "Training loss at step 384: 4.475229263305664\n",
      "Training loss at step 416: 4.802546501159668\n",
      "Training loss at step 448: 5.045231342315674\n",
      "Training loss at step 480: 5.255908966064453\n",
      "Training loss at step 512: 5.499178886413574\n",
      "Training loss at step 544: 5.777167320251465\n",
      "Training loss at step 576: 6.105098247528076\n",
      "Training loss at step 608: 6.489117622375488\n",
      "Training loss at step 640: 6.910290718078613\n",
      "Training loss at step 672: 7.308852195739746\n",
      "Training loss at step 704: 7.597085475921631\n",
      "Training loss at step 736: 7.677380561828613\n",
      "Training loss at step 768: 7.240964889526367\n",
      "Training loss at step 800: 6.3555192947387695\n",
      "Training loss at step 832: 5.527287483215332\n",
      "Training loss at step 864: 4.981378078460693\n",
      "Training loss at step 896: 4.640240669250488\n",
      "Training loss at step 928: 4.375329971313477\n",
      "Training loss at step 960: 4.144038200378418\n",
      "Training loss at step 992: 3.936713695526123\n",
      "Training loss at step 1024: 3.743969440460205\n",
      "Training loss at step 1056: 3.5509848594665527\n",
      "Training loss at step 1088: 3.338487386703491\n",
      "Training loss at step 1120: 3.1517574787139893\n",
      "Training loss at step 1152: 3.0068421363830566\n",
      "Training loss at step 1184: 2.906388282775879\n",
      "Training loss at step 1216: 2.8460257053375244\n",
      "Training loss at step 1248: 2.8311867713928223\n",
      "Training loss at step 1280: 2.951965570449829\n",
      "Training loss at step 1312: 3.3180453777313232\n",
      "Training loss at step 1344: 3.8633110523223877\n",
      "Training loss at step 1376: 4.401162147521973\n",
      "Training loss at step 1408: 4.822856903076172\n",
      "Training loss at step 1440: 5.141816139221191\n",
      "Training loss at step 1472: 5.374828338623047\n",
      "Training loss at step 1504: 5.579472541809082\n",
      "Training loss at step 1536: 5.812736511230469\n",
      "Training loss at step 1568: 6.109053611755371\n",
      "Training loss at step 1600: 6.4779052734375\n",
      "Training loss at step 1632: 6.893468856811523\n",
      "Training loss at step 1664: 7.299069881439209\n",
      "Training loss at step 1696: 7.613642692565918\n",
      "Training loss at step 1728: 7.7524824142456055\n",
      "Training loss at step 1760: 7.459536552429199\n",
      "Training loss at step 1792: 6.602976322174072\n",
      "Training loss at step 1824: 5.672630310058594\n",
      "Training loss at step 1856: 4.981974124908447\n",
      "Training loss at step 1888: 4.535483360290527\n",
      "Training loss at step 1920: 4.2315239906311035\n",
      "Training loss at step 1952: 4.001376152038574\n",
      "Training loss at step 1984: 3.851170301437378\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at step 0: 4.0114641189575195\n",
      "Training loss at step 32: 3.5819931030273438\n",
      "Training loss at step 64: 3.340595006942749\n",
      "Training loss at step 96: 3.159519910812378\n",
      "Training loss at step 128: 3.0137553215026855\n",
      "Training loss at step 160: 2.9043045043945312\n",
      "Training loss at step 192: 2.8348593711853027\n",
      "Training loss at step 224: 2.8034651279449463\n",
      "Training loss at step 256: 2.832209587097168\n",
      "Training loss at step 288: 3.0265421867370605\n",
      "Training loss at step 320: 3.452178478240967\n",
      "Training loss at step 352: 4.002471923828125\n",
      "Training loss at step 384: 4.475776672363281\n",
      "Training loss at step 416: 4.812225341796875\n",
      "Training loss at step 448: 5.054965019226074\n",
      "Training loss at step 480: 5.2583699226379395\n",
      "Training loss at step 512: 5.4991655349731445\n",
      "Training loss at step 544: 5.776694297790527\n",
      "Training loss at step 576: 6.104987621307373\n",
      "Training loss at step 608: 6.489457130432129\n",
      "Training loss at step 640: 6.9109416007995605\n",
      "Training loss at step 672: 7.310199737548828\n",
      "Training loss at step 704: 7.598629951477051\n",
      "Training loss at step 736: 7.67885684967041\n",
      "Training loss at step 768: 7.241876602172852\n",
      "Training loss at step 800: 6.355391502380371\n",
      "Training loss at step 832: 5.525986671447754\n",
      "Training loss at step 864: 4.977935314178467\n",
      "Training loss at step 896: 4.632828712463379\n",
      "Training loss at step 928: 4.365528583526611\n",
      "Training loss at step 960: 4.134723663330078\n",
      "Training loss at step 992: 3.927748918533325\n",
      "Training loss at step 1024: 3.7354750633239746\n",
      "Training loss at step 1056: 3.542083263397217\n",
      "Training loss at step 1088: 3.3309853076934814\n",
      "Training loss at step 1120: 3.146042823791504\n",
      "Training loss at step 1152: 3.002507209777832\n",
      "Training loss at step 1184: 2.903353691101074\n",
      "Training loss at step 1216: 2.843958854675293\n",
      "Training loss at step 1248: 2.830069065093994\n",
      "Training loss at step 1280: 2.9520421028137207\n",
      "Training loss at step 1312: 3.3190948963165283\n",
      "Training loss at step 1344: 3.8648195266723633\n",
      "Training loss at step 1376: 4.400209426879883\n",
      "Training loss at step 1408: 4.8226518630981445\n",
      "Training loss at step 1440: 5.140676498413086\n",
      "Training loss at step 1472: 5.373052597045898\n",
      "Training loss at step 1504: 5.581511497497559\n",
      "Training loss at step 1536: 5.816197395324707\n",
      "Training loss at step 1568: 6.111567497253418\n",
      "Training loss at step 1600: 6.479199409484863\n",
      "Training loss at step 1632: 6.895043849945068\n",
      "Training loss at step 1664: 7.300469875335693\n",
      "Training loss at step 1696: 7.613836288452148\n",
      "Training loss at step 1728: 7.750725269317627\n",
      "Training loss at step 1760: 7.45818567276001\n",
      "Training loss at step 1792: 6.602505207061768\n",
      "Training loss at step 1824: 5.672768592834473\n",
      "Training loss at step 1856: 4.982699871063232\n",
      "Training loss at step 1888: 4.536195755004883\n",
      "Training loss at step 1920: 4.2329230308532715\n",
      "Training loss at step 1952: 4.0029520988464355\n",
      "Training loss at step 1984: 3.8530704975128174\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at step 0: 4.0147857666015625\n",
      "Training loss at step 32: 3.58860445022583\n",
      "Training loss at step 64: 3.3484373092651367\n",
      "Training loss at step 96: 3.16636323928833\n",
      "Training loss at step 128: 3.019165515899658\n",
      "Training loss at step 160: 2.909540891647339\n",
      "Training loss at step 192: 2.839895725250244\n",
      "Training loss at step 224: 2.8077845573425293\n",
      "Training loss at step 256: 2.8341805934906006\n",
      "Training loss at step 288: 3.024177312850952\n",
      "Training loss at step 320: 3.447162389755249\n",
      "Training loss at step 352: 3.997968912124634\n",
      "Training loss at step 384: 4.474315643310547\n",
      "Training loss at step 416: 4.816116809844971\n",
      "Training loss at step 448: 5.058361530303955\n",
      "Training loss at step 480: 5.260753631591797\n",
      "Training loss at step 512: 5.499417781829834\n",
      "Training loss at step 544: 5.776401042938232\n",
      "Training loss at step 576: 6.1050872802734375\n",
      "Training loss at step 608: 6.490557670593262\n",
      "Training loss at step 640: 6.913633346557617\n",
      "Training loss at step 672: 7.312782287597656\n",
      "Training loss at step 704: 7.600959300994873\n",
      "Training loss at step 736: 7.681142807006836\n",
      "Training loss at step 768: 7.243283271789551\n",
      "Training loss at step 800: 6.35522985458374\n",
      "Training loss at step 832: 5.524026870727539\n",
      "Training loss at step 864: 4.972938060760498\n",
      "Training loss at step 896: 4.624839782714844\n",
      "Training loss at step 928: 4.355700492858887\n",
      "Training loss at step 960: 4.122550964355469\n",
      "Training loss at step 992: 3.913877010345459\n",
      "Training loss at step 1024: 3.7194931507110596\n",
      "Training loss at step 1056: 3.5226967334747314\n",
      "Training loss at step 1088: 3.3114166259765625\n",
      "Training loss at step 1120: 3.128474235534668\n",
      "Training loss at step 1152: 2.9870316982269287\n",
      "Training loss at step 1184: 2.8903932571411133\n",
      "Training loss at step 1216: 2.833824634552002\n",
      "Training loss at step 1248: 2.8240253925323486\n",
      "Training loss at step 1280: 2.952780246734619\n",
      "Training loss at step 1312: 3.325098752975464\n",
      "Training loss at step 1344: 3.8710408210754395\n",
      "Training loss at step 1376: 4.400062084197998\n",
      "Training loss at step 1408: 4.819639682769775\n",
      "Training loss at step 1440: 5.135608673095703\n",
      "Training loss at step 1472: 5.366238594055176\n",
      "Training loss at step 1504: 5.570552825927734\n",
      "Training loss at step 1536: 5.805159568786621\n",
      "Training loss at step 1568: 6.101020336151123\n",
      "Training loss at step 1600: 6.4679131507873535\n",
      "Training loss at step 1632: 6.883115768432617\n",
      "Training loss at step 1664: 7.287622928619385\n",
      "Training loss at step 1696: 7.603327751159668\n",
      "Training loss at step 1728: 7.742825508117676\n",
      "Training loss at step 1760: 7.452854633331299\n",
      "Training loss at step 1792: 6.600337505340576\n",
      "Training loss at step 1824: 5.6748552322387695\n",
      "Training loss at step 1856: 4.986907005310059\n",
      "Training loss at step 1888: 4.53974723815918\n",
      "Training loss at step 1920: 4.235415935516357\n",
      "Training loss at step 1952: 4.004544258117676\n",
      "Training loss at step 1984: 3.8536574840545654\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at step 0: 4.012603759765625\n",
      "Training loss at step 32: 3.5851962566375732\n",
      "Training loss at step 64: 3.345207929611206\n",
      "Training loss at step 96: 3.165046453475952\n",
      "Training loss at step 128: 3.0202126502990723\n",
      "Training loss at step 160: 2.9113986492156982\n",
      "Training loss at step 192: 2.842059373855591\n",
      "Training loss at step 224: 2.809995651245117\n",
      "Training loss at step 256: 2.8354790210723877\n",
      "Training loss at step 288: 3.0227911472320557\n",
      "Training loss at step 320: 3.4429149627685547\n",
      "Training loss at step 352: 3.9920144081115723\n",
      "Training loss at step 384: 4.4690961837768555\n",
      "Training loss at step 416: 4.819026947021484\n",
      "Training loss at step 448: 5.060951232910156\n",
      "Training loss at step 480: 5.261940956115723\n",
      "Training loss at step 512: 5.499699592590332\n",
      "Training loss at step 544: 5.776289939880371\n",
      "Training loss at step 576: 6.105093955993652\n",
      "Training loss at step 608: 6.490421772003174\n",
      "Training loss at step 640: 6.912452697753906\n",
      "Training loss at step 672: 7.310637474060059\n",
      "Training loss at step 704: 7.598586082458496\n",
      "Training loss at step 736: 7.6786346435546875\n",
      "Training loss at step 768: 7.241671085357666\n",
      "Training loss at step 800: 6.355353355407715\n",
      "Training loss at step 832: 5.525591850280762\n",
      "Training loss at step 864: 4.972536563873291\n",
      "Training loss at step 896: 4.618046283721924\n",
      "Training loss at step 928: 4.343172073364258\n",
      "Training loss at step 960: 4.11130428314209\n",
      "Training loss at step 992: 3.904031991958618\n",
      "Training loss at step 1024: 3.7112913131713867\n",
      "Training loss at step 1056: 3.517592191696167\n",
      "Training loss at step 1088: 3.309009313583374\n",
      "Training loss at step 1120: 3.1265532970428467\n",
      "Training loss at step 1152: 2.985351324081421\n",
      "Training loss at step 1184: 2.8887476921081543\n",
      "Training loss at step 1216: 2.8324673175811768\n",
      "Training loss at step 1248: 2.8231558799743652\n",
      "Training loss at step 1280: 2.9529056549072266\n",
      "Training loss at step 1312: 3.326054096221924\n",
      "Training loss at step 1344: 3.8722245693206787\n",
      "Training loss at step 1376: 4.400179862976074\n",
      "Training loss at step 1408: 4.824348449707031\n",
      "Training loss at step 1440: 5.141706466674805\n",
      "Training loss at step 1472: 5.3717803955078125\n",
      "Training loss at step 1504: 5.578282356262207\n",
      "Training loss at step 1536: 5.812410354614258\n",
      "Training loss at step 1568: 6.107572555541992\n",
      "Training loss at step 1600: 6.473474502563477\n",
      "Training loss at step 1632: 6.888951301574707\n",
      "Training loss at step 1664: 7.293674945831299\n",
      "Training loss at step 1696: 7.605422496795654\n",
      "Training loss at step 1728: 7.742680549621582\n",
      "Training loss at step 1760: 7.451330184936523\n",
      "Training loss at step 1792: 6.600290298461914\n",
      "Training loss at step 1824: 5.674288272857666\n",
      "Training loss at step 1856: 4.985987663269043\n",
      "Training loss at step 1888: 4.539759159088135\n",
      "Training loss at step 1920: 4.237511157989502\n",
      "Training loss at step 1952: 4.009004592895508\n",
      "Training loss at step 1984: 3.8596179485321045\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at step 0: 4.012973308563232\n",
      "Training loss at step 32: 3.5872347354888916\n",
      "Training loss at step 64: 3.348874092102051\n",
      "Training loss at step 96: 3.1690754890441895\n",
      "Training loss at step 128: 3.0228750705718994\n",
      "Training loss at step 160: 2.913651943206787\n",
      "Training loss at step 192: 2.844266414642334\n",
      "Training loss at step 224: 2.8119454383850098\n",
      "Training loss at step 256: 2.836519241333008\n",
      "Training loss at step 288: 3.021965503692627\n",
      "Training loss at step 320: 3.440415620803833\n",
      "Training loss at step 352: 3.98850679397583\n",
      "Training loss at step 384: 4.465124130249023\n",
      "Training loss at step 416: 4.8139262199401855\n",
      "Training loss at step 448: 5.0579352378845215\n",
      "Training loss at step 480: 5.261789321899414\n",
      "Training loss at step 512: 5.4996771812438965\n",
      "Training loss at step 544: 5.7762346267700195\n",
      "Training loss at step 576: 6.105146408081055\n",
      "Training loss at step 608: 6.49055290222168\n",
      "Training loss at step 640: 6.912771701812744\n",
      "Training loss at step 672: 7.310801029205322\n",
      "Training loss at step 704: 7.59771728515625\n",
      "Training loss at step 736: 7.677757263183594\n",
      "Training loss at step 768: 7.241133213043213\n",
      "Training loss at step 800: 6.355411529541016\n",
      "Training loss at step 832: 5.526220798492432\n",
      "Training loss at step 864: 4.974263668060303\n",
      "Training loss at step 896: 4.616025447845459\n",
      "Training loss at step 928: 4.343615531921387\n",
      "Training loss at step 960: 4.111451148986816\n",
      "Training loss at step 992: 3.903907537460327\n",
      "Training loss at step 1024: 3.710556983947754\n",
      "Training loss at step 1056: 3.517056703567505\n",
      "Training loss at step 1088: 3.309065341949463\n",
      "Training loss at step 1120: 3.1260061264038086\n",
      "Training loss at step 1152: 2.98427414894104\n",
      "Training loss at step 1184: 2.8874824047088623\n",
      "Training loss at step 1216: 2.8312909603118896\n",
      "Training loss at step 1248: 2.8223984241485596\n",
      "Training loss at step 1280: 2.9529788494110107\n",
      "Training loss at step 1312: 3.326366424560547\n",
      "Training loss at step 1344: 3.871276378631592\n",
      "Training loss at step 1376: 4.396031379699707\n",
      "Training loss at step 1408: 4.822164058685303\n",
      "Training loss at step 1440: 5.140273571014404\n",
      "Training loss at step 1472: 5.369913101196289\n",
      "Training loss at step 1504: 5.573634147644043\n",
      "Training loss at step 1536: 5.807663440704346\n",
      "Training loss at step 1568: 6.102943420410156\n",
      "Training loss at step 1600: 6.4683427810668945\n",
      "Training loss at step 1632: 6.882980823516846\n",
      "Training loss at step 1664: 7.2870941162109375\n",
      "Training loss at step 1696: 7.600768566131592\n",
      "Training loss at step 1728: 7.737226486206055\n",
      "Training loss at step 1760: 7.4485931396484375\n",
      "Training loss at step 1792: 6.59910774230957\n",
      "Training loss at step 1824: 5.675200462341309\n",
      "Training loss at step 1856: 4.986798286437988\n",
      "Training loss at step 1888: 4.538992404937744\n",
      "Training loss at step 1920: 4.235408782958984\n",
      "Training loss at step 1952: 4.005865097045898\n",
      "Training loss at step 1984: 3.8555476665496826\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at step 0: 4.007041931152344\n",
      "Training loss at step 32: 3.5778820514678955\n",
      "Training loss at step 64: 3.338514804840088\n",
      "Training loss at step 96: 3.159177780151367\n",
      "Training loss at step 128: 3.0154237747192383\n",
      "Training loss at step 160: 2.908421516418457\n",
      "Training loss at step 192: 2.840641736984253\n",
      "Training loss at step 224: 2.8096189498901367\n",
      "Training loss at step 256: 2.835709810256958\n",
      "Training loss at step 288: 3.0221011638641357\n",
      "Training loss at step 320: 3.44044828414917\n",
      "Training loss at step 352: 3.9865493774414062\n",
      "Training loss at step 384: 4.460615158081055\n",
      "Training loss at step 416: 4.809902191162109\n",
      "Training loss at step 448: 5.05458402633667\n",
      "Training loss at step 480: 5.261215686798096\n",
      "Training loss at step 512: 5.499660015106201\n",
      "Training loss at step 544: 5.776192665100098\n",
      "Training loss at step 576: 6.105065822601318\n",
      "Training loss at step 608: 6.489870071411133\n",
      "Training loss at step 640: 6.910920143127441\n",
      "Training loss at step 672: 7.307723522186279\n",
      "Training loss at step 704: 7.593260765075684\n",
      "Training loss at step 736: 7.673161506652832\n",
      "Training loss at step 768: 7.238187789916992\n",
      "Training loss at step 800: 6.355855464935303\n",
      "Training loss at step 832: 5.530544757843018\n",
      "Training loss at step 864: 4.979647636413574\n",
      "Training loss at step 896: 4.616944789886475\n",
      "Training loss at step 928: 4.342164993286133\n",
      "Training loss at step 960: 4.112475395202637\n",
      "Training loss at step 992: 3.906928777694702\n",
      "Training loss at step 1024: 3.7158315181732178\n",
      "Training loss at step 1056: 3.5269978046417236\n",
      "Training loss at step 1088: 3.3214526176452637\n",
      "Training loss at step 1120: 3.1376800537109375\n",
      "Training loss at step 1152: 2.994624376296997\n",
      "Training loss at step 1184: 2.8962130546569824\n",
      "Training loss at step 1216: 2.8380298614501953\n",
      "Training loss at step 1248: 2.8262829780578613\n",
      "Training loss at step 1280: 2.9522664546966553\n",
      "Training loss at step 1312: 3.3222885131835938\n",
      "Training loss at step 1344: 3.867255210876465\n",
      "Training loss at step 1376: 4.394489288330078\n",
      "Training loss at step 1408: 4.826938629150391\n",
      "Training loss at step 1440: 5.1474714279174805\n",
      "Training loss at step 1472: 5.377885341644287\n",
      "Training loss at step 1504: 5.581951141357422\n",
      "Training loss at step 1536: 5.815545082092285\n",
      "Training loss at step 1568: 6.110109806060791\n",
      "Training loss at step 1600: 6.474870681762695\n",
      "Training loss at step 1632: 6.889142990112305\n",
      "Training loss at step 1664: 7.293548583984375\n",
      "Training loss at step 1696: 7.602036476135254\n",
      "Training loss at step 1728: 7.734929084777832\n",
      "Training loss at step 1760: 7.4452691078186035\n",
      "Training loss at step 1792: 6.598204135894775\n",
      "Training loss at step 1824: 5.674672603607178\n",
      "Training loss at step 1856: 4.987083911895752\n",
      "Training loss at step 1888: 4.53684139251709\n",
      "Training loss at step 1920: 4.230926990509033\n",
      "Training loss at step 1952: 4.0019965171813965\n",
      "Training loss at step 1984: 3.852015256881714\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at step 0: 4.008046627044678\n",
      "Training loss at step 32: 3.5814476013183594\n",
      "Training loss at step 64: 3.3446221351623535\n",
      "Training loss at step 96: 3.1643762588500977\n",
      "Training loss at step 128: 3.018101930618286\n",
      "Training loss at step 160: 2.9092137813568115\n",
      "Training loss at step 192: 2.8402512073516846\n",
      "Training loss at step 224: 2.80871319770813\n",
      "Training loss at step 256: 2.834981918334961\n",
      "Training loss at step 288: 3.0228588581085205\n",
      "Training loss at step 320: 3.441946268081665\n",
      "Training loss at step 352: 3.9880738258361816\n",
      "Training loss at step 384: 4.464376449584961\n",
      "Training loss at step 416: 4.8153462409973145\n",
      "Training loss at step 448: 5.059178352355957\n",
      "Training loss at step 480: 5.263271331787109\n",
      "Training loss at step 512: 5.500166416168213\n",
      "Training loss at step 544: 5.776252269744873\n",
      "Training loss at step 576: 6.105255603790283\n",
      "Training loss at step 608: 6.490325450897217\n",
      "Training loss at step 640: 6.911716938018799\n",
      "Training loss at step 672: 7.308704853057861\n",
      "Training loss at step 704: 7.593691825866699\n",
      "Training loss at step 736: 7.671430587768555\n",
      "Training loss at step 768: 7.236800193786621\n",
      "Training loss at step 800: 6.3560919761657715\n",
      "Training loss at step 832: 5.532368183135986\n",
      "Training loss at step 864: 4.9811859130859375\n",
      "Training loss at step 896: 4.610170841217041\n",
      "Training loss at step 928: 4.336254596710205\n",
      "Training loss at step 960: 4.106144905090332\n",
      "Training loss at step 992: 3.900709629058838\n",
      "Training loss at step 1024: 3.7093474864959717\n",
      "Training loss at step 1056: 3.5197768211364746\n",
      "Training loss at step 1088: 3.315629243850708\n",
      "Training loss at step 1120: 3.133173942565918\n",
      "Training loss at step 1152: 2.9909183979034424\n",
      "Training loss at step 1184: 2.893599510192871\n",
      "Training loss at step 1216: 2.8362627029418945\n",
      "Training loss at step 1248: 2.825493812561035\n",
      "Training loss at step 1280: 2.952404022216797\n",
      "Training loss at step 1312: 3.322218418121338\n",
      "Training loss at step 1344: 3.8654532432556152\n",
      "Training loss at step 1376: 4.389582633972168\n",
      "Training loss at step 1408: 4.822834491729736\n",
      "Training loss at step 1440: 5.143649101257324\n",
      "Training loss at step 1472: 5.373909950256348\n",
      "Training loss at step 1504: 5.57706356048584\n",
      "Training loss at step 1536: 5.810818672180176\n",
      "Training loss at step 1568: 6.106759071350098\n",
      "Training loss at step 1600: 6.471659183502197\n",
      "Training loss at step 1632: 6.883974552154541\n",
      "Training loss at step 1664: 7.279831409454346\n",
      "Training loss at step 1696: 7.583518981933594\n",
      "Training loss at step 1728: 7.71490478515625\n",
      "Training loss at step 1760: 7.427253723144531\n",
      "Training loss at step 1792: 6.591789722442627\n",
      "Training loss at step 1824: 5.6828765869140625\n",
      "Training loss at step 1856: 5.000817775726318\n",
      "Training loss at step 1888: 4.550083637237549\n",
      "Training loss at step 1920: 4.237330436706543\n",
      "Training loss at step 1952: 3.9982221126556396\n",
      "Training loss at step 1984: 3.8471455574035645\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at step 0: 4.005143642425537\n",
      "Training loss at step 32: 3.5764172077178955\n",
      "Training loss at step 64: 3.3385136127471924\n",
      "Training loss at step 96: 3.1608407497406006\n",
      "Training loss at step 128: 3.0157957077026367\n",
      "Training loss at step 160: 2.9071826934814453\n",
      "Training loss at step 192: 2.838543653488159\n",
      "Training loss at step 224: 2.8074958324432373\n",
      "Training loss at step 256: 2.834534168243408\n",
      "Training loss at step 288: 3.0230164527893066\n",
      "Training loss at step 320: 3.44150972366333\n",
      "Training loss at step 352: 3.9858975410461426\n",
      "Training loss at step 384: 4.461879253387451\n",
      "Training loss at step 416: 4.814423561096191\n",
      "Training loss at step 448: 5.059657096862793\n",
      "Training loss at step 480: 5.264435768127441\n",
      "Training loss at step 512: 5.5007710456848145\n",
      "Training loss at step 544: 5.776451110839844\n",
      "Training loss at step 576: 6.105332851409912\n",
      "Training loss at step 608: 6.489569664001465\n",
      "Training loss at step 640: 6.90713357925415\n",
      "Training loss at step 672: 7.299331188201904\n",
      "Training loss at step 704: 7.5816450119018555\n",
      "Training loss at step 736: 7.659833908081055\n",
      "Training loss at step 768: 7.229290962219238\n",
      "Training loss at step 800: 6.358218669891357\n",
      "Training loss at step 832: 5.545492172241211\n",
      "Training loss at step 864: 4.991236686706543\n",
      "Training loss at step 896: 4.599567890167236\n",
      "Training loss at step 928: 4.320641040802002\n",
      "Training loss at step 960: 4.091816425323486\n",
      "Training loss at step 992: 3.888597011566162\n",
      "Training loss at step 1024: 3.7025909423828125\n",
      "Training loss at step 1056: 3.51904034614563\n",
      "Training loss at step 1088: 3.3183653354644775\n",
      "Training loss at step 1120: 3.1360554695129395\n",
      "Training loss at step 1152: 2.9938509464263916\n",
      "Training loss at step 1184: 2.896487236022949\n",
      "Training loss at step 1216: 2.8383114337921143\n",
      "Training loss at step 1248: 2.8264474868774414\n",
      "Training loss at step 1280: 2.952488899230957\n",
      "Training loss at step 1312: 3.3235130310058594\n",
      "Training loss at step 1344: 3.869554042816162\n",
      "Training loss at step 1376: 4.396729469299316\n",
      "Training loss at step 1408: 4.837592124938965\n",
      "Training loss at step 1440: 5.1604461669921875\n",
      "Training loss at step 1472: 5.390172958374023\n",
      "Training loss at step 1504: 5.591884136199951\n",
      "Training loss at step 1536: 5.823093414306641\n",
      "Training loss at step 1568: 6.11856746673584\n",
      "Training loss at step 1600: 6.483461380004883\n",
      "Training loss at step 1632: 6.896694660186768\n",
      "Training loss at step 1664: 7.293518543243408\n",
      "Training loss at step 1696: 7.592039108276367\n",
      "Training loss at step 1728: 7.722444534301758\n",
      "Training loss at step 1760: 7.431159019470215\n",
      "Training loss at step 1792: 6.592496395111084\n",
      "Training loss at step 1824: 5.681945323944092\n",
      "Training loss at step 1856: 4.995645523071289\n",
      "Training loss at step 1888: 4.544032573699951\n",
      "Training loss at step 1920: 4.233333587646484\n",
      "Training loss at step 1952: 4.000248908996582\n",
      "Training loss at step 1984: 3.851418972015381\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at step 0: 4.004141807556152\n",
      "Training loss at step 32: 3.5747487545013428\n",
      "Training loss at step 64: 3.3377628326416016\n",
      "Training loss at step 96: 3.16107177734375\n",
      "Training loss at step 128: 3.0191397666931152\n",
      "Training loss at step 160: 2.9125051498413086\n",
      "Training loss at step 192: 2.8443117141723633\n",
      "Training loss at step 224: 2.8130664825439453\n",
      "Training loss at step 256: 2.837830066680908\n",
      "Training loss at step 288: 3.0207858085632324\n",
      "Training loss at step 320: 3.4344215393066406\n",
      "Training loss at step 352: 3.97714900970459\n",
      "Training loss at step 384: 4.453143119812012\n",
      "Training loss at step 416: 4.807845115661621\n",
      "Training loss at step 448: 5.056341171264648\n",
      "Training loss at step 480: 5.264115333557129\n",
      "Training loss at step 512: 5.5008392333984375\n",
      "Training loss at step 544: 5.776607036590576\n",
      "Training loss at step 576: 6.105363845825195\n",
      "Training loss at step 608: 6.489609241485596\n",
      "Training loss at step 640: 6.907819747924805\n",
      "Training loss at step 672: 7.300349235534668\n",
      "Training loss at step 704: 7.581327438354492\n",
      "Training loss at step 736: 7.659356594085693\n",
      "Training loss at step 768: 7.229203224182129\n",
      "Training loss at step 800: 6.3581342697143555\n",
      "Training loss at step 832: 5.544785976409912\n",
      "Training loss at step 864: 4.993072986602783\n",
      "Training loss at step 896: 4.601635456085205\n",
      "Training loss at step 928: 4.319136619567871\n",
      "Training loss at step 960: 4.091899394989014\n",
      "Training loss at step 992: 3.8891870975494385\n",
      "Training loss at step 1024: 3.7006688117980957\n",
      "Training loss at step 1056: 3.514861822128296\n",
      "Training loss at step 1088: 3.313685894012451\n",
      "Training loss at step 1120: 3.1320996284484863\n",
      "Training loss at step 1152: 2.9902217388153076\n",
      "Training loss at step 1184: 2.8933160305023193\n",
      "Training loss at step 1216: 2.835937738418579\n",
      "Training loss at step 1248: 2.825162172317505\n",
      "Training loss at step 1280: 2.9524199962615967\n",
      "Training loss at step 1312: 3.3230268955230713\n",
      "Training loss at step 1344: 3.8666985034942627\n",
      "Training loss at step 1376: 4.3896589279174805\n",
      "Training loss at step 1408: 4.82729959487915\n",
      "Training loss at step 1440: 5.15044641494751\n",
      "Training loss at step 1472: 5.38136625289917\n",
      "Training loss at step 1504: 5.584743022918701\n",
      "Training loss at step 1536: 5.817298889160156\n",
      "Training loss at step 1568: 6.112928867340088\n",
      "Training loss at step 1600: 6.477893829345703\n",
      "Training loss at step 1632: 6.8873701095581055\n",
      "Training loss at step 1664: 7.275848388671875\n",
      "Training loss at step 1696: 7.576773643493652\n",
      "Training loss at step 1728: 7.707002639770508\n",
      "Training loss at step 1760: 7.420198440551758\n",
      "Training loss at step 1792: 6.590197563171387\n",
      "Training loss at step 1824: 5.686102867126465\n",
      "Training loss at step 1856: 5.005114555358887\n",
      "Training loss at step 1888: 4.55183744430542\n",
      "Training loss at step 1920: 4.239608287811279\n",
      "Training loss at step 1952: 3.998868942260742\n",
      "Training loss at step 1984: 3.848510265350342\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at step 0: 3.999149799346924\n",
      "Training loss at step 32: 3.5652575492858887\n",
      "Training loss at step 64: 3.327498435974121\n",
      "Training loss at step 96: 3.1507229804992676\n",
      "Training loss at step 128: 3.008282423019409\n",
      "Training loss at step 160: 2.9020934104919434\n",
      "Training loss at step 192: 2.83595609664917\n",
      "Training loss at step 224: 2.807220935821533\n",
      "Training loss at step 256: 2.835167169570923\n",
      "Training loss at step 288: 3.0218632221221924\n",
      "Training loss at step 320: 3.4371867179870605\n",
      "Training loss at step 352: 3.977235794067383\n",
      "Training loss at step 384: 4.450952529907227\n",
      "Training loss at step 416: 4.804049491882324\n",
      "Training loss at step 448: 5.050384998321533\n",
      "Training loss at step 480: 5.261322021484375\n",
      "Training loss at step 512: 5.50022554397583\n",
      "Training loss at step 544: 5.776361465454102\n",
      "Training loss at step 576: 6.104957580566406\n",
      "Training loss at step 608: 6.488239288330078\n",
      "Training loss at step 640: 6.904057502746582\n",
      "Training loss at step 672: 7.294116497039795\n",
      "Training loss at step 704: 7.573751449584961\n",
      "Training loss at step 736: 7.652048587799072\n",
      "Training loss at step 768: 7.224973678588867\n",
      "Training loss at step 800: 6.359902381896973\n",
      "Training loss at step 832: 5.551781177520752\n",
      "Training loss at step 864: 4.9988484382629395\n",
      "Training loss at step 896: 4.605325698852539\n",
      "Training loss at step 928: 4.325801372528076\n",
      "Training loss at step 960: 4.102683067321777\n",
      "Training loss at step 992: 3.9036197662353516\n",
      "Training loss at step 1024: 3.720365285873413\n",
      "Training loss at step 1056: 3.5426037311553955\n",
      "Training loss at step 1088: 3.345097303390503\n",
      "Training loss at step 1120: 3.1626124382019043\n",
      "Training loss at step 1152: 3.0178050994873047\n",
      "Training loss at step 1184: 2.917278528213501\n",
      "Training loss at step 1216: 2.8547329902648926\n",
      "Training loss at step 1248: 2.8363986015319824\n",
      "Training loss at step 1280: 2.9517288208007812\n",
      "Training loss at step 1312: 3.3142213821411133\n",
      "Training loss at step 1344: 3.8587589263916016\n",
      "Training loss at step 1376: 4.389605522155762\n",
      "Training loss at step 1408: 4.836340427398682\n",
      "Training loss at step 1440: 5.164177894592285\n",
      "Training loss at step 1472: 5.397078514099121\n",
      "Training loss at step 1504: 5.600489616394043\n",
      "Training loss at step 1536: 5.832728385925293\n",
      "Training loss at step 1568: 6.126591205596924\n",
      "Training loss at step 1600: 6.491151809692383\n",
      "Training loss at step 1632: 6.902824401855469\n",
      "Training loss at step 1664: 7.292233943939209\n",
      "Training loss at step 1696: 7.589273929595947\n",
      "Training loss at step 1728: 7.716069221496582\n",
      "Training loss at step 1760: 7.427764415740967\n",
      "Training loss at step 1792: 6.592354774475098\n",
      "Training loss at step 1824: 5.681207656860352\n",
      "Training loss at step 1856: 4.9923014640808105\n",
      "Training loss at step 1888: 4.533751010894775\n",
      "Training loss at step 1920: 4.219842910766602\n",
      "Training loss at step 1952: 3.984304904937744\n",
      "Training loss at step 1984: 3.8360488414764404\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at step 0: 4.001492023468018\n",
      "Training loss at step 32: 3.5722622871398926\n",
      "Training loss at step 64: 3.3372182846069336\n",
      "Training loss at step 96: 3.160849094390869\n",
      "Training loss at step 128: 3.016146183013916\n",
      "Training loss at step 160: 2.9080305099487305\n",
      "Training loss at step 192: 2.839845895767212\n",
      "Training loss at step 224: 2.8090734481811523\n",
      "Training loss at step 256: 2.8355953693389893\n",
      "Training loss at step 288: 3.021902322769165\n",
      "Training loss at step 320: 3.437520980834961\n",
      "Training loss at step 352: 3.9794955253601074\n",
      "Training loss at step 384: 4.460616588592529\n",
      "Training loss at step 416: 4.815537452697754\n",
      "Training loss at step 448: 5.061708450317383\n",
      "Training loss at step 480: 5.267061233520508\n",
      "Training loss at step 512: 5.501952648162842\n",
      "Training loss at step 544: 5.7771759033203125\n",
      "Training loss at step 576: 6.105401992797852\n",
      "Training loss at step 608: 6.489160060882568\n",
      "Training loss at step 640: 6.905825614929199\n",
      "Training loss at step 672: 7.296682357788086\n",
      "Training loss at step 704: 7.576794624328613\n",
      "Training loss at step 736: 7.653685569763184\n",
      "Training loss at step 768: 7.225912094116211\n",
      "Training loss at step 800: 6.359553813934326\n",
      "Training loss at step 832: 5.549458980560303\n",
      "Training loss at step 864: 4.99123477935791\n",
      "Training loss at step 896: 4.595685005187988\n",
      "Training loss at step 928: 4.310989856719971\n",
      "Training loss at step 960: 4.085589408874512\n",
      "Training loss at step 992: 3.884998083114624\n",
      "Training loss at step 1024: 3.698354482650757\n",
      "Training loss at step 1056: 3.5131092071533203\n",
      "Training loss at step 1088: 3.3130147457122803\n",
      "Training loss at step 1120: 3.13249135017395\n",
      "Training loss at step 1152: 2.9913666248321533\n",
      "Training loss at step 1184: 2.894881248474121\n",
      "Training loss at step 1216: 2.8373711109161377\n",
      "Training loss at step 1248: 2.8261160850524902\n",
      "Training loss at step 1280: 2.952340841293335\n",
      "Training loss at step 1312: 3.3222715854644775\n",
      "Training loss at step 1344: 3.8661956787109375\n",
      "Training loss at step 1376: 4.388545513153076\n",
      "Training loss at step 1408: 4.822822570800781\n",
      "Training loss at step 1440: 5.147047996520996\n",
      "Training loss at step 1472: 5.379438400268555\n",
      "Training loss at step 1504: 5.584410667419434\n",
      "Training loss at step 1536: 5.818802356719971\n",
      "Training loss at step 1568: 6.114597320556641\n",
      "Training loss at step 1600: 6.4794745445251465\n",
      "Training loss at step 1632: 6.889192581176758\n",
      "Training loss at step 1664: 7.278221607208252\n",
      "Training loss at step 1696: 7.576542377471924\n",
      "Training loss at step 1728: 7.705230236053467\n",
      "Training loss at step 1760: 7.419693946838379\n",
      "Training loss at step 1792: 6.590167045593262\n",
      "Training loss at step 1824: 5.68470573425293\n",
      "Training loss at step 1856: 4.997804641723633\n",
      "Training loss at step 1888: 4.538576602935791\n",
      "Training loss at step 1920: 4.2249274253845215\n",
      "Training loss at step 1952: 3.992973804473877\n",
      "Training loss at step 1984: 3.8442494869232178\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at step 0: 3.9999804496765137\n",
      "Training loss at step 32: 3.5682477951049805\n",
      "Training loss at step 64: 3.3329241275787354\n",
      "Training loss at step 96: 3.157474994659424\n",
      "Training loss at step 128: 3.0155580043792725\n",
      "Training loss at step 160: 2.90798020362854\n",
      "Training loss at step 192: 2.8401618003845215\n",
      "Training loss at step 224: 2.8097028732299805\n",
      "Training loss at step 256: 2.8361454010009766\n",
      "Training loss at step 288: 3.0213873386383057\n",
      "Training loss at step 320: 3.4354326725006104\n",
      "Training loss at step 352: 3.9760851860046387\n",
      "Training loss at step 384: 4.454013824462891\n",
      "Training loss at step 416: 4.810189723968506\n",
      "Training loss at step 448: 5.059093952178955\n",
      "Training loss at step 480: 5.267423629760742\n",
      "Training loss at step 512: 5.502711296081543\n",
      "Training loss at step 544: 5.777791976928711\n",
      "Training loss at step 576: 6.1060791015625\n",
      "Training loss at step 608: 6.490527629852295\n",
      "Training loss at step 640: 6.908799171447754\n",
      "Training loss at step 672: 7.301446914672852\n",
      "Training loss at step 704: 7.583232879638672\n",
      "Training loss at step 736: 7.660261154174805\n",
      "Training loss at step 768: 7.229038715362549\n",
      "Training loss at step 800: 6.358299255371094\n",
      "Training loss at step 832: 5.542914390563965\n",
      "Training loss at step 864: 4.981130599975586\n",
      "Training loss at step 896: 4.587724685668945\n",
      "Training loss at step 928: 4.305190086364746\n",
      "Training loss at step 960: 4.082694053649902\n",
      "Training loss at step 992: 3.8845322132110596\n",
      "Training loss at step 1024: 3.7008419036865234\n",
      "Training loss at step 1056: 3.520545721054077\n",
      "Training loss at step 1088: 3.322448492050171\n",
      "Training loss at step 1120: 3.142002820968628\n",
      "Training loss at step 1152: 2.9996836185455322\n",
      "Training loss at step 1184: 2.9017858505249023\n",
      "Training loss at step 1216: 2.842653751373291\n",
      "Training loss at step 1248: 2.8291077613830566\n",
      "Training loss at step 1280: 2.9519076347351074\n",
      "Training loss at step 1312: 3.3195672035217285\n",
      "Training loss at step 1344: 3.8636341094970703\n",
      "Training loss at step 1376: 4.388692855834961\n",
      "Training loss at step 1408: 4.827200889587402\n",
      "Training loss at step 1440: 5.153809547424316\n",
      "Training loss at step 1472: 5.386992454528809\n",
      "Training loss at step 1504: 5.591785430908203\n",
      "Training loss at step 1536: 5.82307243347168\n",
      "Training loss at step 1568: 6.1157331466674805\n",
      "Training loss at step 1600: 6.48048210144043\n",
      "Training loss at step 1632: 6.885590553283691\n",
      "Training loss at step 1664: 7.27318000793457\n",
      "Training loss at step 1696: 7.5736083984375\n",
      "Training loss at step 1728: 7.704662799835205\n",
      "Training loss at step 1760: 7.419046401977539\n",
      "Training loss at step 1792: 6.590166091918945\n",
      "Training loss at step 1824: 5.685357093811035\n",
      "Training loss at step 1856: 5.001115798950195\n",
      "Training loss at step 1888: 4.540517330169678\n",
      "Training loss at step 1920: 4.224980354309082\n",
      "Training loss at step 1952: 3.9889285564422607\n",
      "Training loss at step 1984: 3.8406639099121094\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at step 0: 3.9986321926116943\n",
      "Training loss at step 32: 3.5646865367889404\n",
      "Training loss at step 64: 3.328442335128784\n",
      "Training loss at step 96: 3.152867555618286\n",
      "Training loss at step 128: 3.011533498764038\n",
      "Training loss at step 160: 2.9067118167877197\n",
      "Training loss at step 192: 2.8401637077331543\n",
      "Training loss at step 224: 2.810345411300659\n",
      "Training loss at step 256: 2.836937189102173\n",
      "Training loss at step 288: 3.0204567909240723\n",
      "Training loss at step 320: 3.4310851097106934\n",
      "Training loss at step 352: 3.9682626724243164\n",
      "Training loss at step 384: 4.4452009201049805\n",
      "Training loss at step 416: 4.802587509155273\n",
      "Training loss at step 448: 5.054299354553223\n",
      "Training loss at step 480: 5.265947341918945\n",
      "Training loss at step 512: 5.502022743225098\n",
      "Training loss at step 544: 5.777257919311523\n",
      "Training loss at step 576: 6.105338096618652\n",
      "Training loss at step 608: 6.488855361938477\n",
      "Training loss at step 640: 6.904539108276367\n",
      "Training loss at step 672: 7.294363975524902\n",
      "Training loss at step 704: 7.574821472167969\n",
      "Training loss at step 736: 7.654349327087402\n",
      "Training loss at step 768: 7.226681709289551\n",
      "Training loss at step 800: 6.359381198883057\n",
      "Training loss at step 832: 5.5480780601501465\n",
      "Training loss at step 864: 4.9866838455200195\n",
      "Training loss at step 896: 4.589224815368652\n",
      "Training loss at step 928: 4.305478096008301\n",
      "Training loss at step 960: 4.082685947418213\n",
      "Training loss at step 992: 3.884493112564087\n",
      "Training loss at step 1024: 3.7005116939544678\n",
      "Training loss at step 1056: 3.5194451808929443\n",
      "Training loss at step 1088: 3.320794105529785\n",
      "Training loss at step 1120: 3.1406655311584473\n",
      "Training loss at step 1152: 2.998420238494873\n",
      "Training loss at step 1184: 2.900791883468628\n",
      "Training loss at step 1216: 2.8418312072753906\n",
      "Training loss at step 1248: 2.828598737716675\n",
      "Training loss at step 1280: 2.951953887939453\n",
      "Training loss at step 1312: 3.319899320602417\n",
      "Training loss at step 1344: 3.8635525703430176\n",
      "Training loss at step 1376: 4.388025283813477\n",
      "Training loss at step 1408: 4.824658393859863\n",
      "Training loss at step 1440: 5.1518120765686035\n",
      "Training loss at step 1472: 5.386396408081055\n",
      "Training loss at step 1504: 5.5929718017578125\n",
      "Training loss at step 1536: 5.826746940612793\n",
      "Training loss at step 1568: 6.121570587158203\n",
      "Training loss at step 1600: 6.486249923706055\n",
      "Training loss at step 1632: 6.8953728675842285\n",
      "Training loss at step 1664: 7.2847981452941895\n",
      "Training loss at step 1696: 7.582827568054199\n",
      "Training loss at step 1728: 7.7101216316223145\n",
      "Training loss at step 1760: 7.421905040740967\n",
      "Training loss at step 1792: 6.590795993804932\n",
      "Training loss at step 1824: 5.682843208312988\n",
      "Training loss at step 1856: 4.994969367980957\n",
      "Training loss at step 1888: 4.534118175506592\n",
      "Training loss at step 1920: 4.220862865447998\n",
      "Training loss at step 1952: 3.9910008907318115\n",
      "Training loss at step 1984: 3.843843460083008\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at step 0: 3.997680187225342\n",
      "Training loss at step 32: 3.5615789890289307\n",
      "Training loss at step 64: 3.3247547149658203\n",
      "Training loss at step 96: 3.1490869522094727\n",
      "Training loss at step 128: 3.0070767402648926\n",
      "Training loss at step 160: 2.901538133621216\n",
      "Training loss at step 192: 2.8365697860717773\n",
      "Training loss at step 224: 2.8091933727264404\n",
      "Training loss at step 256: 2.837181568145752\n",
      "Training loss at step 288: 3.0199196338653564\n",
      "Training loss at step 320: 3.428572177886963\n",
      "Training loss at step 352: 3.962810754776001\n",
      "Training loss at step 384: 4.439247131347656\n",
      "Training loss at step 416: 4.795441150665283\n",
      "Training loss at step 448: 5.047519683837891\n",
      "Training loss at step 480: 5.264077186584473\n",
      "Training loss at step 512: 5.501827239990234\n",
      "Training loss at step 544: 5.777365684509277\n",
      "Training loss at step 576: 6.105588912963867\n",
      "Training loss at step 608: 6.489556312561035\n",
      "Training loss at step 640: 6.905977249145508\n",
      "Training loss at step 672: 7.296721458435059\n",
      "Training loss at step 704: 7.578075885772705\n",
      "Training loss at step 736: 7.656026840209961\n",
      "Training loss at step 768: 7.2267560958862305\n",
      "Training loss at step 800: 6.359585762023926\n",
      "Training loss at step 832: 5.548872947692871\n",
      "Training loss at step 864: 4.9855756759643555\n",
      "Training loss at step 896: 4.59284782409668\n",
      "Training loss at step 928: 4.308977127075195\n",
      "Training loss at step 960: 4.088451862335205\n",
      "Training loss at step 992: 3.8925564289093018\n",
      "Training loss at step 1024: 3.709998607635498\n",
      "Training loss at step 1056: 3.5325324535369873\n",
      "Training loss at step 1088: 3.336190938949585\n",
      "Training loss at step 1120: 3.1557631492614746\n",
      "Training loss at step 1152: 3.0123634338378906\n",
      "Training loss at step 1184: 2.913109064102173\n",
      "Training loss at step 1216: 2.8518123626708984\n",
      "Training loss at step 1248: 2.834810256958008\n",
      "Training loss at step 1280: 2.9516944885253906\n",
      "Training loss at step 1312: 3.3144657611846924\n",
      "Training loss at step 1344: 3.8575758934020996\n",
      "Training loss at step 1376: 4.384333610534668\n",
      "Training loss at step 1408: 4.823825359344482\n",
      "Training loss at step 1440: 5.153505802154541\n",
      "Training loss at step 1472: 5.389299392700195\n",
      "Training loss at step 1504: 5.59591007232666\n",
      "Training loss at step 1536: 5.828186988830566\n",
      "Training loss at step 1568: 6.121387481689453\n",
      "Training loss at step 1600: 6.483600616455078\n",
      "Training loss at step 1632: 6.883269786834717\n",
      "Training loss at step 1664: 7.27155876159668\n",
      "Training loss at step 1696: 7.574908256530762\n",
      "Training loss at step 1728: 7.706162452697754\n",
      "Training loss at step 1760: 7.419641494750977\n",
      "Training loss at step 1792: 6.590051651000977\n",
      "Training loss at step 1824: 5.685654640197754\n",
      "Training loss at step 1856: 5.000298500061035\n",
      "Training loss at step 1888: 4.537082672119141\n",
      "Training loss at step 1920: 4.218270301818848\n",
      "Training loss at step 1952: 3.9782071113586426\n",
      "Training loss at step 1984: 3.829944133758545\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at step 0: 3.9989118576049805\n",
      "Training loss at step 32: 3.5664799213409424\n",
      "Training loss at step 64: 3.3316707611083984\n",
      "Training loss at step 96: 3.1570088863372803\n",
      "Training loss at step 128: 3.015122175216675\n",
      "Training loss at step 160: 2.907576322555542\n",
      "Training loss at step 192: 2.8399856090545654\n",
      "Training loss at step 224: 2.8098220825195312\n",
      "Training loss at step 256: 2.83640193939209\n",
      "Training loss at step 288: 3.0208332538604736\n",
      "Training loss at step 320: 3.432605504989624\n",
      "Training loss at step 352: 3.9700357913970947\n",
      "Training loss at step 384: 4.454714298248291\n",
      "Training loss at step 416: 4.8111138343811035\n",
      "Training loss at step 448: 5.060176849365234\n",
      "Training loss at step 480: 5.269747734069824\n",
      "Training loss at step 512: 5.503840446472168\n",
      "Training loss at step 544: 5.778189182281494\n",
      "Training loss at step 576: 6.10573673248291\n",
      "Training loss at step 608: 6.489326000213623\n",
      "Training loss at step 640: 6.904998779296875\n",
      "Training loss at step 672: 7.295384883880615\n",
      "Training loss at step 704: 7.575648307800293\n",
      "Training loss at step 736: 7.653772830963135\n",
      "Training loss at step 768: 7.225912094116211\n",
      "Training loss at step 800: 6.360012531280518\n",
      "Training loss at step 832: 5.55103063583374\n",
      "Training loss at step 864: 4.977491855621338\n",
      "Training loss at step 896: 4.568391799926758\n",
      "Training loss at step 928: 4.2862772941589355\n",
      "Training loss at step 960: 4.062740325927734\n",
      "Training loss at step 992: 3.864842414855957\n",
      "Training loss at step 1024: 3.6850426197052\n",
      "Training loss at step 1056: 3.5053610801696777\n",
      "Training loss at step 1088: 3.3058602809906006\n",
      "Training loss at step 1120: 3.1275010108947754\n",
      "Training loss at step 1152: 2.9868290424346924\n",
      "Training loss at step 1184: 2.8894717693328857\n",
      "Training loss at step 1216: 2.8313398361206055\n",
      "Training loss at step 1248: 2.820906400680542\n",
      "Training loss at step 1280: 2.954223871231079\n",
      "Training loss at step 1312: 3.3379828929901123\n",
      "Training loss at step 1344: 3.9004149436950684\n",
      "Training loss at step 1376: 4.436887741088867\n",
      "Training loss at step 1408: 4.883621692657471\n",
      "Training loss at step 1440: 5.206571578979492\n",
      "Training loss at step 1472: 5.427842140197754\n",
      "Training loss at step 1504: 5.62175178527832\n",
      "Training loss at step 1536: 5.845515251159668\n",
      "Training loss at step 1568: 6.13415002822876\n",
      "Training loss at step 1600: 6.489365577697754\n",
      "Training loss at step 1632: 6.892653942108154\n",
      "Training loss at step 1664: 7.284416675567627\n",
      "Training loss at step 1696: 7.578018665313721\n",
      "Training loss at step 1728: 7.704850196838379\n",
      "Training loss at step 1760: 7.415409564971924\n",
      "Training loss at step 1792: 6.588863372802734\n",
      "Training loss at step 1824: 5.700594902038574\n",
      "Training loss at step 1856: 5.038049221038818\n",
      "Training loss at step 1888: 4.587937355041504\n",
      "Training loss at step 1920: 4.276400566101074\n",
      "Training loss at step 1952: 4.053329944610596\n",
      "Training loss at step 1984: 3.9058756828308105\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at step 0: 4.002380847930908\n",
      "Training loss at step 32: 3.5713906288146973\n",
      "Training loss at step 64: 3.3375139236450195\n",
      "Training loss at step 96: 3.1634364128112793\n",
      "Training loss at step 128: 3.0241427421569824\n",
      "Training loss at step 160: 2.921553134918213\n",
      "Training loss at step 192: 2.8558332920074463\n",
      "Training loss at step 224: 2.8240201473236084\n",
      "Training loss at step 256: 2.844774007797241\n",
      "Training loss at step 288: 3.0188560485839844\n",
      "Training loss at step 320: 3.424325942993164\n",
      "Training loss at step 352: 3.962723970413208\n",
      "Training loss at step 384: 4.439543724060059\n",
      "Training loss at step 416: 4.797687530517578\n",
      "Training loss at step 448: 5.055673122406006\n",
      "Training loss at step 480: 5.269934177398682\n",
      "Training loss at step 512: 5.505300045013428\n",
      "Training loss at step 544: 5.77982234954834\n",
      "Training loss at step 576: 6.107475280761719\n",
      "Training loss at step 608: 6.4918599128723145\n",
      "Training loss at step 640: 6.908747673034668\n",
      "Training loss at step 672: 7.300592422485352\n",
      "Training loss at step 704: 7.582638740539551\n",
      "Training loss at step 736: 7.660598278045654\n",
      "Training loss at step 768: 7.229495048522949\n",
      "Training loss at step 800: 6.358382225036621\n",
      "Training loss at step 832: 5.541425704956055\n",
      "Training loss at step 864: 4.966681003570557\n",
      "Training loss at step 896: 4.5618391036987305\n",
      "Training loss at step 928: 4.277343273162842\n",
      "Training loss at step 960: 4.058345317840576\n",
      "Training loss at step 992: 3.8653993606567383\n",
      "Training loss at step 1024: 3.6853091716766357\n",
      "Training loss at step 1056: 3.5026278495788574\n",
      "Training loss at step 1088: 3.3063175678253174\n",
      "Training loss at step 1120: 3.1255056858062744\n",
      "Training loss at step 1152: 2.984797954559326\n",
      "Training loss at step 1184: 2.888657569885254\n",
      "Training loss at step 1216: 2.8322412967681885\n",
      "Training loss at step 1248: 2.822878837585449\n",
      "Training loss at step 1280: 2.9532158374786377\n",
      "Training loss at step 1312: 3.326287031173706\n",
      "Training loss at step 1344: 3.869033098220825\n",
      "Training loss at step 1376: 4.384517192840576\n",
      "Training loss at step 1408: 4.808456897735596\n",
      "Training loss at step 1440: 5.137476921081543\n",
      "Training loss at step 1472: 5.375686168670654\n",
      "Training loss at step 1504: 5.585870742797852\n",
      "Training loss at step 1536: 5.822419166564941\n",
      "Training loss at step 1568: 6.118960380554199\n",
      "Training loss at step 1600: 6.482532501220703\n",
      "Training loss at step 1632: 6.880372047424316\n",
      "Training loss at step 1664: 7.269687652587891\n",
      "Training loss at step 1696: 7.567307949066162\n",
      "Training loss at step 1728: 7.696628570556641\n",
      "Training loss at step 1760: 7.414356708526611\n",
      "Training loss at step 1792: 6.589106559753418\n",
      "Training loss at step 1824: 5.686683654785156\n",
      "Training loss at step 1856: 5.002530574798584\n",
      "Training loss at step 1888: 4.544989585876465\n",
      "Training loss at step 1920: 4.2341413497924805\n",
      "Training loss at step 1952: 3.999871015548706\n",
      "Training loss at step 1984: 3.854722023010254\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at step 0: 3.997645139694214\n",
      "Training loss at step 32: 3.5599048137664795\n",
      "Training loss at step 64: 3.323154926300049\n",
      "Training loss at step 96: 3.1474075317382812\n",
      "Training loss at step 128: 3.004211902618408\n",
      "Training loss at step 160: 2.8971831798553467\n",
      "Training loss at step 192: 2.831921339035034\n",
      "Training loss at step 224: 2.8060836791992188\n",
      "Training loss at step 256: 2.8367605209350586\n",
      "Training loss at step 288: 3.0188629627227783\n",
      "Training loss at step 320: 3.4198813438415527\n",
      "Training loss at step 352: 3.9431803226470947\n",
      "Training loss at step 384: 4.409512519836426\n",
      "Training loss at step 416: 4.768246650695801\n",
      "Training loss at step 448: 5.0333781242370605\n",
      "Training loss at step 480: 5.260146141052246\n",
      "Training loss at step 512: 5.50124454498291\n",
      "Training loss at step 544: 5.777231216430664\n",
      "Training loss at step 576: 6.105615615844727\n",
      "Training loss at step 608: 6.489247798919678\n",
      "Training loss at step 640: 6.903005123138428\n",
      "Training loss at step 672: 7.291159629821777\n",
      "Training loss at step 704: 7.5701775550842285\n",
      "Training loss at step 736: 7.6478753089904785\n",
      "Training loss at step 768: 7.222298622131348\n",
      "Training loss at step 800: 6.361199855804443\n",
      "Training loss at step 832: 5.552944660186768\n",
      "Training loss at step 864: 4.984281063079834\n",
      "Training loss at step 896: 4.588181495666504\n",
      "Training loss at step 928: 4.3087568283081055\n",
      "Training loss at step 960: 4.093722343444824\n",
      "Training loss at step 992: 3.9043257236480713\n",
      "Training loss at step 1024: 3.7315800189971924\n",
      "Training loss at step 1056: 3.563629150390625\n",
      "Training loss at step 1088: 3.369330406188965\n",
      "Training loss at step 1120: 3.186223268508911\n",
      "Training loss at step 1152: 3.0388481616973877\n",
      "Training loss at step 1184: 2.9351553916931152\n",
      "Training loss at step 1216: 2.8686320781707764\n",
      "Training loss at step 1248: 2.8449130058288574\n",
      "Training loss at step 1280: 2.9521758556365967\n",
      "Training loss at step 1312: 3.3078246116638184\n",
      "Training loss at step 1344: 3.849487781524658\n",
      "Training loss at step 1376: 4.377567291259766\n",
      "Training loss at step 1408: 4.820221424102783\n",
      "Training loss at step 1440: 5.157473564147949\n",
      "Training loss at step 1472: 5.397981643676758\n",
      "Training loss at step 1504: 5.6083526611328125\n",
      "Training loss at step 1536: 5.8436055183410645\n",
      "Training loss at step 1568: 6.138798713684082\n",
      "Training loss at step 1600: 6.501091957092285\n",
      "Training loss at step 1632: 6.899824142456055\n",
      "Training loss at step 1664: 7.287564277648926\n",
      "Training loss at step 1696: 7.586124420166016\n",
      "Training loss at step 1728: 7.716020584106445\n",
      "Training loss at step 1760: 7.427689075469971\n",
      "Training loss at step 1792: 6.592593193054199\n",
      "Training loss at step 1824: 5.680219650268555\n",
      "Training loss at step 1856: 4.989840507507324\n",
      "Training loss at step 1888: 4.52598762512207\n",
      "Training loss at step 1920: 4.209108352661133\n",
      "Training loss at step 1952: 3.968620777130127\n",
      "Training loss at step 1984: 3.819650888442993\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at step 0: 3.997556686401367\n",
      "Training loss at step 32: 3.560106039047241\n",
      "Training loss at step 64: 3.3233115673065186\n",
      "Training loss at step 96: 3.1476924419403076\n",
      "Training loss at step 128: 3.005425214767456\n",
      "Training loss at step 160: 2.899874210357666\n",
      "Training loss at step 192: 2.8340673446655273\n",
      "Training loss at step 224: 2.8056647777557373\n",
      "Training loss at step 256: 2.835099935531616\n",
      "Training loss at step 288: 3.020629405975342\n",
      "Training loss at step 320: 3.4279141426086426\n",
      "Training loss at step 352: 3.9576244354248047\n",
      "Training loss at step 384: 4.44163703918457\n",
      "Training loss at step 416: 4.798644065856934\n",
      "Training loss at step 448: 5.052500247955322\n",
      "Training loss at step 480: 5.2680463790893555\n",
      "Training loss at step 512: 5.50416898727417\n",
      "Training loss at step 544: 5.77877140045166\n",
      "Training loss at step 576: 6.106287002563477\n",
      "Training loss at step 608: 6.4895782470703125\n",
      "Training loss at step 640: 6.903066635131836\n",
      "Training loss at step 672: 7.291553497314453\n",
      "Training loss at step 704: 7.571845531463623\n",
      "Training loss at step 736: 7.649228572845459\n",
      "Training loss at step 768: 7.2227373123168945\n",
      "Training loss at step 800: 6.361601829528809\n",
      "Training loss at step 832: 5.554180145263672\n",
      "Training loss at step 864: 4.980247497558594\n",
      "Training loss at step 896: 4.575470924377441\n",
      "Training loss at step 928: 4.293286323547363\n",
      "Training loss at step 960: 4.074096202850342\n",
      "Training loss at step 992: 3.8812787532806396\n",
      "Training loss at step 1024: 3.7014358043670654\n",
      "Training loss at step 1056: 3.5249063968658447\n",
      "Training loss at step 1088: 3.3307695388793945\n",
      "Training loss at step 1120: 3.1503334045410156\n",
      "Training loss at step 1152: 3.0077574253082275\n",
      "Training loss at step 1184: 2.909303903579712\n",
      "Training loss at step 1216: 2.8487889766693115\n",
      "Training loss at step 1248: 2.832874298095703\n",
      "Training loss at step 1280: 2.9517648220062256\n",
      "Training loss at step 1312: 3.3154821395874023\n",
      "Training loss at step 1344: 3.857328414916992\n",
      "Training loss at step 1376: 4.379770755767822\n",
      "Training loss at step 1408: 4.812121868133545\n",
      "Training loss at step 1440: 5.14382266998291\n",
      "Training loss at step 1472: 5.3820695877075195\n",
      "Training loss at step 1504: 5.591409683227539\n",
      "Training loss at step 1536: 5.826722145080566\n",
      "Training loss at step 1568: 6.121894836425781\n",
      "Training loss at step 1600: 6.484318256378174\n",
      "Training loss at step 1632: 6.886274337768555\n",
      "Training loss at step 1664: 7.275455474853516\n",
      "Training loss at step 1696: 7.574555397033691\n",
      "Training loss at step 1728: 7.703804016113281\n",
      "Training loss at step 1760: 7.4177703857421875\n",
      "Training loss at step 1792: 6.589745044708252\n",
      "Training loss at step 1824: 5.684069633483887\n",
      "Training loss at step 1856: 4.996724605560303\n",
      "Training loss at step 1888: 4.535455226898193\n",
      "Training loss at step 1920: 4.220897197723389\n",
      "Training loss at step 1952: 3.9853131771087646\n",
      "Training loss at step 1984: 3.8389673233032227\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at step 0: 3.9978842735290527\n",
      "Training loss at step 32: 3.5623297691345215\n",
      "Training loss at step 64: 3.326023578643799\n",
      "Training loss at step 96: 3.151007652282715\n",
      "Training loss at step 128: 3.010199546813965\n",
      "Training loss at step 160: 2.906464099884033\n",
      "Training loss at step 192: 2.843188762664795\n",
      "Training loss at step 224: 2.8156208992004395\n",
      "Training loss at step 256: 2.8409383296966553\n",
      "Training loss at step 288: 3.018422842025757\n",
      "Training loss at step 320: 3.4211084842681885\n",
      "Training loss at step 352: 3.9519481658935547\n",
      "Training loss at step 384: 4.441425323486328\n",
      "Training loss at step 416: 4.80090856552124\n",
      "Training loss at step 448: 5.054821014404297\n",
      "Training loss at step 480: 5.270050048828125\n",
      "Training loss at step 512: 5.505216121673584\n",
      "Training loss at step 544: 5.77925968170166\n",
      "Training loss at step 576: 6.106625556945801\n",
      "Training loss at step 608: 6.490238189697266\n",
      "Training loss at step 640: 6.903001308441162\n",
      "Training loss at step 672: 7.289883136749268\n",
      "Training loss at step 704: 7.567675590515137\n",
      "Training loss at step 736: 7.645930290222168\n",
      "Training loss at step 768: 7.221339225769043\n",
      "Training loss at step 800: 6.362029075622559\n",
      "Training loss at step 832: 5.5520405769348145\n",
      "Training loss at step 864: 4.97462272644043\n",
      "Training loss at step 896: 4.571670055389404\n",
      "Training loss at step 928: 4.283016681671143\n",
      "Training loss at step 960: 4.060464859008789\n",
      "Training loss at step 992: 3.8658082485198975\n",
      "Training loss at step 1024: 3.6884677410125732\n",
      "Training loss at step 1056: 3.510444402694702\n",
      "Training loss at step 1088: 3.310742139816284\n",
      "Training loss at step 1120: 3.129927396774292\n",
      "Training loss at step 1152: 2.988236427307129\n",
      "Training loss at step 1184: 2.891409397125244\n",
      "Training loss at step 1216: 2.834038257598877\n",
      "Training loss at step 1248: 2.8236746788024902\n",
      "Training loss at step 1280: 2.952685594558716\n",
      "Training loss at step 1312: 3.3253116607666016\n",
      "Training loss at step 1344: 3.869152545928955\n",
      "Training loss at step 1376: 4.387560844421387\n",
      "Training loss at step 1408: 4.811132907867432\n",
      "Training loss at step 1440: 5.140586853027344\n",
      "Training loss at step 1472: 5.3768310546875\n",
      "Training loss at step 1504: 5.58636474609375\n",
      "Training loss at step 1536: 5.823415279388428\n",
      "Training loss at step 1568: 6.119952201843262\n",
      "Training loss at step 1600: 6.482488632202148\n",
      "Training loss at step 1632: 6.8820343017578125\n",
      "Training loss at step 1664: 7.271158695220947\n",
      "Training loss at step 1696: 7.57418155670166\n",
      "Training loss at step 1728: 7.706819534301758\n",
      "Training loss at step 1760: 7.419015884399414\n",
      "Training loss at step 1792: 6.590124607086182\n",
      "Training loss at step 1824: 5.684604644775391\n",
      "Training loss at step 1856: 4.99768590927124\n",
      "Training loss at step 1888: 4.534936428070068\n",
      "Training loss at step 1920: 4.217568874359131\n",
      "Training loss at step 1952: 3.986361265182495\n",
      "Training loss at step 1984: 3.841118335723877\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at step 0: 3.997572898864746\n",
      "Training loss at step 32: 3.5598108768463135\n",
      "Training loss at step 64: 3.3230884075164795\n",
      "Training loss at step 96: 3.1473543643951416\n",
      "Training loss at step 128: 3.0042343139648438\n",
      "Training loss at step 160: 2.8974461555480957\n",
      "Training loss at step 192: 2.832521677017212\n",
      "Training loss at step 224: 2.8069846630096436\n",
      "Training loss at step 256: 2.8375086784362793\n",
      "Training loss at step 288: 3.018465518951416\n",
      "Training loss at step 320: 3.41774320602417\n",
      "Training loss at step 352: 3.9391839504241943\n",
      "Training loss at step 384: 4.418105125427246\n",
      "Training loss at step 416: 4.774964809417725\n",
      "Training loss at step 448: 5.035952568054199\n",
      "Training loss at step 480: 5.263129234313965\n",
      "Training loss at step 512: 5.502802848815918\n",
      "Training loss at step 544: 5.778044700622559\n",
      "Training loss at step 576: 6.106054306030273\n",
      "Training loss at step 608: 6.488953590393066\n",
      "Training loss at step 640: 6.900992393493652\n",
      "Training loss at step 672: 7.287339687347412\n",
      "Training loss at step 704: 7.565834999084473\n",
      "Training loss at step 736: 7.643170356750488\n",
      "Training loss at step 768: 7.219552040100098\n",
      "Training loss at step 800: 6.3634419441223145\n",
      "Training loss at step 832: 5.557367324829102\n",
      "Training loss at step 864: 4.97926664352417\n",
      "Training loss at step 896: 4.575570583343506\n",
      "Training loss at step 928: 4.293428897857666\n",
      "Training loss at step 960: 4.0755696296691895\n",
      "Training loss at step 992: 3.8849306106567383\n",
      "Training loss at step 1024: 3.70953106880188\n",
      "Training loss at step 1056: 3.5401992797851562\n",
      "Training loss at step 1088: 3.346708297729492\n",
      "Training loss at step 1120: 3.166801691055298\n",
      "Training loss at step 1152: 3.022057056427002\n",
      "Training loss at step 1184: 2.921001434326172\n",
      "Training loss at step 1216: 2.857464075088501\n",
      "Training loss at step 1248: 2.837725877761841\n",
      "Training loss at step 1280: 2.951657772064209\n",
      "Training loss at step 1312: 3.3133251667022705\n",
      "Training loss at step 1344: 3.857194423675537\n",
      "Training loss at step 1376: 4.385018825531006\n",
      "Training loss at step 1408: 4.823521137237549\n",
      "Training loss at step 1440: 5.156872749328613\n",
      "Training loss at step 1472: 5.3938889503479\n",
      "Training loss at step 1504: 5.602569580078125\n",
      "Training loss at step 1536: 5.836655616760254\n",
      "Training loss at step 1568: 6.130040168762207\n",
      "Training loss at step 1600: 6.492132186889648\n",
      "Training loss at step 1632: 6.89163875579834\n",
      "Training loss at step 1664: 7.280184745788574\n",
      "Training loss at step 1696: 7.578627586364746\n",
      "Training loss at step 1728: 7.706243991851807\n",
      "Training loss at step 1760: 7.419090270996094\n",
      "Training loss at step 1792: 6.5902252197265625\n",
      "Training loss at step 1824: 5.683226585388184\n",
      "Training loss at step 1856: 4.9953837394714355\n",
      "Training loss at step 1888: 4.532753944396973\n",
      "Training loss at step 1920: 4.213008880615234\n",
      "Training loss at step 1952: 3.9750659465789795\n",
      "Training loss at step 1984: 3.8285791873931885\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at step 0: 3.998249053955078\n",
      "Training loss at step 32: 3.5634734630584717\n",
      "Training loss at step 64: 3.3278801441192627\n",
      "Training loss at step 96: 3.1533045768737793\n",
      "Training loss at step 128: 3.0132882595062256\n",
      "Training loss at step 160: 2.9101226329803467\n",
      "Training loss at step 192: 2.844303607940674\n",
      "Training loss at step 224: 2.8147225379943848\n",
      "Training loss at step 256: 2.839961528778076\n",
      "Training loss at step 288: 3.0187065601348877\n",
      "Training loss at step 320: 3.422715187072754\n",
      "Training loss at step 352: 3.9535465240478516\n",
      "Training loss at step 384: 4.444732189178467\n",
      "Training loss at step 416: 4.80324649810791\n",
      "Training loss at step 448: 5.057072639465332\n",
      "Training loss at step 480: 5.272857666015625\n",
      "Training loss at step 512: 5.506795883178711\n",
      "Training loss at step 544: 5.78032922744751\n",
      "Training loss at step 576: 6.107089996337891\n",
      "Training loss at step 608: 6.4896111488342285\n",
      "Training loss at step 640: 6.90066385269165\n",
      "Training loss at step 672: 7.285337448120117\n",
      "Training loss at step 704: 7.561641216278076\n",
      "Training loss at step 736: 7.638453483581543\n",
      "Training loss at step 768: 7.2172160148620605\n",
      "Training loss at step 800: 6.365133285522461\n",
      "Training loss at step 832: 5.558749675750732\n",
      "Training loss at step 864: 4.97732400894165\n",
      "Training loss at step 896: 4.5635504722595215\n",
      "Training loss at step 928: 4.275240421295166\n",
      "Training loss at step 960: 4.051847457885742\n",
      "Training loss at step 992: 3.8576948642730713\n",
      "Training loss at step 1024: 3.6774728298187256\n",
      "Training loss at step 1056: 3.497382640838623\n",
      "Training loss at step 1088: 3.3022491931915283\n",
      "Training loss at step 1120: 3.1236424446105957\n",
      "Training loss at step 1152: 2.9829654693603516\n",
      "Training loss at step 1184: 2.8872907161712646\n",
      "Training loss at step 1216: 2.8311402797698975\n",
      "Training loss at step 1248: 2.8221592903137207\n",
      "Training loss at step 1280: 2.9529900550842285\n",
      "Training loss at step 1312: 3.3253889083862305\n",
      "Training loss at step 1344: 3.8661532402038574\n",
      "Training loss at step 1376: 4.381833553314209\n",
      "Training loss at step 1408: 4.807014465332031\n",
      "Training loss at step 1440: 5.139960289001465\n",
      "Training loss at step 1472: 5.377264976501465\n",
      "Training loss at step 1504: 5.587173938751221\n",
      "Training loss at step 1536: 5.823758602142334\n",
      "Training loss at step 1568: 6.119809150695801\n",
      "Training loss at step 1600: 6.481639862060547\n",
      "Training loss at step 1632: 6.882761001586914\n",
      "Training loss at step 1664: 7.272353649139404\n",
      "Training loss at step 1696: 7.5725250244140625\n",
      "Training loss at step 1728: 7.69700813293457\n",
      "Training loss at step 1760: 7.410424709320068\n",
      "Training loss at step 1792: 6.588117599487305\n",
      "Training loss at step 1824: 5.685573577880859\n",
      "Training loss at step 1856: 4.998271942138672\n",
      "Training loss at step 1888: 4.5355730056762695\n",
      "Training loss at step 1920: 4.217468738555908\n",
      "Training loss at step 1952: 3.990844249725342\n",
      "Training loss at step 1984: 3.8463597297668457\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at step 0: 3.997523307800293\n",
      "Training loss at step 32: 3.560103178024292\n",
      "Training loss at step 64: 3.3233251571655273\n",
      "Training loss at step 96: 3.147780418395996\n",
      "Training loss at step 128: 3.0056827068328857\n",
      "Training loss at step 160: 2.9005212783813477\n",
      "Training loss at step 192: 2.8369901180267334\n",
      "Training loss at step 224: 2.811835289001465\n",
      "Training loss at step 256: 2.840590238571167\n",
      "Training loss at step 288: 3.017754316329956\n",
      "Training loss at step 320: 3.4151077270507812\n",
      "Training loss at step 352: 3.9390041828155518\n",
      "Training loss at step 384: 4.4196672439575195\n",
      "Training loss at step 416: 4.782044410705566\n",
      "Training loss at step 448: 5.0446882247924805\n",
      "Training loss at step 480: 5.2685933113098145\n",
      "Training loss at step 512: 5.506000518798828\n",
      "Training loss at step 544: 5.780303955078125\n",
      "Training loss at step 576: 6.107392311096191\n",
      "Training loss at step 608: 6.489554405212402\n",
      "Training loss at step 640: 6.900606632232666\n",
      "Training loss at step 672: 7.28524923324585\n",
      "Training loss at step 704: 7.562424659729004\n",
      "Training loss at step 736: 7.6394829750061035\n",
      "Training loss at step 768: 7.217618942260742\n",
      "Training loss at step 800: 6.364489555358887\n",
      "Training loss at step 832: 5.558131217956543\n",
      "Training loss at step 864: 4.976483345031738\n",
      "Training loss at step 896: 4.558006763458252\n",
      "Training loss at step 928: 4.2733683586120605\n",
      "Training loss at step 960: 4.053980827331543\n",
      "Training loss at step 992: 3.862980365753174\n",
      "Training loss at step 1024: 3.686046600341797\n",
      "Training loss at step 1056: 3.515434503555298\n",
      "Training loss at step 1088: 3.322732448577881\n",
      "Training loss at step 1120: 3.14444637298584\n",
      "Training loss at step 1152: 3.0013883113861084\n",
      "Training loss at step 1184: 2.9028098583221436\n",
      "Training loss at step 1216: 2.843343496322632\n",
      "Training loss at step 1248: 2.8295140266418457\n",
      "Training loss at step 1280: 2.9517791271209717\n",
      "Training loss at step 1312: 3.317554473876953\n",
      "Training loss at step 1344: 3.858125686645508\n",
      "Training loss at step 1376: 4.379125595092773\n",
      "Training loss at step 1408: 4.813887596130371\n",
      "Training loss at step 1440: 5.1501312255859375\n",
      "Training loss at step 1472: 5.389008522033691\n",
      "Training loss at step 1504: 5.598712921142578\n",
      "Training loss at step 1536: 5.833807945251465\n",
      "Training loss at step 1568: 6.127922058105469\n",
      "Training loss at step 1600: 6.488068580627441\n",
      "Training loss at step 1632: 6.884882926940918\n",
      "Training loss at step 1664: 7.271101951599121\n",
      "Training loss at step 1696: 7.563582420349121\n",
      "Training loss at step 1728: 7.6864013671875\n",
      "Training loss at step 1760: 7.405241012573242\n",
      "Training loss at step 1792: 6.587131500244141\n",
      "Training loss at step 1824: 5.688506126403809\n",
      "Training loss at step 1856: 5.001092910766602\n",
      "Training loss at step 1888: 4.538944244384766\n",
      "Training loss at step 1920: 4.219611167907715\n",
      "Training loss at step 1952: 3.9870996475219727\n",
      "Training loss at step 1984: 3.842832088470459\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at step 0: 3.997851610183716\n",
      "Training loss at step 32: 3.559866189956665\n",
      "Training loss at step 64: 3.3234949111938477\n",
      "Training loss at step 96: 3.1478819847106934\n",
      "Training loss at step 128: 3.003990411758423\n",
      "Training loss at step 160: 2.8961408138275146\n",
      "Training loss at step 192: 2.830740451812744\n",
      "Training loss at step 224: 2.8058345317840576\n",
      "Training loss at step 256: 2.8377017974853516\n",
      "Training loss at step 288: 3.017813205718994\n",
      "Training loss at step 320: 3.4118921756744385\n",
      "Training loss at step 352: 3.9265151023864746\n",
      "Training loss at step 384: 4.406116962432861\n",
      "Training loss at step 416: 4.7646870613098145\n",
      "Training loss at step 448: 5.033748149871826\n",
      "Training loss at step 480: 5.263689041137695\n",
      "Training loss at step 512: 5.503584861755371\n",
      "Training loss at step 544: 5.778629779815674\n",
      "Training loss at step 576: 6.106072902679443\n",
      "Training loss at step 608: 6.487815856933594\n",
      "Training loss at step 640: 6.896406650543213\n",
      "Training loss at step 672: 7.2766618728637695\n",
      "Training loss at step 704: 7.550236701965332\n",
      "Training loss at step 736: 7.627270221710205\n",
      "Training loss at step 768: 7.21195650100708\n",
      "Training loss at step 800: 6.369790077209473\n",
      "Training loss at step 832: 5.5663652420043945\n",
      "Training loss at step 864: 4.983444690704346\n",
      "Training loss at step 896: 4.573732852935791\n",
      "Training loss at step 928: 4.288743019104004\n",
      "Training loss at step 960: 4.0689167976379395\n",
      "Training loss at step 992: 3.878965139389038\n",
      "Training loss at step 1024: 3.7080883979797363\n",
      "Training loss at step 1056: 3.5413644313812256\n",
      "Training loss at step 1088: 3.3466715812683105\n",
      "Training loss at step 1120: 3.1660516262054443\n",
      "Training loss at step 1152: 3.021059513092041\n",
      "Training loss at step 1184: 2.9194836616516113\n",
      "Training loss at step 1216: 2.8560402393341064\n",
      "Training loss at step 1248: 2.836871385574341\n",
      "Training loss at step 1280: 2.9516024589538574\n",
      "Training loss at step 1312: 3.312727212905884\n",
      "Training loss at step 1344: 3.854320526123047\n",
      "Training loss at step 1376: 4.380876064300537\n",
      "Training loss at step 1408: 4.8184099197387695\n",
      "Training loss at step 1440: 5.1598429679870605\n",
      "Training loss at step 1472: 5.399404525756836\n",
      "Training loss at step 1504: 5.60916805267334\n",
      "Training loss at step 1536: 5.8435821533203125\n",
      "Training loss at step 1568: 6.137485504150391\n",
      "Training loss at step 1600: 6.496185779571533\n",
      "Training loss at step 1632: 6.893739700317383\n",
      "Training loss at step 1664: 7.283576011657715\n",
      "Training loss at step 1696: 7.581214427947998\n",
      "Training loss at step 1728: 7.70541524887085\n",
      "Training loss at step 1760: 7.413969039916992\n",
      "Training loss at step 1792: 6.588652610778809\n",
      "Training loss at step 1824: 5.683715343475342\n",
      "Training loss at step 1856: 4.991157531738281\n",
      "Training loss at step 1888: 4.526177406311035\n",
      "Training loss at step 1920: 4.202456474304199\n",
      "Training loss at step 1952: 3.9674174785614014\n",
      "Training loss at step 1984: 3.824340343475342\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at step 0: 3.997553825378418\n",
      "Training loss at step 32: 3.5600907802581787\n",
      "Training loss at step 64: 3.323366641998291\n",
      "Training loss at step 96: 3.1478400230407715\n",
      "Training loss at step 128: 3.0057833194732666\n",
      "Training loss at step 160: 2.900698661804199\n",
      "Training loss at step 192: 2.8372819423675537\n",
      "Training loss at step 224: 2.812276840209961\n",
      "Training loss at step 256: 2.840928554534912\n",
      "Training loss at step 288: 3.0178709030151367\n",
      "Training loss at step 320: 3.4155640602111816\n",
      "Training loss at step 352: 3.9402689933776855\n",
      "Training loss at step 384: 4.433098793029785\n",
      "Training loss at step 416: 4.794363021850586\n",
      "Training loss at step 448: 5.0534868240356445\n",
      "Training loss at step 480: 5.274092674255371\n",
      "Training loss at step 512: 5.50910758972168\n",
      "Training loss at step 544: 5.782322406768799\n",
      "Training loss at step 576: 6.108114242553711\n",
      "Training loss at step 608: 6.490142822265625\n",
      "Training loss at step 640: 6.900296688079834\n",
      "Training loss at step 672: 7.284459590911865\n",
      "Training loss at step 704: 7.561450958251953\n",
      "Training loss at step 736: 7.638644218444824\n",
      "Training loss at step 768: 7.217400550842285\n",
      "Training loss at step 800: 6.364077091217041\n",
      "Training loss at step 832: 5.557581901550293\n",
      "Training loss at step 864: 4.981311798095703\n",
      "Training loss at step 896: 4.554827690124512\n",
      "Training loss at step 928: 4.2631378173828125\n",
      "Training loss at step 960: 4.0428571701049805\n",
      "Training loss at step 992: 3.8511929512023926\n",
      "Training loss at step 1024: 3.673460006713867\n",
      "Training loss at step 1056: 3.498835563659668\n",
      "Training loss at step 1088: 3.3092596530914307\n",
      "Training loss at step 1120: 3.132209300994873\n",
      "Training loss at step 1152: 2.9909510612487793\n",
      "Training loss at step 1184: 2.894230604171753\n",
      "Training loss at step 1216: 2.836730480194092\n",
      "Training loss at step 1248: 2.825498580932617\n",
      "Training loss at step 1280: 2.9524307250976562\n",
      "Training loss at step 1312: 3.322082042694092\n",
      "Training loss at step 1344: 3.8623909950256348\n",
      "Training loss at step 1376: 4.379204273223877\n",
      "Training loss at step 1408: 4.805389404296875\n",
      "Training loss at step 1440: 5.140476703643799\n",
      "Training loss at step 1472: 5.379809379577637\n",
      "Training loss at step 1504: 5.590551853179932\n",
      "Training loss at step 1536: 5.826938629150391\n",
      "Training loss at step 1568: 6.121994495391846\n",
      "Training loss at step 1600: 6.481589317321777\n",
      "Training loss at step 1632: 6.879916667938232\n",
      "Training loss at step 1664: 7.2655558586120605\n",
      "Training loss at step 1696: 7.551943778991699\n",
      "Training loss at step 1728: 7.678304672241211\n",
      "Training loss at step 1760: 7.3992180824279785\n",
      "Training loss at step 1792: 6.586117744445801\n",
      "Training loss at step 1824: 5.690490245819092\n",
      "Training loss at step 1856: 4.998081684112549\n",
      "Training loss at step 1888: 4.533914089202881\n",
      "Training loss at step 1920: 4.215342044830322\n",
      "Training loss at step 1952: 3.9905877113342285\n",
      "Training loss at step 1984: 3.8490281105041504\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at step 0: 3.997462272644043\n",
      "Training loss at step 32: 3.559868574142456\n",
      "Training loss at step 64: 3.323084592819214\n",
      "Training loss at step 96: 3.147343873977661\n",
      "Training loss at step 128: 3.0043015480041504\n",
      "Training loss at step 160: 2.8976588249206543\n",
      "Training loss at step 192: 2.8330535888671875\n",
      "Training loss at step 224: 2.808077573776245\n",
      "Training loss at step 256: 2.838794708251953\n",
      "Training loss at step 288: 3.0176708698272705\n",
      "Training loss at step 320: 3.4119651317596436\n",
      "Training loss at step 352: 3.9275588989257812\n",
      "Training loss at step 384: 4.410006523132324\n",
      "Training loss at step 416: 4.767244338989258\n",
      "Training loss at step 448: 5.037031173706055\n",
      "Training loss at step 480: 5.266933917999268\n",
      "Training loss at step 512: 5.506019592285156\n",
      "Training loss at step 544: 5.780610084533691\n",
      "Training loss at step 576: 6.106787204742432\n",
      "Training loss at step 608: 6.487713813781738\n",
      "Training loss at step 640: 6.895228385925293\n",
      "Training loss at step 672: 7.273233413696289\n",
      "Training loss at step 704: 7.545230865478516\n",
      "Training loss at step 736: 7.621363639831543\n",
      "Training loss at step 768: 7.209461212158203\n",
      "Training loss at step 800: 6.372951984405518\n",
      "Training loss at step 832: 5.569124698638916\n",
      "Training loss at step 864: 4.976705074310303\n",
      "Training loss at step 896: 4.557311058044434\n",
      "Training loss at step 928: 4.272186279296875\n",
      "Training loss at step 960: 4.052777290344238\n",
      "Training loss at step 992: 3.864243268966675\n",
      "Training loss at step 1024: 3.6959314346313477\n",
      "Training loss at step 1056: 3.53076434135437\n",
      "Training loss at step 1088: 3.335667133331299\n",
      "Training loss at step 1120: 3.155843496322632\n",
      "Training loss at step 1152: 3.0118422508239746\n",
      "Training loss at step 1184: 2.911250591278076\n",
      "Training loss at step 1216: 2.8494205474853516\n",
      "Training loss at step 1248: 2.8326938152313232\n",
      "Training loss at step 1280: 2.9515721797943115\n",
      "Training loss at step 1312: 3.315828323364258\n",
      "Training loss at step 1344: 3.8577141761779785\n",
      "Training loss at step 1376: 4.383056640625\n",
      "Training loss at step 1408: 4.818077087402344\n",
      "Training loss at step 1440: 5.162322044372559\n",
      "Training loss at step 1472: 5.402310848236084\n",
      "Training loss at step 1504: 5.612398147583008\n",
      "Training loss at step 1536: 5.847143173217773\n",
      "Training loss at step 1568: 6.141651153564453\n",
      "Training loss at step 1600: 6.500624656677246\n",
      "Training loss at step 1632: 6.898288726806641\n",
      "Training loss at step 1664: 7.289621829986572\n",
      "Training loss at step 1696: 7.582066535949707\n",
      "Training loss at step 1728: 7.705921173095703\n",
      "Training loss at step 1760: 7.415060043334961\n",
      "Training loss at step 1792: 6.588785171508789\n",
      "Training loss at step 1824: 5.682376861572266\n",
      "Training loss at step 1856: 4.989330291748047\n",
      "Training loss at step 1888: 4.525257587432861\n",
      "Training loss at step 1920: 4.203449726104736\n",
      "Training loss at step 1952: 3.970456123352051\n",
      "Training loss at step 1984: 3.829451560974121\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at step 0: 3.9975483417510986\n",
      "Training loss at step 32: 3.5601601600646973\n",
      "Training loss at step 64: 3.323364496231079\n",
      "Training loss at step 96: 3.147791862487793\n",
      "Training loss at step 128: 3.005680561065674\n",
      "Training loss at step 160: 2.9005448818206787\n",
      "Training loss at step 192: 2.8371851444244385\n",
      "Training loss at step 224: 2.812413454055786\n",
      "Training loss at step 256: 2.84139347076416\n",
      "Training loss at step 288: 3.017299175262451\n",
      "Training loss at step 320: 3.4106297492980957\n",
      "Training loss at step 352: 3.9294188022613525\n",
      "Training loss at step 384: 4.420559406280518\n",
      "Training loss at step 416: 4.784850120544434\n",
      "Training loss at step 448: 5.048716068267822\n",
      "Training loss at step 480: 5.273361682891846\n",
      "Training loss at step 512: 5.509731292724609\n",
      "Training loss at step 544: 5.783267974853516\n",
      "Training loss at step 576: 6.108644485473633\n",
      "Training loss at step 608: 6.489893436431885\n",
      "Training loss at step 640: 6.898378372192383\n",
      "Training loss at step 672: 7.279525279998779\n",
      "Training loss at step 704: 7.5537567138671875\n",
      "Training loss at step 736: 7.630826950073242\n",
      "Training loss at step 768: 7.213688850402832\n",
      "Training loss at step 800: 6.366914749145508\n",
      "Training loss at step 832: 5.559621810913086\n",
      "Training loss at step 864: 4.980599880218506\n",
      "Training loss at step 896: 4.5513153076171875\n",
      "Training loss at step 928: 4.256293296813965\n",
      "Training loss at step 960: 4.036482810974121\n",
      "Training loss at step 992: 3.8462448120117188\n",
      "Training loss at step 1024: 3.6702728271484375\n",
      "Training loss at step 1056: 3.4988293647766113\n",
      "Training loss at step 1088: 3.309694528579712\n",
      "Training loss at step 1120: 3.1324236392974854\n",
      "Training loss at step 1152: 2.990605592727661\n",
      "Training loss at step 1184: 2.8933846950531006\n",
      "Training loss at step 1216: 2.835864782333374\n",
      "Training loss at step 1248: 2.824909210205078\n",
      "Training loss at step 1280: 2.9522767066955566\n",
      "Training loss at step 1312: 3.3206801414489746\n",
      "Training loss at step 1344: 3.8593602180480957\n",
      "Training loss at step 1376: 4.37478494644165\n",
      "Training loss at step 1408: 4.800765037536621\n",
      "Training loss at step 1440: 5.138760566711426\n",
      "Training loss at step 1472: 5.379735469818115\n",
      "Training loss at step 1504: 5.591587543487549\n",
      "Training loss at step 1536: 5.8289289474487305\n",
      "Training loss at step 1568: 6.12455940246582\n",
      "Training loss at step 1600: 6.483087062835693\n",
      "Training loss at step 1632: 6.880430698394775\n",
      "Training loss at step 1664: 7.2621660232543945\n",
      "Training loss at step 1696: 7.545586585998535\n",
      "Training loss at step 1728: 7.670907020568848\n",
      "Training loss at step 1760: 7.396283149719238\n",
      "Training loss at step 1792: 6.586080551147461\n",
      "Training loss at step 1824: 5.690888404846191\n",
      "Training loss at step 1856: 4.992461681365967\n",
      "Training loss at step 1888: 4.525484085083008\n",
      "Training loss at step 1920: 4.206499099731445\n",
      "Training loss at step 1952: 3.9823219776153564\n",
      "Training loss at step 1984: 3.842013120651245\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at step 0: 3.997511386871338\n",
      "Training loss at step 32: 3.559800148010254\n",
      "Training loss at step 64: 3.32314133644104\n",
      "Training loss at step 96: 3.1473920345306396\n",
      "Training loss at step 128: 3.0041255950927734\n",
      "Training loss at step 160: 2.8972725868225098\n",
      "Training loss at step 192: 2.832796573638916\n",
      "Training loss at step 224: 2.8083877563476562\n",
      "Training loss at step 256: 2.8396880626678467\n",
      "Training loss at step 288: 3.0171568393707275\n",
      "Training loss at step 320: 3.4071483612060547\n",
      "Training loss at step 352: 3.9178760051727295\n",
      "Training loss at step 384: 4.403080940246582\n",
      "Training loss at step 416: 4.769974231719971\n",
      "Training loss at step 448: 5.040008544921875\n",
      "Training loss at step 480: 5.27028751373291\n",
      "Training loss at step 512: 5.508981227874756\n",
      "Training loss at step 544: 5.7836456298828125\n",
      "Training loss at step 576: 6.109527587890625\n",
      "Training loss at step 608: 6.48891544342041\n",
      "Training loss at step 640: 6.896101951599121\n",
      "Training loss at step 672: 7.2709503173828125\n",
      "Training loss at step 704: 7.540719032287598\n",
      "Training loss at step 736: 7.616742134094238\n",
      "Training loss at step 768: 7.2077836990356445\n",
      "Training loss at step 800: 6.37427282333374\n",
      "Training loss at step 832: 5.561451435089111\n",
      "Training loss at step 864: 4.956629276275635\n",
      "Training loss at step 896: 4.533324718475342\n",
      "Training loss at step 928: 4.2535200119018555\n",
      "Training loss at step 960: 4.036334037780762\n",
      "Training loss at step 992: 3.8516669273376465\n",
      "Training loss at step 1024: 3.68825101852417\n",
      "Training loss at step 1056: 3.526108980178833\n",
      "Training loss at step 1088: 3.3319694995880127\n",
      "Training loss at step 1120: 3.1516354084014893\n",
      "Training loss at step 1152: 3.0069308280944824\n",
      "Training loss at step 1184: 2.9066290855407715\n",
      "Training loss at step 1216: 2.8454384803771973\n",
      "Training loss at step 1248: 2.830057144165039\n",
      "Training loss at step 1280: 2.951725721359253\n",
      "Training loss at step 1312: 3.3184404373168945\n",
      "Training loss at step 1344: 3.860590696334839\n",
      "Training loss at step 1376: 4.382711410522461\n",
      "Training loss at step 1408: 4.813204765319824\n",
      "Training loss at step 1440: 5.161250114440918\n",
      "Training loss at step 1472: 5.4030327796936035\n",
      "Training loss at step 1504: 5.614799499511719\n",
      "Training loss at step 1536: 5.852066516876221\n",
      "Training loss at step 1568: 6.147586345672607\n",
      "Training loss at step 1600: 6.507979393005371\n",
      "Training loss at step 1632: 6.9071245193481445\n",
      "Training loss at step 1664: 7.2934889793396\n",
      "Training loss at step 1696: 7.579694747924805\n",
      "Training loss at step 1728: 7.702203273773193\n",
      "Training loss at step 1760: 7.411131858825684\n",
      "Training loss at step 1792: 6.587666034698486\n",
      "Training loss at step 1824: 5.68508243560791\n",
      "Training loss at step 1856: 4.984411716461182\n",
      "Training loss at step 1888: 4.518686294555664\n",
      "Training loss at step 1920: 4.198146820068359\n",
      "Training loss at step 1952: 3.966921329498291\n",
      "Training loss at step 1984: 3.8254129886627197\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at step 0: 3.9975991249084473\n",
      "Training loss at step 32: 3.5598559379577637\n",
      "Training loss at step 64: 3.323194980621338\n",
      "Training loss at step 96: 3.14741587638855\n",
      "Training loss at step 128: 3.004120111465454\n",
      "Training loss at step 160: 2.897338390350342\n",
      "Training loss at step 192: 2.8330421447753906\n",
      "Training loss at step 224: 2.808823347091675\n",
      "Training loss at step 256: 2.8402278423309326\n",
      "Training loss at step 288: 3.0170998573303223\n",
      "Training loss at step 320: 3.406608819961548\n",
      "Training loss at step 352: 3.916815757751465\n",
      "Training loss at step 384: 4.4009013175964355\n",
      "Training loss at step 416: 4.7690205574035645\n",
      "Training loss at step 448: 5.039826393127441\n",
      "Training loss at step 480: 5.2704315185546875\n",
      "Training loss at step 512: 5.5093536376953125\n",
      "Training loss at step 544: 5.783522129058838\n",
      "Training loss at step 576: 6.109197616577148\n",
      "Training loss at step 608: 6.4893083572387695\n",
      "Training loss at step 640: 6.896683692932129\n",
      "Training loss at step 672: 7.275233268737793\n",
      "Training loss at step 704: 7.547486305236816\n",
      "Training loss at step 736: 7.623953819274902\n",
      "Training loss at step 768: 7.210457801818848\n",
      "Training loss at step 800: 6.371279239654541\n",
      "Training loss at step 832: 5.567978858947754\n",
      "Training loss at step 864: 4.98966646194458\n",
      "Training loss at step 896: 4.553393363952637\n",
      "Training loss at step 928: 4.254194736480713\n",
      "Training loss at step 960: 4.032534599304199\n",
      "Training loss at step 992: 3.839992046356201\n",
      "Training loss at step 1024: 3.663977861404419\n",
      "Training loss at step 1056: 3.4931397438049316\n",
      "Training loss at step 1088: 3.2986128330230713\n",
      "Training loss at step 1120: 3.1179087162017822\n",
      "Training loss at step 1152: 2.9744679927825928\n",
      "Training loss at step 1184: 2.875977039337158\n",
      "Training loss at step 1216: 2.8196117877960205\n",
      "Training loss at step 1248: 2.815850019454956\n",
      "Training loss at step 1280: 2.967151403427124\n",
      "Training loss at step 1312: 3.367894411087036\n",
      "Training loss at step 1344: 3.922551393508911\n",
      "Training loss at step 1376: 4.433018684387207\n",
      "Training loss at step 1408: 4.854114532470703\n",
      "Training loss at step 1440: 5.175124645233154\n",
      "Training loss at step 1472: 5.395136833190918\n",
      "Training loss at step 1504: 5.593230724334717\n",
      "Training loss at step 1536: 5.822380065917969\n",
      "Training loss at step 1568: 6.113405227661133\n",
      "Training loss at step 1600: 6.470366954803467\n",
      "Training loss at step 1632: 6.869688034057617\n",
      "Training loss at step 1664: 7.250822067260742\n",
      "Training loss at step 1696: 7.537044048309326\n",
      "Training loss at step 1728: 7.663308143615723\n",
      "Training loss at step 1760: 7.389753818511963\n",
      "Training loss at step 1792: 6.585919380187988\n",
      "Training loss at step 1824: 5.700192928314209\n",
      "Training loss at step 1856: 5.008801460266113\n",
      "Training loss at step 1888: 4.551353454589844\n",
      "Training loss at step 1920: 4.238003730773926\n",
      "Training loss at step 1952: 4.024740219116211\n",
      "Training loss at step 1984: 3.8908684253692627\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at step 0: 4.006616592407227\n",
      "Training loss at step 32: 3.5736303329467773\n",
      "Training loss at step 64: 3.33879017829895\n",
      "Training loss at step 96: 3.1653695106506348\n",
      "Training loss at step 128: 3.026878595352173\n",
      "Training loss at step 160: 2.925381660461426\n",
      "Training loss at step 192: 2.8625166416168213\n",
      "Training loss at step 224: 2.8337345123291016\n",
      "Training loss at step 256: 2.8534884452819824\n",
      "Training loss at step 288: 3.0191283226013184\n",
      "Training loss at step 320: 3.4128079414367676\n",
      "Training loss at step 352: 3.9359796047210693\n",
      "Training loss at step 384: 4.407657146453857\n",
      "Training loss at step 416: 4.762248992919922\n",
      "Training loss at step 448: 5.034567356109619\n",
      "Training loss at step 480: 5.270388603210449\n",
      "Training loss at step 512: 5.511651992797852\n",
      "Training loss at step 544: 5.787860870361328\n",
      "Training loss at step 576: 6.11550235748291\n",
      "Training loss at step 608: 6.493617057800293\n",
      "Training loss at step 640: 6.901011943817139\n",
      "Training loss at step 672: 7.275716304779053\n",
      "Training loss at step 704: 7.541930198669434\n",
      "Training loss at step 736: 7.616806983947754\n",
      "Training loss at step 768: 7.207734107971191\n",
      "Training loss at step 800: 6.370005130767822\n",
      "Training loss at step 832: 5.547560214996338\n",
      "Training loss at step 864: 4.937027931213379\n",
      "Training loss at step 896: 4.512661457061768\n",
      "Training loss at step 928: 4.2347493171691895\n",
      "Training loss at step 960: 4.022768974304199\n",
      "Training loss at step 992: 3.840763807296753\n",
      "Training loss at step 1024: 3.6772146224975586\n",
      "Training loss at step 1056: 3.519728183746338\n",
      "Training loss at step 1088: 3.3294761180877686\n",
      "Training loss at step 1120: 3.1496100425720215\n",
      "Training loss at step 1152: 3.0045669078826904\n",
      "Training loss at step 1184: 2.9032225608825684\n",
      "Training loss at step 1216: 2.8431289196014404\n",
      "Training loss at step 1248: 2.829287052154541\n",
      "Training loss at step 1280: 2.9516823291778564\n",
      "Training loss at step 1312: 3.315062999725342\n",
      "Training loss at step 1344: 3.850322723388672\n",
      "Training loss at step 1376: 4.367161750793457\n",
      "Training loss at step 1408: 4.798386573791504\n",
      "Training loss at step 1440: 5.1502838134765625\n",
      "Training loss at step 1472: 5.397912979125977\n",
      "Training loss at step 1504: 5.615035057067871\n",
      "Training loss at step 1536: 5.854142189025879\n",
      "Training loss at step 1568: 6.152043342590332\n",
      "Training loss at step 1600: 6.509006500244141\n",
      "Training loss at step 1632: 6.908724784851074\n",
      "Training loss at step 1664: 7.28704309463501\n",
      "Training loss at step 1696: 7.572281360626221\n",
      "Training loss at step 1728: 7.696065425872803\n",
      "Training loss at step 1760: 7.410898208618164\n",
      "Training loss at step 1792: 6.588057518005371\n",
      "Training loss at step 1824: 5.685322284698486\n",
      "Training loss at step 1856: 4.9835309982299805\n",
      "Training loss at step 1888: 4.516619682312012\n",
      "Training loss at step 1920: 4.195687294006348\n",
      "Training loss at step 1952: 3.9636926651000977\n",
      "Training loss at step 1984: 3.8241734504699707\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at step 0: 4.003559589385986\n",
      "Training loss at step 32: 3.567484140396118\n",
      "Training loss at step 64: 3.335515022277832\n",
      "Training loss at step 96: 3.161607027053833\n",
      "Training loss at step 128: 3.01434063911438\n",
      "Training loss at step 160: 2.897873640060425\n",
      "Training loss at step 192: 2.8259880542755127\n",
      "Training loss at step 224: 2.8020403385162354\n",
      "Training loss at step 256: 2.83970046043396\n",
      "Training loss at step 288: 3.0168063640594482\n",
      "Training loss at step 320: 3.395662307739258\n",
      "Training loss at step 352: 3.8986313343048096\n",
      "Training loss at step 384: 4.374392509460449\n",
      "Training loss at step 416: 4.744791507720947\n",
      "Training loss at step 448: 5.025552272796631\n",
      "Training loss at step 480: 5.264235496520996\n",
      "Training loss at step 512: 5.507341384887695\n",
      "Training loss at step 544: 5.783660888671875\n",
      "Training loss at step 576: 6.110069274902344\n",
      "Training loss at step 608: 6.488641262054443\n",
      "Training loss at step 640: 6.895044803619385\n",
      "Training loss at step 672: 7.269264221191406\n",
      "Training loss at step 704: 7.5376410484313965\n",
      "Training loss at step 736: 7.613056182861328\n",
      "Training loss at step 768: 7.2065629959106445\n",
      "Training loss at step 800: 6.376987934112549\n",
      "Training loss at step 832: 5.563682556152344\n",
      "Training loss at step 864: 4.965417385101318\n",
      "Training loss at step 896: 4.536982536315918\n",
      "Training loss at step 928: 4.257114887237549\n",
      "Training loss at step 960: 4.049701690673828\n",
      "Training loss at step 992: 3.8702378273010254\n",
      "Training loss at step 1024: 3.7050604820251465\n",
      "Training loss at step 1056: 3.5498125553131104\n",
      "Training loss at step 1088: 3.3692543506622314\n",
      "Training loss at step 1120: 3.1947221755981445\n",
      "Training loss at step 1152: 3.05009388923645\n",
      "Training loss at step 1184: 2.945122003555298\n",
      "Training loss at step 1216: 2.878063678741455\n",
      "Training loss at step 1248: 2.852152109146118\n",
      "Training loss at step 1280: 2.9536638259887695\n",
      "Training loss at step 1312: 3.298698663711548\n",
      "Training loss at step 1344: 3.8290913105010986\n",
      "Training loss at step 1376: 4.3518385887146\n",
      "Training loss at step 1408: 4.791756629943848\n",
      "Training loss at step 1440: 5.144883155822754\n",
      "Training loss at step 1472: 5.3973846435546875\n",
      "Training loss at step 1504: 5.617633819580078\n",
      "Training loss at step 1536: 5.859435081481934\n",
      "Training loss at step 1568: 6.158021450042725\n",
      "Training loss at step 1600: 6.515749931335449\n",
      "Training loss at step 1632: 6.913052082061768\n",
      "Training loss at step 1664: 7.295819282531738\n",
      "Training loss at step 1696: 7.572026252746582\n",
      "Training loss at step 1728: 7.692074298858643\n",
      "Training loss at step 1760: 7.405604362487793\n",
      "Training loss at step 1792: 6.587047576904297\n",
      "Training loss at step 1824: 5.681705474853516\n",
      "Training loss at step 1856: 4.978322982788086\n",
      "Training loss at step 1888: 4.516149044036865\n",
      "Training loss at step 1920: 4.204240798950195\n",
      "Training loss at step 1952: 3.977553367614746\n",
      "Training loss at step 1984: 3.8316760063171387\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at step 0: 3.9976158142089844\n",
      "Training loss at step 32: 3.5599217414855957\n",
      "Training loss at step 64: 3.323880434036255\n",
      "Training loss at step 96: 3.1491034030914307\n",
      "Training loss at step 128: 3.004887342453003\n",
      "Training loss at step 160: 2.895409107208252\n",
      "Training loss at step 192: 2.829407215118408\n",
      "Training loss at step 224: 2.8062684535980225\n",
      "Training loss at step 256: 2.8403732776641846\n",
      "Training loss at step 288: 3.0170164108276367\n",
      "Training loss at step 320: 3.4044976234436035\n",
      "Training loss at step 352: 3.9196817874908447\n",
      "Training loss at step 384: 4.415530204772949\n",
      "Training loss at step 416: 4.779702186584473\n",
      "Training loss at step 448: 5.045022010803223\n",
      "Training loss at step 480: 5.274240493774414\n",
      "Training loss at step 512: 5.512417793273926\n",
      "Training loss at step 544: 5.786935806274414\n",
      "Training loss at step 576: 6.111572265625\n",
      "Training loss at step 608: 6.48893404006958\n",
      "Training loss at step 640: 6.894676208496094\n",
      "Training loss at step 672: 7.267486095428467\n",
      "Training loss at step 704: 7.534857273101807\n",
      "Training loss at step 736: 7.610811710357666\n",
      "Training loss at step 768: 7.206114768981934\n",
      "Training loss at step 800: 6.378551959991455\n",
      "Training loss at step 832: 5.563857555389404\n",
      "Training loss at step 864: 4.967935562133789\n",
      "Training loss at step 896: 4.540271282196045\n",
      "Training loss at step 928: 4.25271463394165\n",
      "Training loss at step 960: 4.033717155456543\n",
      "Training loss at step 992: 3.852712631225586\n",
      "Training loss at step 1024: 3.695692539215088\n",
      "Training loss at step 1056: 3.5347259044647217\n",
      "Training loss at step 1088: 3.3367271423339844\n",
      "Training loss at step 1120: 3.154012680053711\n",
      "Training loss at step 1152: 3.0078372955322266\n",
      "Training loss at step 1184: 2.907010555267334\n",
      "Training loss at step 1216: 2.8459136486053467\n",
      "Training loss at step 1248: 2.830604314804077\n",
      "Training loss at step 1280: 2.9515459537506104\n",
      "Training loss at step 1312: 3.315744161605835\n",
      "Training loss at step 1344: 3.853954792022705\n",
      "Training loss at step 1376: 4.370795249938965\n",
      "Training loss at step 1408: 4.788209915161133\n",
      "Training loss at step 1440: 5.134939193725586\n",
      "Training loss at step 1472: 5.382978439331055\n",
      "Training loss at step 1504: 5.601226806640625\n",
      "Training loss at step 1536: 5.842579364776611\n",
      "Training loss at step 1568: 6.1397705078125\n",
      "Training loss at step 1600: 6.495980262756348\n",
      "Training loss at step 1632: 6.895941257476807\n",
      "Training loss at step 1664: 7.272708415985107\n",
      "Training loss at step 1696: 7.564974308013916\n",
      "Training loss at step 1728: 7.686906337738037\n",
      "Training loss at step 1760: 7.40016508102417\n",
      "Training loss at step 1792: 6.586352348327637\n",
      "Training loss at step 1824: 5.692806720733643\n",
      "Training loss at step 1856: 4.988270282745361\n",
      "Training loss at step 1888: 4.518766403198242\n",
      "Training loss at step 1920: 4.1963629722595215\n",
      "Training loss at step 1952: 3.9626622200012207\n",
      "Training loss at step 1984: 3.820315361022949\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at step 0: 3.9976446628570557\n",
      "Training loss at step 32: 3.559849500656128\n",
      "Training loss at step 64: 3.3239455223083496\n",
      "Training loss at step 96: 3.149430274963379\n",
      "Training loss at step 128: 3.005441188812256\n",
      "Training loss at step 160: 2.895048141479492\n",
      "Training loss at step 192: 2.8262667655944824\n",
      "Training loss at step 224: 2.79992413520813\n",
      "Training loss at step 256: 2.8346352577209473\n",
      "Training loss at step 288: 3.0176498889923096\n",
      "Training loss at step 320: 3.4059433937072754\n",
      "Training loss at step 352: 3.9111015796661377\n",
      "Training loss at step 384: 4.3962483406066895\n",
      "Training loss at step 416: 4.765870571136475\n",
      "Training loss at step 448: 5.040140628814697\n",
      "Training loss at step 480: 5.273193359375\n",
      "Training loss at step 512: 5.512840270996094\n",
      "Training loss at step 544: 5.787432670593262\n",
      "Training loss at step 576: 6.114293098449707\n",
      "Training loss at step 608: 6.4912309646606445\n",
      "Training loss at step 640: 6.8969879150390625\n",
      "Training loss at step 672: 7.273317337036133\n",
      "Training loss at step 704: 7.544092178344727\n",
      "Training loss at step 736: 7.6197075843811035\n",
      "Training loss at step 768: 7.208878517150879\n",
      "Training loss at step 800: 6.371042251586914\n",
      "Training loss at step 832: 5.558189868927002\n",
      "Training loss at step 864: 4.969886779785156\n",
      "Training loss at step 896: 4.534531593322754\n",
      "Training loss at step 928: 4.2455525398254395\n",
      "Training loss at step 960: 4.031205177307129\n",
      "Training loss at step 992: 3.849510669708252\n",
      "Training loss at step 1024: 3.686753034591675\n",
      "Training loss at step 1056: 3.5260732173919678\n",
      "Training loss at step 1088: 3.336345911026001\n",
      "Training loss at step 1120: 3.158313512802124\n",
      "Training loss at step 1152: 3.0152478218078613\n",
      "Training loss at step 1184: 2.9155426025390625\n",
      "Training loss at step 1216: 2.8537161350250244\n",
      "Training loss at step 1248: 2.8361318111419678\n",
      "Training loss at step 1280: 2.952014207839966\n",
      "Training loss at step 1312: 3.312448740005493\n",
      "Training loss at step 1344: 3.852356195449829\n",
      "Training loss at step 1376: 4.373358249664307\n",
      "Training loss at step 1408: 4.798222064971924\n",
      "Training loss at step 1440: 5.141134738922119\n",
      "Training loss at step 1472: 5.385889530181885\n",
      "Training loss at step 1504: 5.599862098693848\n",
      "Training loss at step 1536: 5.838899612426758\n",
      "Training loss at step 1568: 6.137022972106934\n",
      "Training loss at step 1600: 6.4893951416015625\n",
      "Training loss at step 1632: 6.891488075256348\n",
      "Training loss at step 1664: 7.271193504333496\n",
      "Training loss at step 1696: 7.549650192260742\n",
      "Training loss at step 1728: 7.675871849060059\n",
      "Training loss at step 1760: 7.395947456359863\n",
      "Training loss at step 1792: 6.5854597091674805\n",
      "Training loss at step 1824: 5.6873016357421875\n",
      "Training loss at step 1856: 4.983399391174316\n",
      "Training loss at step 1888: 4.520323276519775\n",
      "Training loss at step 1920: 4.203871726989746\n",
      "Training loss at step 1952: 3.9727861881256104\n",
      "Training loss at step 1984: 3.8287618160247803\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at step 0: 4.001272201538086\n",
      "Training loss at step 32: 3.566128969192505\n",
      "Training loss at step 64: 3.327871561050415\n",
      "Training loss at step 96: 3.151005983352661\n",
      "Training loss at step 128: 3.008326530456543\n",
      "Training loss at step 160: 2.903364896774292\n",
      "Training loss at step 192: 2.84025502204895\n",
      "Training loss at step 224: 2.8160548210144043\n",
      "Training loss at step 256: 2.8442907333374023\n",
      "Training loss at step 288: 3.017035484313965\n",
      "Training loss at step 320: 3.4063215255737305\n",
      "Training loss at step 352: 3.925306797027588\n",
      "Training loss at step 384: 4.426682949066162\n",
      "Training loss at step 416: 4.794231414794922\n",
      "Training loss at step 448: 5.0598578453063965\n",
      "Training loss at step 480: 5.286222457885742\n",
      "Training loss at step 512: 5.521833896636963\n",
      "Training loss at step 544: 5.795926094055176\n",
      "Training loss at step 576: 6.119483947753906\n",
      "Training loss at step 608: 6.492532730102539\n",
      "Training loss at step 640: 6.8971662521362305\n",
      "Training loss at step 672: 7.2691569328308105\n",
      "Training loss at step 704: 7.533318042755127\n",
      "Training loss at step 736: 7.608075141906738\n",
      "Training loss at step 768: 7.205419063568115\n",
      "Training loss at step 800: 6.377676486968994\n",
      "Training loss at step 832: 5.5552825927734375\n",
      "Training loss at step 864: 4.937382698059082\n",
      "Training loss at step 896: 4.5023193359375\n",
      "Training loss at step 928: 4.217005729675293\n",
      "Training loss at step 960: 3.999321699142456\n",
      "Training loss at step 992: 3.8152623176574707\n",
      "Training loss at step 1024: 3.654507875442505\n",
      "Training loss at step 1056: 3.4882781505584717\n",
      "Training loss at step 1088: 3.2932512760162354\n",
      "Training loss at step 1120: 3.1152725219726562\n",
      "Training loss at step 1152: 2.974807024002075\n",
      "Training loss at step 1184: 2.8798913955688477\n",
      "Training loss at step 1216: 2.82544207572937\n",
      "Training loss at step 1248: 2.8190834522247314\n",
      "Training loss at step 1280: 2.9535350799560547\n",
      "Training loss at step 1312: 3.3265371322631836\n",
      "Training loss at step 1344: 3.8626341819763184\n",
      "Training loss at step 1376: 4.370806694030762\n",
      "Training loss at step 1408: 4.780409812927246\n",
      "Training loss at step 1440: 5.125227928161621\n",
      "Training loss at step 1472: 5.375394821166992\n",
      "Training loss at step 1504: 5.595926284790039\n",
      "Training loss at step 1536: 5.8389081954956055\n",
      "Training loss at step 1568: 6.137372970581055\n",
      "Training loss at step 1600: 6.4963531494140625\n",
      "Training loss at step 1632: 6.89697790145874\n",
      "Training loss at step 1664: 7.2648468017578125\n",
      "Training loss at step 1696: 7.55135440826416\n",
      "Training loss at step 1728: 7.6762871742248535\n",
      "Training loss at step 1760: 7.397454738616943\n",
      "Training loss at step 1792: 6.586301326751709\n",
      "Training loss at step 1824: 5.691864013671875\n",
      "Training loss at step 1856: 4.983940124511719\n",
      "Training loss at step 1888: 4.514313697814941\n",
      "Training loss at step 1920: 4.194219589233398\n",
      "Training loss at step 1952: 3.975163459777832\n",
      "Training loss at step 1984: 3.841892957687378\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at step 0: 3.9978837966918945\n",
      "Training loss at step 32: 3.560065269470215\n",
      "Training loss at step 64: 3.324808359146118\n",
      "Training loss at step 96: 3.1506500244140625\n",
      "Training loss at step 128: 3.0061635971069336\n",
      "Training loss at step 160: 2.8951456546783447\n",
      "Training loss at step 192: 2.8267123699188232\n",
      "Training loss at step 224: 2.801328420639038\n",
      "Training loss at step 256: 2.836153268814087\n",
      "Training loss at step 288: 3.0171453952789307\n",
      "Training loss at step 320: 3.4025802612304688\n",
      "Training loss at step 352: 3.9026131629943848\n",
      "Training loss at step 384: 4.37777853012085\n",
      "Training loss at step 416: 4.743927955627441\n",
      "Training loss at step 448: 5.02928352355957\n",
      "Training loss at step 480: 5.268633842468262\n",
      "Training loss at step 512: 5.51158332824707\n",
      "Training loss at step 544: 5.788529396057129\n",
      "Training loss at step 576: 6.117947578430176\n",
      "Training loss at step 608: 6.493258476257324\n",
      "Training loss at step 640: 6.898411273956299\n",
      "Training loss at step 672: 7.271008014678955\n",
      "Training loss at step 704: 7.536369323730469\n",
      "Training loss at step 736: 7.610898971557617\n",
      "Training loss at step 768: 7.205903053283691\n",
      "Training loss at step 800: 6.374749660491943\n",
      "Training loss at step 832: 5.550904273986816\n",
      "Training loss at step 864: 4.946475982666016\n",
      "Training loss at step 896: 4.517833709716797\n",
      "Training loss at step 928: 4.24237060546875\n",
      "Training loss at step 960: 4.034097194671631\n",
      "Training loss at step 992: 3.855698585510254\n",
      "Training loss at step 1024: 3.697589159011841\n",
      "Training loss at step 1056: 3.546103000640869\n",
      "Training loss at step 1088: 3.3602986335754395\n",
      "Training loss at step 1120: 3.183295965194702\n",
      "Training loss at step 1152: 3.0383026599884033\n",
      "Training loss at step 1184: 2.935641050338745\n",
      "Training loss at step 1216: 2.870238780975342\n",
      "Training loss at step 1248: 2.8470993041992188\n",
      "Training loss at step 1280: 2.9527652263641357\n",
      "Training loss at step 1312: 3.301179885864258\n",
      "Training loss at step 1344: 3.8324429988861084\n",
      "Training loss at step 1376: 4.354069232940674\n",
      "Training loss at step 1408: 4.784154891967773\n",
      "Training loss at step 1440: 5.136310577392578\n",
      "Training loss at step 1472: 5.389491081237793\n",
      "Training loss at step 1504: 5.610161304473877\n",
      "Training loss at step 1536: 5.8530378341674805\n",
      "Training loss at step 1568: 6.152254104614258\n",
      "Training loss at step 1600: 6.507692337036133\n",
      "Training loss at step 1632: 6.908246994018555\n",
      "Training loss at step 1664: 7.276096343994141\n",
      "Training loss at step 1696: 7.551682949066162\n",
      "Training loss at step 1728: 7.677740097045898\n",
      "Training loss at step 1760: 7.397145748138428\n",
      "Training loss at step 1792: 6.58583927154541\n",
      "Training loss at step 1824: 5.683622360229492\n",
      "Training loss at step 1856: 4.973248481750488\n",
      "Training loss at step 1888: 4.506759166717529\n",
      "Training loss at step 1920: 4.190898895263672\n",
      "Training loss at step 1952: 3.9619061946868896\n",
      "Training loss at step 1984: 3.819897413253784\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at step 0: 3.998110771179199\n",
      "Training loss at step 32: 3.5607855319976807\n",
      "Training loss at step 64: 3.323348045349121\n",
      "Training loss at step 96: 3.147418975830078\n",
      "Training loss at step 128: 3.00454044342041\n",
      "Training loss at step 160: 2.8980846405029297\n",
      "Training loss at step 192: 2.8346409797668457\n",
      "Training loss at step 224: 2.8116707801818848\n",
      "Training loss at step 256: 2.842888355255127\n",
      "Training loss at step 288: 3.0170881748199463\n",
      "Training loss at step 320: 3.406895160675049\n",
      "Training loss at step 352: 3.9268431663513184\n",
      "Training loss at step 384: 4.427372455596924\n",
      "Training loss at step 416: 4.7936882972717285\n",
      "Training loss at step 448: 5.057413101196289\n",
      "Training loss at step 480: 5.284777641296387\n",
      "Training loss at step 512: 5.521129131317139\n",
      "Training loss at step 544: 5.7951202392578125\n",
      "Training loss at step 576: 6.119539737701416\n",
      "Training loss at step 608: 6.490937232971191\n",
      "Training loss at step 640: 6.894931316375732\n",
      "Training loss at step 672: 7.266286373138428\n",
      "Training loss at step 704: 7.530555248260498\n",
      "Training loss at step 736: 7.605504989624023\n",
      "Training loss at step 768: 7.205151557922363\n",
      "Training loss at step 800: 6.3821330070495605\n",
      "Training loss at step 832: 5.560624599456787\n",
      "Training loss at step 864: 4.94671106338501\n",
      "Training loss at step 896: 4.508098125457764\n",
      "Training loss at step 928: 4.2237348556518555\n",
      "Training loss at step 960: 4.004003524780273\n",
      "Training loss at step 992: 3.822913408279419\n",
      "Training loss at step 1024: 3.6676735877990723\n",
      "Training loss at step 1056: 3.5036277770996094\n",
      "Training loss at step 1088: 3.306340456008911\n",
      "Training loss at step 1120: 3.125561237335205\n",
      "Training loss at step 1152: 2.9828238487243652\n",
      "Training loss at step 1184: 2.885991096496582\n",
      "Training loss at step 1216: 2.8294970989227295\n",
      "Training loss at step 1248: 2.8210017681121826\n",
      "Training loss at step 1280: 2.9529895782470703\n",
      "Training loss at step 1312: 3.3247973918914795\n",
      "Training loss at step 1344: 3.8612546920776367\n",
      "Training loss at step 1376: 4.368965148925781\n",
      "Training loss at step 1408: 4.774908065795898\n",
      "Training loss at step 1440: 5.1203765869140625\n",
      "Training loss at step 1472: 5.372282981872559\n",
      "Training loss at step 1504: 5.593596935272217\n",
      "Training loss at step 1536: 5.8379411697387695\n",
      "Training loss at step 1568: 6.136735916137695\n",
      "Training loss at step 1600: 6.495851516723633\n",
      "Training loss at step 1632: 6.896731376647949\n",
      "Training loss at step 1664: 7.262323379516602\n",
      "Training loss at step 1696: 7.544061660766602\n",
      "Training loss at step 1728: 7.670229911804199\n",
      "Training loss at step 1760: 7.393281936645508\n",
      "Training loss at step 1792: 6.585996627807617\n",
      "Training loss at step 1824: 5.691771984100342\n",
      "Training loss at step 1856: 4.9801812171936035\n",
      "Training loss at step 1888: 4.5103840827941895\n",
      "Training loss at step 1920: 4.189971446990967\n",
      "Training loss at step 1952: 3.970536470413208\n",
      "Training loss at step 1984: 3.8375022411346436\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at step 0: 3.9979915618896484\n",
      "Training loss at step 32: 3.559936761856079\n",
      "Training loss at step 64: 3.3237457275390625\n",
      "Training loss at step 96: 3.1490917205810547\n",
      "Training loss at step 128: 3.005017042160034\n",
      "Training loss at step 160: 2.8949265480041504\n",
      "Training loss at step 192: 2.8270115852355957\n",
      "Training loss at step 224: 2.801569938659668\n",
      "Training loss at step 256: 2.835998058319092\n",
      "Training loss at step 288: 3.0172441005706787\n",
      "Training loss at step 320: 3.4033637046813965\n",
      "Training loss at step 352: 3.904170036315918\n",
      "Training loss at step 384: 4.382108211517334\n",
      "Training loss at step 416: 4.753809928894043\n",
      "Training loss at step 448: 5.036470413208008\n",
      "Training loss at step 480: 5.27381706237793\n",
      "Training loss at step 512: 5.515719890594482\n",
      "Training loss at step 544: 5.79270076751709\n",
      "Training loss at step 576: 6.123727321624756\n",
      "Training loss at step 608: 6.496718883514404\n",
      "Training loss at step 640: 6.900517463684082\n",
      "Training loss at step 672: 7.27239990234375\n",
      "Training loss at step 704: 7.5364484786987305\n",
      "Training loss at step 736: 7.610954761505127\n",
      "Training loss at step 768: 7.205965042114258\n",
      "Training loss at step 800: 6.3735246658325195\n",
      "Training loss at step 832: 5.54620885848999\n",
      "Training loss at step 864: 4.938265323638916\n",
      "Training loss at step 896: 4.507135391235352\n",
      "Training loss at step 928: 4.232466220855713\n",
      "Training loss at step 960: 4.021815776824951\n",
      "Training loss at step 992: 3.843456268310547\n",
      "Training loss at step 1024: 3.6870899200439453\n",
      "Training loss at step 1056: 3.5336766242980957\n",
      "Training loss at step 1088: 3.3451766967773438\n",
      "Training loss at step 1120: 3.1661529541015625\n",
      "Training loss at step 1152: 3.021456003189087\n",
      "Training loss at step 1184: 2.9205451011657715\n",
      "Training loss at step 1216: 2.8578407764434814\n",
      "Training loss at step 1248: 2.8388116359710693\n",
      "Training loss at step 1280: 2.9518063068389893\n",
      "Training loss at step 1312: 3.3060097694396973\n",
      "Training loss at step 1344: 3.8374414443969727\n",
      "Training loss at step 1376: 4.353037357330322\n",
      "Training loss at step 1408: 4.772838115692139\n",
      "Training loss at step 1440: 5.121382713317871\n",
      "Training loss at step 1472: 5.376188278198242\n",
      "Training loss at step 1504: 5.598033905029297\n",
      "Training loss at step 1536: 5.84269905090332\n",
      "Training loss at step 1568: 6.144005298614502\n",
      "Training loss at step 1600: 6.498701095581055\n",
      "Training loss at step 1632: 6.899903297424316\n",
      "Training loss at step 1664: 7.26607084274292\n",
      "Training loss at step 1696: 7.543948173522949\n",
      "Training loss at step 1728: 7.66841983795166\n",
      "Training loss at step 1760: 7.392389297485352\n",
      "Training loss at step 1792: 6.585416316986084\n",
      "Training loss at step 1824: 5.685832977294922\n",
      "Training loss at step 1856: 4.97255277633667\n",
      "Training loss at step 1888: 4.503928184509277\n",
      "Training loss at step 1920: 4.186059951782227\n",
      "Training loss at step 1952: 3.9584076404571533\n",
      "Training loss at step 1984: 3.820784091949463\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at step 0: 3.9988913536071777\n",
      "Training loss at step 32: 3.5617616176605225\n",
      "Training loss at step 64: 3.3239455223083496\n",
      "Training loss at step 96: 3.147678852081299\n",
      "Training loss at step 128: 3.0048484802246094\n",
      "Training loss at step 160: 2.8985278606414795\n",
      "Training loss at step 192: 2.8349900245666504\n",
      "Training loss at step 224: 2.811656951904297\n",
      "Training loss at step 256: 2.842588424682617\n",
      "Training loss at step 288: 3.0169272422790527\n",
      "Training loss at step 320: 3.4061083793640137\n",
      "Training loss at step 352: 3.9244985580444336\n",
      "Training loss at step 384: 4.4241943359375\n",
      "Training loss at step 416: 4.7939453125\n",
      "Training loss at step 448: 5.060502052307129\n",
      "Training loss at step 480: 5.289069175720215\n",
      "Training loss at step 512: 5.5261688232421875\n",
      "Training loss at step 544: 5.801609992980957\n",
      "Training loss at step 576: 6.128918170928955\n",
      "Training loss at step 608: 6.497155666351318\n",
      "Training loss at step 640: 6.8993072509765625\n",
      "Training loss at step 672: 7.269885063171387\n",
      "Training loss at step 704: 7.53206729888916\n",
      "Training loss at step 736: 7.6050615310668945\n",
      "Training loss at step 768: 7.204824924468994\n",
      "Training loss at step 800: 6.377658843994141\n",
      "Training loss at step 832: 5.54924201965332\n",
      "Training loss at step 864: 4.92305850982666\n",
      "Training loss at step 896: 4.489035129547119\n",
      "Training loss at step 928: 4.212292194366455\n",
      "Training loss at step 960: 3.9966678619384766\n",
      "Training loss at step 992: 3.816014289855957\n",
      "Training loss at step 1024: 3.662109851837158\n",
      "Training loss at step 1056: 3.500692367553711\n",
      "Training loss at step 1088: 3.3041162490844727\n",
      "Training loss at step 1120: 3.123530864715576\n",
      "Training loss at step 1152: 2.980703115463257\n",
      "Training loss at step 1184: 2.8839361667633057\n",
      "Training loss at step 1216: 2.827817916870117\n",
      "Training loss at step 1248: 2.8200364112854004\n",
      "Training loss at step 1280: 2.9531989097595215\n",
      "Training loss at step 1312: 3.3252153396606445\n",
      "Training loss at step 1344: 3.8600833415985107\n",
      "Training loss at step 1376: 4.364497184753418\n",
      "Training loss at step 1408: 4.768058776855469\n",
      "Training loss at step 1440: 5.111886501312256\n",
      "Training loss at step 1472: 5.366339683532715\n",
      "Training loss at step 1504: 5.590660095214844\n",
      "Training loss at step 1536: 5.836236000061035\n",
      "Training loss at step 1568: 6.13410758972168\n",
      "Training loss at step 1600: 6.492038726806641\n",
      "Training loss at step 1632: 6.8910346031188965\n",
      "Training loss at step 1664: 7.2486066818237305\n",
      "Training loss at step 1696: 7.5319743156433105\n",
      "Training loss at step 1728: 7.664420127868652\n",
      "Training loss at step 1760: 7.389287948608398\n",
      "Training loss at step 1792: 6.586272239685059\n",
      "Training loss at step 1824: 5.6951446533203125\n",
      "Training loss at step 1856: 4.979508876800537\n",
      "Training loss at step 1888: 4.507958889007568\n",
      "Training loss at step 1920: 4.186841011047363\n",
      "Training loss at step 1952: 3.96981143951416\n",
      "Training loss at step 1984: 3.8388562202453613\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at step 0: 3.997908115386963\n",
      "Training loss at step 32: 3.559913158416748\n",
      "Training loss at step 64: 3.3238189220428467\n",
      "Training loss at step 96: 3.149413585662842\n",
      "Training loss at step 128: 3.0054545402526855\n",
      "Training loss at step 160: 2.895042896270752\n",
      "Training loss at step 192: 2.826417922973633\n",
      "Training loss at step 224: 2.80047869682312\n",
      "Training loss at step 256: 2.8353002071380615\n",
      "Training loss at step 288: 3.0172007083892822\n",
      "Training loss at step 320: 3.4023735523223877\n",
      "Training loss at step 352: 3.900786876678467\n",
      "Training loss at step 384: 4.376506805419922\n",
      "Training loss at step 416: 4.749650001525879\n",
      "Training loss at step 448: 5.03531551361084\n",
      "Training loss at step 480: 5.2743449211120605\n",
      "Training loss at step 512: 5.517303943634033\n",
      "Training loss at step 544: 5.795265197753906\n",
      "Training loss at step 576: 6.126877784729004\n",
      "Training loss at step 608: 6.497462749481201\n",
      "Training loss at step 640: 6.899683475494385\n",
      "Training loss at step 672: 7.270635604858398\n",
      "Training loss at step 704: 7.532927513122559\n",
      "Training loss at step 736: 7.606042861938477\n",
      "Training loss at step 768: 7.2048234939575195\n",
      "Training loss at step 800: 6.375400543212891\n",
      "Training loss at step 832: 5.5453410148620605\n",
      "Training loss at step 864: 4.918760776519775\n",
      "Training loss at step 896: 4.491530418395996\n",
      "Training loss at step 928: 4.22383451461792\n",
      "Training loss at step 960: 4.015219211578369\n",
      "Training loss at step 992: 3.838311195373535\n",
      "Training loss at step 1024: 3.683540105819702\n",
      "Training loss at step 1056: 3.5330233573913574\n",
      "Training loss at step 1088: 3.3465802669525146\n",
      "Training loss at step 1120: 3.1682536602020264\n",
      "Training loss at step 1152: 3.022235155105591\n",
      "Training loss at step 1184: 2.9206347465515137\n",
      "Training loss at step 1216: 2.85756516456604\n",
      "Training loss at step 1248: 2.8384554386138916\n",
      "Training loss at step 1280: 2.9517645835876465\n",
      "Training loss at step 1312: 3.3056416511535645\n",
      "Training loss at step 1344: 3.835592031478882\n",
      "Training loss at step 1376: 4.349027633666992\n",
      "Training loss at step 1408: 4.770246505737305\n",
      "Training loss at step 1440: 5.121899604797363\n",
      "Training loss at step 1472: 5.37917423248291\n",
      "Training loss at step 1504: 5.602657318115234\n",
      "Training loss at step 1536: 5.848574638366699\n",
      "Training loss at step 1568: 6.149879455566406\n",
      "Training loss at step 1600: 6.50568962097168\n",
      "Training loss at step 1632: 6.908605098724365\n",
      "Training loss at step 1664: 7.279698371887207\n",
      "Training loss at step 1696: 7.551646709442139\n",
      "Training loss at step 1728: 7.670922756195068\n",
      "Training loss at step 1760: 7.39314079284668\n",
      "Training loss at step 1792: 6.58499813079834\n",
      "Training loss at step 1824: 5.683035373687744\n",
      "Training loss at step 1856: 4.968780517578125\n",
      "Training loss at step 1888: 4.501731872558594\n",
      "Training loss at step 1920: 4.1877007484436035\n",
      "Training loss at step 1952: 3.9626388549804688\n",
      "Training loss at step 1984: 3.8239877223968506\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at step 0: 4.000277042388916\n",
      "Training loss at step 32: 3.563964605331421\n",
      "Training loss at step 64: 3.3255739212036133\n",
      "Training loss at step 96: 3.1487653255462646\n",
      "Training loss at step 128: 3.006099224090576\n",
      "Training loss at step 160: 2.9003586769104004\n",
      "Training loss at step 192: 2.8372628688812256\n",
      "Training loss at step 224: 2.8136351108551025\n",
      "Training loss at step 256: 2.8435323238372803\n",
      "Training loss at step 288: 3.016756296157837\n",
      "Training loss at step 320: 3.4049999713897705\n",
      "Training loss at step 352: 3.922154188156128\n",
      "Training loss at step 384: 4.420483589172363\n",
      "Training loss at step 416: 4.792060852050781\n",
      "Training loss at step 448: 5.059496879577637\n",
      "Training loss at step 480: 5.2892842292785645\n",
      "Training loss at step 512: 5.527121543884277\n",
      "Training loss at step 544: 5.802626609802246\n",
      "Training loss at step 576: 6.129268646240234\n",
      "Training loss at step 608: 6.496292591094971\n",
      "Training loss at step 640: 6.897718906402588\n",
      "Training loss at step 672: 7.267729759216309\n",
      "Training loss at step 704: 7.529563903808594\n",
      "Training loss at step 736: 7.6029229164123535\n",
      "Training loss at step 768: 7.204789161682129\n",
      "Training loss at step 800: 6.378563404083252\n",
      "Training loss at step 832: 5.545827865600586\n",
      "Training loss at step 864: 4.9282965660095215\n",
      "Training loss at step 896: 4.490814685821533\n",
      "Training loss at step 928: 4.209677696228027\n",
      "Training loss at step 960: 3.991079092025757\n",
      "Training loss at step 992: 3.8109781742095947\n",
      "Training loss at step 1024: 3.659815788269043\n",
      "Training loss at step 1056: 3.4983115196228027\n",
      "Training loss at step 1088: 3.299701452255249\n",
      "Training loss at step 1120: 3.1174330711364746\n",
      "Training loss at step 1152: 2.9740402698516846\n",
      "Training loss at step 1184: 2.8775246143341064\n",
      "Training loss at step 1216: 2.8225064277648926\n",
      "Training loss at step 1248: 2.816974639892578\n",
      "Training loss at step 1280: 2.95434832572937\n",
      "Training loss at step 1312: 3.3288733959198\n",
      "Training loss at step 1344: 3.861612319946289\n",
      "Training loss at step 1376: 4.360706806182861\n",
      "Training loss at step 1408: 4.75987434387207\n",
      "Training loss at step 1440: 5.110856533050537\n",
      "Training loss at step 1472: 5.36782169342041\n",
      "Training loss at step 1504: 5.593518257141113\n",
      "Training loss at step 1536: 5.838830947875977\n",
      "Training loss at step 1568: 6.1354079246521\n",
      "Training loss at step 1600: 6.492148399353027\n",
      "Training loss at step 1632: 6.887754440307617\n",
      "Training loss at step 1664: 7.243093967437744\n",
      "Training loss at step 1696: 7.53529167175293\n",
      "Training loss at step 1728: 7.663407802581787\n",
      "Training loss at step 1760: 7.386996746063232\n",
      "Training loss at step 1792: 6.5864081382751465\n",
      "Training loss at step 1824: 5.700676918029785\n",
      "Training loss at step 1856: 4.982799530029297\n",
      "Training loss at step 1888: 4.5081071853637695\n",
      "Training loss at step 1920: 4.1855902671813965\n",
      "Training loss at step 1952: 3.9689059257507324\n",
      "Training loss at step 1984: 3.8401546478271484\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at step 0: 3.9981064796447754\n",
      "Training loss at step 32: 3.5600547790527344\n",
      "Training loss at step 64: 3.3250880241394043\n",
      "Training loss at step 96: 3.151522636413574\n",
      "Training loss at step 128: 3.0075888633728027\n",
      "Training loss at step 160: 2.8957557678222656\n",
      "Training loss at step 192: 2.8255555629730225\n",
      "Training loss at step 224: 2.798915386199951\n",
      "Training loss at step 256: 2.8346424102783203\n",
      "Training loss at step 288: 3.0170395374298096\n",
      "Training loss at step 320: 3.3995702266693115\n",
      "Training loss at step 352: 3.893566131591797\n",
      "Training loss at step 384: 4.3655829429626465\n",
      "Training loss at step 416: 4.740589141845703\n",
      "Training loss at step 448: 5.030112266540527\n",
      "Training loss at step 480: 5.272068023681641\n",
      "Training loss at step 512: 5.516644477844238\n",
      "Training loss at step 544: 5.795370101928711\n",
      "Training loss at step 576: 6.128334999084473\n",
      "Training loss at step 608: 6.498715877532959\n",
      "Training loss at step 640: 6.900015354156494\n",
      "Training loss at step 672: 7.270409107208252\n",
      "Training loss at step 704: 7.532395362854004\n",
      "Training loss at step 736: 7.6049699783325195\n",
      "Training loss at step 768: 7.204652786254883\n",
      "Training loss at step 800: 6.374843120574951\n",
      "Training loss at step 832: 5.5409088134765625\n",
      "Training loss at step 864: 4.919227600097656\n",
      "Training loss at step 896: 4.491591930389404\n",
      "Training loss at step 928: 4.225595474243164\n",
      "Training loss at step 960: 4.017884731292725\n",
      "Training loss at step 992: 3.84222149848938\n",
      "Training loss at step 1024: 3.692748785018921\n",
      "Training loss at step 1056: 3.547854423522949\n",
      "Training loss at step 1088: 3.361625909805298\n",
      "Training loss at step 1120: 3.1795294284820557\n",
      "Training loss at step 1152: 3.0324389934539795\n",
      "Training loss at step 1184: 2.929102659225464\n",
      "Training loss at step 1216: 2.8642661571502686\n",
      "Training loss at step 1248: 2.842547655105591\n",
      "Training loss at step 1280: 2.9520745277404785\n",
      "Training loss at step 1312: 3.303044319152832\n",
      "Training loss at step 1344: 3.8311991691589355\n",
      "Training loss at step 1376: 4.343825340270996\n",
      "Training loss at step 1408: 4.765933990478516\n",
      "Training loss at step 1440: 5.119611740112305\n",
      "Training loss at step 1472: 5.3795166015625\n",
      "Training loss at step 1504: 5.605251312255859\n",
      "Training loss at step 1536: 5.852324485778809\n",
      "Training loss at step 1568: 6.14935302734375\n",
      "Training loss at step 1600: 6.503379821777344\n",
      "Training loss at step 1632: 6.906251907348633\n",
      "Training loss at step 1664: 7.264939308166504\n",
      "Training loss at step 1696: 7.540197849273682\n",
      "Training loss at step 1728: 7.670413970947266\n",
      "Training loss at step 1760: 7.393214225769043\n",
      "Training loss at step 1792: 6.585189342498779\n",
      "Training loss at step 1824: 5.684597969055176\n",
      "Training loss at step 1856: 4.965124607086182\n",
      "Training loss at step 1888: 4.493257999420166\n",
      "Training loss at step 1920: 4.175786972045898\n",
      "Training loss at step 1952: 3.9498403072357178\n",
      "Training loss at step 1984: 3.8112847805023193\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at step 0: 3.9998724460601807\n",
      "Training loss at step 32: 3.563370943069458\n",
      "Training loss at step 64: 3.324772357940674\n",
      "Training loss at step 96: 3.148040294647217\n",
      "Training loss at step 128: 3.004849910736084\n",
      "Training loss at step 160: 2.8978569507598877\n",
      "Training loss at step 192: 2.833313465118408\n",
      "Training loss at step 224: 2.809396743774414\n",
      "Training loss at step 256: 2.8409976959228516\n",
      "Training loss at step 288: 3.016622543334961\n",
      "Training loss at step 320: 3.4036941528320312\n",
      "Training loss at step 352: 3.919814109802246\n",
      "Training loss at step 384: 4.4179534912109375\n",
      "Training loss at step 416: 4.791342735290527\n",
      "Training loss at step 448: 5.0613555908203125\n",
      "Training loss at step 480: 5.2919464111328125\n",
      "Training loss at step 512: 5.530491352081299\n",
      "Training loss at step 544: 5.807034492492676\n",
      "Training loss at step 576: 6.1352691650390625\n",
      "Training loss at step 608: 6.49915885925293\n",
      "Training loss at step 640: 6.897948265075684\n",
      "Training loss at step 672: 7.267382621765137\n",
      "Training loss at step 704: 7.528713226318359\n",
      "Training loss at step 736: 7.601809501647949\n",
      "Training loss at step 768: 7.204711437225342\n",
      "Training loss at step 800: 6.379025936126709\n",
      "Training loss at step 832: 5.5436248779296875\n",
      "Training loss at step 864: 4.908384323120117\n",
      "Training loss at step 896: 4.4742512702941895\n",
      "Training loss at step 928: 4.203324794769287\n",
      "Training loss at step 960: 3.9862239360809326\n",
      "Training loss at step 992: 3.806771755218506\n",
      "Training loss at step 1024: 3.656714916229248\n",
      "Training loss at step 1056: 3.4963958263397217\n",
      "Training loss at step 1088: 3.2987499237060547\n",
      "Training loss at step 1120: 3.1158523559570312\n",
      "Training loss at step 1152: 2.972651481628418\n",
      "Training loss at step 1184: 2.87650203704834\n",
      "Training loss at step 1216: 2.821786642074585\n",
      "Training loss at step 1248: 2.816671371459961\n",
      "Training loss at step 1280: 2.954526901245117\n",
      "Training loss at step 1312: 3.328862428665161\n",
      "Training loss at step 1344: 3.8602659702301025\n",
      "Training loss at step 1376: 4.356893539428711\n",
      "Training loss at step 1408: 4.754877090454102\n",
      "Training loss at step 1440: 5.104525089263916\n",
      "Training loss at step 1472: 5.363619327545166\n",
      "Training loss at step 1504: 5.590508937835693\n",
      "Training loss at step 1536: 5.837723731994629\n",
      "Training loss at step 1568: 6.135733604431152\n",
      "Training loss at step 1600: 6.494688987731934\n",
      "Training loss at step 1632: 6.892936706542969\n",
      "Training loss at step 1664: 7.246654033660889\n",
      "Training loss at step 1696: 7.533839225769043\n",
      "Training loss at step 1728: 7.659206867218018\n",
      "Training loss at step 1760: 7.383503437042236\n",
      "Training loss at step 1792: 6.5863542556762695\n",
      "Training loss at step 1824: 5.699428558349609\n",
      "Training loss at step 1856: 4.978400707244873\n",
      "Training loss at step 1888: 4.5049214363098145\n",
      "Training loss at step 1920: 4.185301780700684\n",
      "Training loss at step 1952: 3.96781325340271\n",
      "Training loss at step 1984: 3.8397254943847656\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at step 0: 3.998351573944092\n",
      "Training loss at step 32: 3.5605149269104004\n",
      "Training loss at step 64: 3.323256254196167\n",
      "Training loss at step 96: 3.1482152938842773\n",
      "Training loss at step 128: 3.0046274662017822\n",
      "Training loss at step 160: 2.894913673400879\n",
      "Training loss at step 192: 2.8269243240356445\n",
      "Training loss at step 224: 2.8011980056762695\n",
      "Training loss at step 256: 2.835799217224121\n",
      "Training loss at step 288: 3.016953945159912\n",
      "Training loss at step 320: 3.400505781173706\n",
      "Training loss at step 352: 3.895784378051758\n",
      "Training loss at step 384: 4.367452144622803\n",
      "Training loss at step 416: 4.74474573135376\n",
      "Training loss at step 448: 5.034623622894287\n",
      "Training loss at step 480: 5.275705337524414\n",
      "Training loss at step 512: 5.520017623901367\n",
      "Training loss at step 544: 5.799037933349609\n",
      "Training loss at step 576: 6.13210391998291\n",
      "Training loss at step 608: 6.4996185302734375\n",
      "Training loss at step 640: 6.898412704467773\n",
      "Training loss at step 672: 7.267818450927734\n",
      "Training loss at step 704: 7.528942108154297\n",
      "Training loss at step 736: 7.60162353515625\n",
      "Training loss at step 768: 7.204823970794678\n",
      "Training loss at step 800: 6.37918758392334\n",
      "Training loss at step 832: 5.541646957397461\n",
      "Training loss at step 864: 4.910937786102295\n",
      "Training loss at step 896: 4.478910446166992\n",
      "Training loss at step 928: 4.21252965927124\n",
      "Training loss at step 960: 4.003170013427734\n",
      "Training loss at step 992: 3.8267674446105957\n",
      "Training loss at step 1024: 3.6731014251708984\n",
      "Training loss at step 1056: 3.524008274078369\n",
      "Training loss at step 1088: 3.3380935192108154\n",
      "Training loss at step 1120: 3.158174514770508\n",
      "Training loss at step 1152: 3.0115275382995605\n",
      "Training loss at step 1184: 2.909872531890869\n",
      "Training loss at step 1216: 2.848266839981079\n",
      "Training loss at step 1248: 2.8324363231658936\n",
      "Training loss at step 1280: 2.951573133468628\n",
      "Training loss at step 1312: 3.308526039123535\n",
      "Training loss at step 1344: 3.8364882469177246\n",
      "Training loss at step 1376: 4.34277868270874\n",
      "Training loss at step 1408: 4.759241580963135\n",
      "Training loss at step 1440: 5.111518383026123\n",
      "Training loss at step 1472: 5.372798442840576\n",
      "Training loss at step 1504: 5.601200103759766\n",
      "Training loss at step 1536: 5.850901126861572\n",
      "Training loss at step 1568: 6.152876377105713\n",
      "Training loss at step 1600: 6.509098052978516\n",
      "Training loss at step 1632: 6.912956714630127\n",
      "Training loss at step 1664: 7.276454448699951\n",
      "Training loss at step 1696: 7.544567584991455\n",
      "Training loss at step 1728: 7.664396286010742\n",
      "Training loss at step 1760: 7.387667179107666\n",
      "Training loss at step 1792: 6.584918975830078\n",
      "Training loss at step 1824: 5.68552303314209\n",
      "Training loss at step 1856: 4.965965747833252\n",
      "Training loss at step 1888: 4.4965081214904785\n",
      "Training loss at step 1920: 4.182799339294434\n",
      "Training loss at step 1952: 3.963812828063965\n",
      "Training loss at step 1984: 3.832667589187622\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at step 0: 3.999791383743286\n",
      "Training loss at step 32: 3.5629208087921143\n",
      "Training loss at step 64: 3.324483871459961\n",
      "Training loss at step 96: 3.147946834564209\n",
      "Training loss at step 128: 3.0049920082092285\n",
      "Training loss at step 160: 2.8984227180480957\n",
      "Training loss at step 192: 2.8344671726226807\n",
      "Training loss at step 224: 2.8111765384674072\n",
      "Training loss at step 256: 2.8426661491394043\n",
      "Training loss at step 288: 3.0165581703186035\n",
      "Training loss at step 320: 3.3992130756378174\n",
      "Training loss at step 352: 3.9078879356384277\n",
      "Training loss at step 384: 4.401111602783203\n",
      "Training loss at step 416: 4.777958393096924\n",
      "Training loss at step 448: 5.054248809814453\n",
      "Training loss at step 480: 5.288572788238525\n",
      "Training loss at step 512: 5.529557704925537\n",
      "Training loss at step 544: 5.806991100311279\n",
      "Training loss at step 576: 6.138626575469971\n",
      "Training loss at step 608: 6.504002094268799\n",
      "Training loss at step 640: 6.901852130889893\n",
      "Training loss at step 672: 7.270288467407227\n",
      "Training loss at step 704: 7.530835151672363\n",
      "Training loss at step 736: 7.602913856506348\n",
      "Training loss at step 768: 7.2044358253479\n",
      "Training loss at step 800: 6.374075412750244\n",
      "Training loss at step 832: 5.5324883460998535\n",
      "Training loss at step 864: 4.910542011260986\n",
      "Training loss at step 896: 4.476990699768066\n",
      "Training loss at step 928: 4.206704139709473\n",
      "Training loss at step 960: 3.9903666973114014\n",
      "Training loss at step 992: 3.812983512878418\n",
      "Training loss at step 1024: 3.668325424194336\n",
      "Training loss at step 1056: 3.5134687423706055\n",
      "Training loss at step 1088: 3.3131542205810547\n",
      "Training loss at step 1120: 3.127255439758301\n",
      "Training loss at step 1152: 2.979743003845215\n",
      "Training loss at step 1184: 2.880481719970703\n",
      "Training loss at step 1216: 2.8236894607543945\n",
      "Training loss at step 1248: 2.8171610832214355\n",
      "Training loss at step 1280: 2.954233407974243\n",
      "Training loss at step 1312: 3.327767848968506\n",
      "Training loss at step 1344: 3.8568267822265625\n",
      "Training loss at step 1376: 4.350327491760254\n",
      "Training loss at step 1408: 4.74798583984375\n",
      "Training loss at step 1440: 5.10344123840332\n",
      "Training loss at step 1472: 5.365206718444824\n",
      "Training loss at step 1504: 5.594232559204102\n",
      "Training loss at step 1536: 5.837934494018555\n",
      "Training loss at step 1568: 6.131841659545898\n",
      "Training loss at step 1600: 6.486952781677246\n",
      "Training loss at step 1632: 6.871295928955078\n",
      "Training loss at step 1664: 7.2290873527526855\n",
      "Training loss at step 1696: 7.526219367980957\n",
      "Training loss at step 1728: 7.6542158126831055\n",
      "Training loss at step 1760: 7.381871223449707\n",
      "Training loss at step 1792: 6.587430000305176\n",
      "Training loss at step 1824: 5.712462902069092\n",
      "Training loss at step 1856: 4.991512298583984\n",
      "Training loss at step 1888: 4.507362365722656\n",
      "Training loss at step 1920: 4.183931827545166\n",
      "Training loss at step 1952: 3.957845687866211\n",
      "Training loss at step 1984: 3.8280367851257324\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at step 0: 3.998368501663208\n",
      "Training loss at step 32: 3.560387372970581\n",
      "Training loss at step 64: 3.3266091346740723\n",
      "Training loss at step 96: 3.15390682220459\n",
      "Training loss at step 128: 3.0100111961364746\n",
      "Training loss at step 160: 2.8971662521362305\n",
      "Training loss at step 192: 2.8252358436584473\n",
      "Training loss at step 224: 2.7977211475372314\n",
      "Training loss at step 256: 2.8342695236206055\n",
      "Training loss at step 288: 3.0166897773742676\n",
      "Training loss at step 320: 3.395153522491455\n",
      "Training loss at step 352: 3.883988857269287\n",
      "Training loss at step 384: 4.356265068054199\n",
      "Training loss at step 416: 4.7398271560668945\n",
      "Training loss at step 448: 5.032333850860596\n",
      "Training loss at step 480: 5.275366306304932\n",
      "Training loss at step 512: 5.521056175231934\n",
      "Training loss at step 544: 5.801100254058838\n",
      "Training loss at step 576: 6.132521629333496\n",
      "Training loss at step 608: 6.499901294708252\n",
      "Training loss at step 640: 6.898687362670898\n",
      "Training loss at step 672: 7.267476558685303\n",
      "Training loss at step 704: 7.527486324310303\n",
      "Training loss at step 736: 7.6001739501953125\n",
      "Training loss at step 768: 7.204565048217773\n",
      "Training loss at step 800: 6.376171112060547\n",
      "Training loss at step 832: 5.532008171081543\n",
      "Training loss at step 864: 4.891899108886719\n",
      "Training loss at step 896: 4.469053268432617\n",
      "Training loss at step 928: 4.208935260772705\n",
      "Training loss at step 960: 4.002556800842285\n",
      "Training loss at step 992: 3.827939987182617\n",
      "Training loss at step 1024: 3.677398204803467\n",
      "Training loss at step 1056: 3.534139394760132\n",
      "Training loss at step 1088: 3.3498337268829346\n",
      "Training loss at step 1120: 3.1694421768188477\n",
      "Training loss at step 1152: 3.0216946601867676\n",
      "Training loss at step 1184: 2.918656349182129\n",
      "Training loss at step 1216: 2.8552215099334717\n",
      "Training loss at step 1248: 2.8372416496276855\n",
      "Training loss at step 1280: 2.951655626296997\n",
      "Training loss at step 1312: 3.303760051727295\n",
      "Training loss at step 1344: 3.8275585174560547\n",
      "Training loss at step 1376: 4.332503318786621\n",
      "Training loss at step 1408: 4.7496161460876465\n",
      "Training loss at step 1440: 5.1054463386535645\n",
      "Training loss at step 1472: 5.371747016906738\n",
      "Training loss at step 1504: 5.604177474975586\n",
      "Training loss at step 1536: 5.8573760986328125\n",
      "Training loss at step 1568: 6.1567230224609375\n",
      "Training loss at step 1600: 6.510254859924316\n",
      "Training loss at step 1632: 6.916654586791992\n",
      "Training loss at step 1664: 7.27380895614624\n",
      "Training loss at step 1696: 7.539425373077393\n",
      "Training loss at step 1728: 7.663748741149902\n",
      "Training loss at step 1760: 7.3882222175598145\n",
      "Training loss at step 1792: 6.584771633148193\n",
      "Training loss at step 1824: 5.682469367980957\n",
      "Training loss at step 1856: 4.959203720092773\n",
      "Training loss at step 1888: 4.48662805557251\n",
      "Training loss at step 1920: 4.173126220703125\n",
      "Training loss at step 1952: 3.9582881927490234\n",
      "Training loss at step 1984: 3.8244121074676514\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at step 0: 4.00186824798584\n",
      "Training loss at step 32: 3.565582275390625\n",
      "Training loss at step 64: 3.326108694076538\n",
      "Training loss at step 96: 3.1486873626708984\n",
      "Training loss at step 128: 3.005324125289917\n",
      "Training loss at step 160: 2.8979625701904297\n",
      "Training loss at step 192: 2.832045078277588\n",
      "Training loss at step 224: 2.8073198795318604\n",
      "Training loss at step 256: 2.839388847351074\n",
      "Training loss at step 288: 3.0165553092956543\n",
      "Training loss at step 320: 3.400845766067505\n",
      "Training loss at step 352: 3.9110140800476074\n",
      "Training loss at step 384: 4.405716896057129\n",
      "Training loss at step 416: 4.781856536865234\n",
      "Training loss at step 448: 5.05820369720459\n",
      "Training loss at step 480: 5.292084217071533\n",
      "Training loss at step 512: 5.533092498779297\n",
      "Training loss at step 544: 5.811009407043457\n",
      "Training loss at step 576: 6.139675617218018\n",
      "Training loss at step 608: 6.50026273727417\n",
      "Training loss at step 640: 6.89407205581665\n",
      "Training loss at step 672: 7.2627387046813965\n",
      "Training loss at step 704: 7.524021148681641\n",
      "Training loss at step 736: 7.597439289093018\n",
      "Training loss at step 768: 7.20688009262085\n",
      "Training loss at step 800: 6.382423400878906\n",
      "Training loss at step 832: 5.52316951751709\n",
      "Training loss at step 864: 4.889812469482422\n",
      "Training loss at step 896: 4.457810878753662\n",
      "Training loss at step 928: 4.192503929138184\n",
      "Training loss at step 960: 3.975983142852783\n",
      "Training loss at step 992: 3.799301862716675\n",
      "Training loss at step 1024: 3.656489610671997\n",
      "Training loss at step 1056: 3.5012967586517334\n",
      "Training loss at step 1088: 3.3019890785217285\n",
      "Training loss at step 1120: 3.115659475326538\n",
      "Training loss at step 1152: 2.970036268234253\n",
      "Training loss at step 1184: 2.8728725910186768\n",
      "Training loss at step 1216: 2.818164587020874\n",
      "Training loss at step 1248: 2.8144161701202393\n",
      "Training loss at step 1280: 2.95589280128479\n",
      "Training loss at step 1312: 3.3322362899780273\n",
      "Training loss at step 1344: 3.860090970993042\n",
      "Training loss at step 1376: 4.348599433898926\n",
      "Training loss at step 1408: 4.742839336395264\n",
      "Training loss at step 1440: 5.096632480621338\n",
      "Training loss at step 1472: 5.361893653869629\n",
      "Training loss at step 1504: 5.593181133270264\n",
      "Training loss at step 1536: 5.843314170837402\n",
      "Training loss at step 1568: 6.14077091217041\n",
      "Training loss at step 1600: 6.499931812286377\n",
      "Training loss at step 1632: 6.893881320953369\n",
      "Training loss at step 1664: 7.243948459625244\n",
      "Training loss at step 1696: 7.527133941650391\n",
      "Training loss at step 1728: 7.6562089920043945\n",
      "Training loss at step 1760: 7.382019519805908\n",
      "Training loss at step 1792: 6.586955547332764\n",
      "Training loss at step 1824: 5.703936576843262\n",
      "Training loss at step 1856: 4.975965976715088\n",
      "Training loss at step 1888: 4.496214866638184\n",
      "Training loss at step 1920: 4.177184581756592\n",
      "Training loss at step 1952: 3.9635250568389893\n",
      "Training loss at step 1984: 3.8407135009765625\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at step 0: 3.998426914215088\n",
      "Training loss at step 32: 3.560384511947632\n",
      "Training loss at step 64: 3.323563575744629\n",
      "Training loss at step 96: 3.1488049030303955\n",
      "Training loss at step 128: 3.0051300525665283\n",
      "Training loss at step 160: 2.894935369491577\n",
      "Training loss at step 192: 2.8268930912017822\n",
      "Training loss at step 224: 2.8017570972442627\n",
      "Training loss at step 256: 2.836845636367798\n",
      "Training loss at step 288: 3.0165786743164062\n",
      "Training loss at step 320: 3.3962314128875732\n",
      "Training loss at step 352: 3.8870205879211426\n",
      "Training loss at step 384: 4.357007026672363\n",
      "Training loss at step 416: 4.740731239318848\n",
      "Training loss at step 448: 5.034771919250488\n",
      "Training loss at step 480: 5.277990341186523\n",
      "Training loss at step 512: 5.524272918701172\n",
      "Training loss at step 544: 5.805163383483887\n",
      "Training loss at step 576: 6.142322540283203\n",
      "Training loss at step 608: 6.514449596405029\n",
      "Training loss at step 640: 6.908590793609619\n",
      "Training loss at step 672: 7.276304244995117\n",
      "Training loss at step 704: 7.536449432373047\n",
      "Training loss at step 736: 7.607454299926758\n",
      "Training loss at step 768: 7.2049102783203125\n",
      "Training loss at step 800: 6.368003845214844\n",
      "Training loss at step 832: 5.523576736450195\n",
      "Training loss at step 864: 4.89932107925415\n",
      "Training loss at step 896: 4.4727067947387695\n",
      "Training loss at step 928: 4.211479663848877\n",
      "Training loss at step 960: 4.002340793609619\n",
      "Training loss at step 992: 3.8274786472320557\n",
      "Training loss at step 1024: 3.6802728176116943\n",
      "Training loss at step 1056: 3.5373244285583496\n",
      "Training loss at step 1088: 3.349043846130371\n",
      "Training loss at step 1120: 3.1617791652679443\n",
      "Training loss at step 1152: 3.011133909225464\n",
      "Training loss at step 1184: 2.907759428024292\n",
      "Training loss at step 1216: 2.84568452835083\n",
      "Training loss at step 1248: 2.8302903175354004\n",
      "Training loss at step 1280: 2.951692581176758\n",
      "Training loss at step 1312: 3.311992883682251\n",
      "Training loss at step 1344: 3.838054895401001\n",
      "Training loss at step 1376: 4.335293769836426\n",
      "Training loss at step 1408: 4.744351863861084\n",
      "Training loss at step 1440: 5.095218181610107\n",
      "Training loss at step 1472: 5.359990119934082\n",
      "Training loss at step 1504: 5.5930280685424805\n",
      "Training loss at step 1536: 5.844875335693359\n",
      "Training loss at step 1568: 6.134405136108398\n",
      "Training loss at step 1600: 6.490145206451416\n",
      "Training loss at step 1632: 6.881707191467285\n",
      "Training loss at step 1664: 7.2240800857543945\n",
      "Training loss at step 1696: 7.510746955871582\n",
      "Training loss at step 1728: 7.646210670471191\n",
      "Training loss at step 1760: 7.378417491912842\n",
      "Training loss at step 1792: 6.5897979736328125\n",
      "Training loss at step 1824: 5.706962585449219\n",
      "Training loss at step 1856: 4.973621368408203\n",
      "Training loss at step 1888: 4.491362571716309\n",
      "Training loss at step 1920: 4.170929431915283\n",
      "Training loss at step 1952: 3.953137159347534\n",
      "Training loss at step 1984: 3.8208136558532715\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at step 0: 3.9988207817077637\n",
      "Training loss at step 32: 3.561062812805176\n",
      "Training loss at step 64: 3.323439836502075\n",
      "Training loss at step 96: 3.1479101181030273\n",
      "Training loss at step 128: 3.0041797161102295\n",
      "Training loss at step 160: 2.8952369689941406\n",
      "Training loss at step 192: 2.8285436630249023\n",
      "Training loss at step 224: 2.8045876026153564\n",
      "Training loss at step 256: 2.8394057750701904\n",
      "Training loss at step 288: 3.016474962234497\n",
      "Training loss at step 320: 3.394963026046753\n",
      "Training loss at step 352: 3.898000717163086\n",
      "Training loss at step 384: 4.3890180587768555\n",
      "Training loss at step 416: 4.76893424987793\n",
      "Training loss at step 448: 5.0541791915893555\n",
      "Training loss at step 480: 5.291528701782227\n",
      "Training loss at step 512: 5.535004138946533\n",
      "Training loss at step 544: 5.813767433166504\n",
      "Training loss at step 576: 6.138238906860352\n",
      "Training loss at step 608: 6.502179145812988\n",
      "Training loss at step 640: 6.896125793457031\n",
      "Training loss at step 672: 7.264477729797363\n",
      "Training loss at step 704: 7.525211334228516\n",
      "Training loss at step 736: 7.598682880401611\n",
      "Training loss at step 768: 7.205157279968262\n",
      "Training loss at step 800: 6.378975868225098\n",
      "Training loss at step 832: 5.52893590927124\n",
      "Training loss at step 864: 4.862578868865967\n",
      "Training loss at step 896: 4.445476055145264\n",
      "Training loss at step 928: 4.1854329109191895\n",
      "Training loss at step 960: 3.9722225666046143\n",
      "Training loss at step 992: 3.797271490097046\n",
      "Training loss at step 1024: 3.6561641693115234\n",
      "Training loss at step 1056: 3.507443904876709\n",
      "Training loss at step 1088: 3.3098397254943848\n",
      "Training loss at step 1120: 3.123077154159546\n",
      "Training loss at step 1152: 2.975437879562378\n",
      "Training loss at step 1184: 2.8766868114471436\n",
      "Training loss at step 1216: 2.820686101913452\n",
      "Training loss at step 1248: 2.815603733062744\n",
      "Training loss at step 1280: 2.9551610946655273\n",
      "Training loss at step 1312: 3.3295681476593018\n",
      "Training loss at step 1344: 3.8557815551757812\n",
      "Training loss at step 1376: 4.342896461486816\n",
      "Training loss at step 1408: 4.740574836730957\n",
      "Training loss at step 1440: 5.097687721252441\n",
      "Training loss at step 1472: 5.366700172424316\n",
      "Training loss at step 1504: 5.600384712219238\n",
      "Training loss at step 1536: 5.851365089416504\n",
      "Training loss at step 1568: 6.1483049392700195\n",
      "Training loss at step 1600: 6.505315780639648\n",
      "Training loss at step 1632: 6.903141498565674\n",
      "Training loss at step 1664: 7.246848106384277\n",
      "Training loss at step 1696: 7.5282063484191895\n",
      "Training loss at step 1728: 7.6525373458862305\n",
      "Training loss at step 1760: 7.379156112670898\n",
      "Training loss at step 1792: 6.58729362487793\n",
      "Training loss at step 1824: 5.697752475738525\n",
      "Training loss at step 1856: 4.968184471130371\n",
      "Training loss at step 1888: 4.4927592277526855\n",
      "Training loss at step 1920: 4.175487995147705\n",
      "Training loss at step 1952: 3.962578296661377\n",
      "Training loss at step 1984: 3.8408803939819336\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at step 0: 3.9987599849700928\n",
      "Training loss at step 32: 3.561404228210449\n",
      "Training loss at step 64: 3.323279619216919\n",
      "Training loss at step 96: 3.147479295730591\n",
      "Training loss at step 128: 3.0040202140808105\n",
      "Training loss at step 160: 2.895143985748291\n",
      "Training loss at step 192: 2.8281497955322266\n",
      "Training loss at step 224: 2.803173542022705\n",
      "Training loss at step 256: 2.8373796939849854\n",
      "Training loss at step 288: 3.0164833068847656\n",
      "Training loss at step 320: 3.396535634994507\n",
      "Training loss at step 352: 3.8868069648742676\n",
      "Training loss at step 384: 4.3549089431762695\n",
      "Training loss at step 416: 4.740127086639404\n",
      "Training loss at step 448: 5.036303997039795\n",
      "Training loss at step 480: 5.279777526855469\n",
      "Training loss at step 512: 5.5263566970825195\n",
      "Training loss at step 544: 5.807250022888184\n",
      "Training loss at step 576: 6.1389970779418945\n",
      "Training loss at step 608: 6.505441665649414\n",
      "Training loss at step 640: 6.898894309997559\n",
      "Training loss at step 672: 7.265561103820801\n",
      "Training loss at step 704: 7.525888442993164\n",
      "Training loss at step 736: 7.599457263946533\n",
      "Training loss at step 768: 7.2041497230529785\n",
      "Training loss at step 800: 6.371803283691406\n",
      "Training loss at step 832: 5.518842697143555\n",
      "Training loss at step 864: 4.8790283203125\n",
      "Training loss at step 896: 4.4549946784973145\n",
      "Training loss at step 928: 4.194008827209473\n",
      "Training loss at step 960: 3.9844725131988525\n",
      "Training loss at step 992: 3.8093483448028564\n",
      "Training loss at step 1024: 3.6577093601226807\n",
      "Training loss at step 1056: 3.5099897384643555\n",
      "Training loss at step 1088: 3.327047109603882\n",
      "Training loss at step 1120: 3.141529083251953\n",
      "Training loss at step 1152: 2.9923770427703857\n",
      "Training loss at step 1184: 2.890807628631592\n",
      "Training loss at step 1216: 2.8320200443267822\n",
      "Training loss at step 1248: 2.822580099105835\n",
      "Training loss at step 1280: 2.9520699977874756\n",
      "Training loss at step 1312: 3.313312530517578\n",
      "Training loss at step 1344: 3.831183671951294\n",
      "Training loss at step 1376: 4.317684173583984\n",
      "Training loss at step 1408: 4.725321292877197\n",
      "Training loss at step 1440: 5.078625679016113\n",
      "Training loss at step 1472: 5.349595069885254\n",
      "Training loss at step 1504: 5.589252948760986\n",
      "Training loss at step 1536: 5.849726676940918\n",
      "Training loss at step 1568: 6.151748180389404\n",
      "Training loss at step 1600: 6.508103370666504\n",
      "Training loss at step 1632: 6.9111456871032715\n",
      "Training loss at step 1664: 7.256805419921875\n",
      "Training loss at step 1696: 7.521200656890869\n",
      "Training loss at step 1728: 7.644083023071289\n",
      "Training loss at step 1760: 7.375744819641113\n",
      "Training loss at step 1792: 6.587148666381836\n",
      "Training loss at step 1824: 5.69067907333374\n",
      "Training loss at step 1856: 4.95945930480957\n",
      "Training loss at step 1888: 4.484471321105957\n",
      "Training loss at step 1920: 4.173559665679932\n",
      "Training loss at step 1952: 3.9687323570251465\n",
      "Training loss at step 1984: 3.846850872039795\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at step 0: 3.998584270477295\n",
      "Training loss at step 32: 3.560638427734375\n",
      "Training loss at step 64: 3.3233063220977783\n",
      "Training loss at step 96: 3.147918224334717\n",
      "Training loss at step 128: 3.004133462905884\n",
      "Training loss at step 160: 2.895240306854248\n",
      "Training loss at step 192: 2.8289284706115723\n",
      "Training loss at step 224: 2.8058013916015625\n",
      "Training loss at step 256: 2.8408679962158203\n",
      "Training loss at step 288: 3.0164055824279785\n",
      "Training loss at step 320: 3.3917031288146973\n",
      "Training loss at step 352: 3.8893861770629883\n",
      "Training loss at step 384: 4.376471042633057\n",
      "Training loss at step 416: 4.758082389831543\n",
      "Training loss at step 448: 5.04779052734375\n",
      "Training loss at step 480: 5.288073539733887\n",
      "Training loss at step 512: 5.533018112182617\n",
      "Training loss at step 544: 5.812742233276367\n",
      "Training loss at step 576: 6.139131546020508\n",
      "Training loss at step 608: 6.496366500854492\n",
      "Training loss at step 640: 6.891980171203613\n",
      "Training loss at step 672: 7.263598442077637\n",
      "Training loss at step 704: 7.524454593658447\n",
      "Training loss at step 736: 7.597323417663574\n",
      "Training loss at step 768: 7.206965923309326\n",
      "Training loss at step 800: 6.374128341674805\n",
      "Training loss at step 832: 5.501955509185791\n",
      "Training loss at step 864: 4.856472015380859\n",
      "Training loss at step 896: 4.442005157470703\n",
      "Training loss at step 928: 4.182958602905273\n",
      "Training loss at step 960: 3.9684789180755615\n",
      "Training loss at step 992: 3.7975237369537354\n",
      "Training loss at step 1024: 3.6641194820404053\n",
      "Training loss at step 1056: 3.5230250358581543\n",
      "Training loss at step 1088: 3.325333833694458\n",
      "Training loss at step 1120: 3.13310170173645\n",
      "Training loss at step 1152: 2.9807379245758057\n",
      "Training loss at step 1184: 2.878640651702881\n",
      "Training loss at step 1216: 2.8208439350128174\n",
      "Training loss at step 1248: 2.815077066421509\n",
      "Training loss at step 1280: 2.9553468227386475\n",
      "Training loss at step 1312: 3.3303916454315186\n",
      "Training loss at step 1344: 3.854733467102051\n",
      "Training loss at step 1376: 4.337480545043945\n",
      "Training loss at step 1408: 4.738344192504883\n",
      "Training loss at step 1440: 5.097462177276611\n",
      "Training loss at step 1472: 5.369046211242676\n",
      "Training loss at step 1504: 5.60572624206543\n",
      "Training loss at step 1536: 5.85764741897583\n",
      "Training loss at step 1568: 6.1523332595825195\n",
      "Training loss at step 1600: 6.5099077224731445\n",
      "Training loss at step 1632: 6.899990081787109\n",
      "Training loss at step 1664: 7.240002632141113\n",
      "Training loss at step 1696: 7.524697303771973\n",
      "Training loss at step 1728: 7.651863098144531\n",
      "Training loss at step 1760: 7.379133701324463\n",
      "Training loss at step 1792: 6.587603569030762\n",
      "Training loss at step 1824: 5.705807685852051\n",
      "Training loss at step 1856: 4.970824241638184\n",
      "Training loss at step 1888: 4.488372802734375\n",
      "Training loss at step 1920: 4.168135166168213\n",
      "Training loss at step 1952: 3.952730655670166\n",
      "Training loss at step 1984: 3.8287038803100586\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at step 0: 3.9981272220611572\n",
      "Training loss at step 32: 3.559948205947876\n",
      "Training loss at step 64: 3.324155569076538\n",
      "Training loss at step 96: 3.1502249240875244\n",
      "Training loss at step 128: 3.0065739154815674\n",
      "Training loss at step 160: 2.8955142498016357\n",
      "Training loss at step 192: 2.8257787227630615\n",
      "Training loss at step 224: 2.8003077507019043\n",
      "Training loss at step 256: 2.8369505405426025\n",
      "Training loss at step 288: 3.0163071155548096\n",
      "Training loss at step 320: 3.390362024307251\n",
      "Training loss at step 352: 3.8742849826812744\n",
      "Training loss at step 384: 4.347180366516113\n",
      "Training loss at step 416: 4.735374450683594\n",
      "Training loss at step 448: 5.033791542053223\n",
      "Training loss at step 480: 5.279049396514893\n",
      "Training loss at step 512: 5.526730060577393\n",
      "Training loss at step 544: 5.808234214782715\n",
      "Training loss at step 576: 6.145841598510742\n",
      "Training loss at step 608: 6.5233473777771\n",
      "Training loss at step 640: 6.912532806396484\n",
      "Training loss at step 672: 7.276795864105225\n",
      "Training loss at step 704: 7.535323619842529\n",
      "Training loss at step 736: 7.606928825378418\n",
      "Training loss at step 768: 7.204806327819824\n",
      "Training loss at step 800: 6.366786956787109\n",
      "Training loss at step 832: 5.517500400543213\n",
      "Training loss at step 864: 4.889259338378906\n",
      "Training loss at step 896: 4.467659950256348\n",
      "Training loss at step 928: 4.210378170013428\n",
      "Training loss at step 960: 3.9983880519866943\n",
      "Training loss at step 992: 3.823580503463745\n",
      "Training loss at step 1024: 3.6856093406677246\n",
      "Training loss at step 1056: 3.5484187602996826\n",
      "Training loss at step 1088: 3.360447883605957\n",
      "Training loss at step 1120: 3.1651840209960938\n",
      "Training loss at step 1152: 3.0073556900024414\n",
      "Training loss at step 1184: 2.9018208980560303\n",
      "Training loss at step 1216: 2.8400628566741943\n",
      "Training loss at step 1248: 2.8265271186828613\n",
      "Training loss at step 1280: 2.9517245292663574\n",
      "Training loss at step 1312: 3.3125741481781006\n",
      "Training loss at step 1344: 3.8311305046081543\n",
      "Training loss at step 1376: 4.317653179168701\n",
      "Training loss at step 1408: 4.727458953857422\n",
      "Training loss at step 1440: 5.082780838012695\n",
      "Training loss at step 1472: 5.354704856872559\n",
      "Training loss at step 1504: 5.592787742614746\n",
      "Training loss at step 1536: 5.845646858215332\n",
      "Training loss at step 1568: 6.133109092712402\n",
      "Training loss at step 1600: 6.491428375244141\n",
      "Training loss at step 1632: 6.875880241394043\n",
      "Training loss at step 1664: 7.217230319976807\n",
      "Training loss at step 1696: 7.501891613006592\n",
      "Training loss at step 1728: 7.637400150299072\n",
      "Training loss at step 1760: 7.373374938964844\n",
      "Training loss at step 1792: 6.592762470245361\n",
      "Training loss at step 1824: 5.717901229858398\n",
      "Training loss at step 1856: 4.971009254455566\n",
      "Training loss at step 1888: 4.483600616455078\n",
      "Training loss at step 1920: 4.161323547363281\n",
      "Training loss at step 1952: 3.940781831741333\n",
      "Training loss at step 1984: 3.8118114471435547\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at step 0: 3.998011350631714\n",
      "Training loss at step 32: 3.5601696968078613\n",
      "Training loss at step 64: 3.323585033416748\n",
      "Training loss at step 96: 3.1494739055633545\n",
      "Training loss at step 128: 3.006228446960449\n",
      "Training loss at step 160: 2.8954923152923584\n",
      "Training loss at step 192: 2.825453519821167\n",
      "Training loss at step 224: 2.7983570098876953\n",
      "Training loss at step 256: 2.8343513011932373\n",
      "Training loss at step 288: 3.0164637565612793\n",
      "Training loss at step 320: 3.392923355102539\n",
      "Training loss at step 352: 3.8828067779541016\n",
      "Training loss at step 384: 4.366724014282227\n",
      "Training loss at step 416: 4.752751350402832\n",
      "Training loss at step 448: 5.048800468444824\n",
      "Training loss at step 480: 5.290019512176514\n",
      "Training loss at step 512: 5.536978721618652\n",
      "Training loss at step 544: 5.814733982086182\n",
      "Training loss at step 576: 6.13277006149292\n",
      "Training loss at step 608: 6.492648124694824\n",
      "Training loss at step 640: 6.892441272735596\n",
      "Training loss at step 672: 7.265194892883301\n",
      "Training loss at step 704: 7.525572299957275\n",
      "Training loss at step 736: 7.597980976104736\n",
      "Training loss at step 768: 7.209620475769043\n",
      "Training loss at step 800: 6.380471706390381\n",
      "Training loss at step 832: 5.494551658630371\n",
      "Training loss at step 864: 4.81602144241333\n",
      "Training loss at step 896: 4.422341346740723\n",
      "Training loss at step 928: 4.165480613708496\n",
      "Training loss at step 960: 3.956307888031006\n",
      "Training loss at step 992: 3.7813479900360107\n",
      "Training loss at step 1024: 3.6311962604522705\n",
      "Training loss at step 1056: 3.483191967010498\n",
      "Training loss at step 1088: 3.2985804080963135\n",
      "Training loss at step 1120: 3.118187427520752\n",
      "Training loss at step 1152: 2.9725284576416016\n",
      "Training loss at step 1184: 2.8756346702575684\n",
      "Training loss at step 1216: 2.8207361698150635\n",
      "Training loss at step 1248: 2.8166263103485107\n",
      "Training loss at step 1280: 2.953474998474121\n",
      "Training loss at step 1312: 3.3187427520751953\n",
      "Training loss at step 1344: 3.830540180206299\n",
      "Training loss at step 1376: 4.3066911697387695\n",
      "Training loss at step 1408: 4.7114787101745605\n",
      "Training loss at step 1440: 5.074276924133301\n",
      "Training loss at step 1472: 5.35140323638916\n",
      "Training loss at step 1504: 5.594340801239014\n",
      "Training loss at step 1536: 5.859090805053711\n",
      "Training loss at step 1568: 6.163762092590332\n",
      "Training loss at step 1600: 6.523375511169434\n",
      "Training loss at step 1632: 6.933399200439453\n",
      "Training loss at step 1664: 7.288846969604492\n",
      "Training loss at step 1696: 7.543301582336426\n",
      "Training loss at step 1728: 7.654115200042725\n",
      "Training loss at step 1760: 7.3790483474731445\n",
      "Training loss at step 1792: 6.5854620933532715\n",
      "Training loss at step 1824: 5.687917709350586\n",
      "Training loss at step 1856: 4.956597805023193\n",
      "Training loss at step 1888: 4.482908725738525\n",
      "Training loss at step 1920: 4.178321838378906\n",
      "Training loss at step 1952: 3.9844095706939697\n",
      "Training loss at step 1984: 3.8724491596221924\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at step 0: 4.00259256362915\n",
      "Training loss at step 32: 3.56833815574646\n",
      "Training loss at step 64: 3.3293986320495605\n",
      "Training loss at step 96: 3.1507887840270996\n",
      "Training loss at step 128: 3.007075309753418\n",
      "Training loss at step 160: 2.900001287460327\n",
      "Training loss at step 192: 2.8347904682159424\n",
      "Training loss at step 224: 2.8091588020324707\n",
      "Training loss at step 256: 2.839932918548584\n",
      "Training loss at step 288: 3.0163726806640625\n",
      "Training loss at step 320: 3.3993239402770996\n",
      "Training loss at step 352: 3.893463134765625\n",
      "Training loss at step 384: 4.371761322021484\n",
      "Training loss at step 416: 4.756032943725586\n",
      "Training loss at step 448: 5.051701545715332\n",
      "Training loss at step 480: 5.2924933433532715\n",
      "Training loss at step 512: 5.5396528244018555\n",
      "Training loss at step 544: 5.820931434631348\n",
      "Training loss at step 576: 6.155701637268066\n",
      "Training loss at step 608: 6.526966571807861\n",
      "Training loss at step 640: 6.915865421295166\n",
      "Training loss at step 672: 7.278426170349121\n",
      "Training loss at step 704: 7.535674095153809\n",
      "Training loss at step 736: 7.606555461883545\n",
      "Training loss at step 768: 7.204665184020996\n",
      "Training loss at step 800: 6.36850643157959\n",
      "Training loss at step 832: 5.5202555656433105\n",
      "Training loss at step 864: 4.8939971923828125\n",
      "Training loss at step 896: 4.4564714431762695\n",
      "Training loss at step 928: 4.191522598266602\n",
      "Training loss at step 960: 3.978576421737671\n",
      "Training loss at step 992: 3.7983744144439697\n",
      "Training loss at step 1024: 3.655747652053833\n",
      "Training loss at step 1056: 3.519810676574707\n",
      "Training loss at step 1088: 3.3268556594848633\n",
      "Training loss at step 1120: 3.125866174697876\n",
      "Training loss at step 1152: 2.970008134841919\n",
      "Training loss at step 1184: 2.8689117431640625\n",
      "Training loss at step 1216: 2.814032554626465\n",
      "Training loss at step 1248: 2.8123466968536377\n",
      "Training loss at step 1280: 2.957122564315796\n",
      "Training loss at step 1312: 3.330632209777832\n",
      "Training loss at step 1344: 3.8435792922973633\n",
      "Training loss at step 1376: 4.312436580657959\n",
      "Training loss at step 1408: 4.713799953460693\n",
      "Training loss at step 1440: 5.065072536468506\n",
      "Training loss at step 1472: 5.337944030761719\n",
      "Training loss at step 1504: 5.5779266357421875\n",
      "Training loss at step 1536: 5.820417404174805\n",
      "Training loss at step 1568: 6.110336780548096\n",
      "Training loss at step 1600: 6.4612274169921875\n",
      "Training loss at step 1632: 6.821367263793945\n",
      "Training loss at step 1664: 7.19643497467041\n",
      "Training loss at step 1696: 7.494967460632324\n",
      "Training loss at step 1728: 7.634433269500732\n",
      "Training loss at step 1760: 7.371675491333008\n",
      "Training loss at step 1792: 6.5959672927856445\n",
      "Training loss at step 1824: 5.7524871826171875\n",
      "Training loss at step 1856: 5.014427185058594\n",
      "Training loss at step 1888: 4.496292591094971\n",
      "Training loss at step 1920: 4.169094085693359\n",
      "Training loss at step 1952: 3.9470303058624268\n",
      "Training loss at step 1984: 3.82627534866333\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at step 0: 3.9986538887023926\n",
      "Training loss at step 32: 3.5610480308532715\n",
      "Training loss at step 64: 3.3271260261535645\n",
      "Training loss at step 96: 3.154256820678711\n",
      "Training loss at step 128: 3.0097405910491943\n",
      "Training loss at step 160: 2.896679401397705\n",
      "Training loss at step 192: 2.8252973556518555\n",
      "Training loss at step 224: 2.8000800609588623\n",
      "Training loss at step 256: 2.8391363620758057\n",
      "Training loss at step 288: 3.016850233078003\n",
      "Training loss at step 320: 3.384913682937622\n",
      "Training loss at step 352: 3.8700273036956787\n",
      "Training loss at step 384: 4.351016044616699\n",
      "Training loss at step 416: 4.7413153648376465\n",
      "Training loss at step 448: 5.04195499420166\n",
      "Training loss at step 480: 5.287426948547363\n",
      "Training loss at step 512: 5.537703514099121\n",
      "Training loss at step 544: 5.816176414489746\n",
      "Training loss at step 576: 6.139224052429199\n",
      "Training loss at step 608: 6.505782127380371\n",
      "Training loss at step 640: 6.895401954650879\n",
      "Training loss at step 672: 7.263139247894287\n",
      "Training loss at step 704: 7.5246782302856445\n",
      "Training loss at step 736: 7.598523139953613\n",
      "Training loss at step 768: 7.204455375671387\n",
      "Training loss at step 800: 6.368870258331299\n",
      "Training loss at step 832: 5.4954071044921875\n",
      "Training loss at step 864: 4.820213794708252\n",
      "Training loss at step 896: 4.425830841064453\n",
      "Training loss at step 928: 4.174594879150391\n",
      "Training loss at step 960: 3.9662275314331055\n",
      "Training loss at step 992: 3.7965142726898193\n",
      "Training loss at step 1024: 3.668729066848755\n",
      "Training loss at step 1056: 3.535430669784546\n",
      "Training loss at step 1088: 3.34662127494812\n",
      "Training loss at step 1120: 3.151235818862915\n",
      "Training loss at step 1152: 2.9909627437591553\n",
      "Training loss at step 1184: 2.8859450817108154\n",
      "Training loss at step 1216: 2.8256702423095703\n",
      "Training loss at step 1248: 2.817434787750244\n",
      "Training loss at step 1280: 2.953782796859741\n",
      "Training loss at step 1312: 3.323992967605591\n",
      "Training loss at step 1344: 3.840061902999878\n",
      "Training loss at step 1376: 4.31837797164917\n",
      "Training loss at step 1408: 4.728582382202148\n",
      "Training loss at step 1440: 5.096648216247559\n",
      "Training loss at step 1472: 5.37633752822876\n",
      "Training loss at step 1504: 5.618060111999512\n",
      "Training loss at step 1536: 5.866869926452637\n",
      "Training loss at step 1568: 6.15313720703125\n",
      "Training loss at step 1600: 6.510699272155762\n",
      "Training loss at step 1632: 6.900430202484131\n",
      "Training loss at step 1664: 7.244935035705566\n",
      "Training loss at step 1696: 7.533164024353027\n",
      "Training loss at step 1728: 7.653627395629883\n",
      "Training loss at step 1760: 7.378032684326172\n",
      "Training loss at step 1792: 6.588611602783203\n",
      "Training loss at step 1824: 5.7106032371521\n",
      "Training loss at step 1856: 4.973451614379883\n",
      "Training loss at step 1888: 4.487062931060791\n",
      "Training loss at step 1920: 4.166820526123047\n",
      "Training loss at step 1952: 3.9455180168151855\n",
      "Training loss at step 1984: 3.8224587440490723\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at step 0: 3.9987845420837402\n",
      "Training loss at step 32: 3.5610485076904297\n",
      "Training loss at step 64: 3.323173999786377\n",
      "Training loss at step 96: 3.147670269012451\n",
      "Training loss at step 128: 3.0042777061462402\n",
      "Training loss at step 160: 2.894932270050049\n",
      "Training loss at step 192: 2.826615333557129\n",
      "Training loss at step 224: 2.8010427951812744\n",
      "Training loss at step 256: 2.836611270904541\n",
      "Training loss at step 288: 3.01627779006958\n",
      "Training loss at step 320: 3.392055034637451\n",
      "Training loss at step 352: 3.874896764755249\n",
      "Training loss at step 384: 4.343768119812012\n",
      "Training loss at step 416: 4.734951019287109\n",
      "Training loss at step 448: 5.0380072593688965\n",
      "Training loss at step 480: 5.283295154571533\n",
      "Training loss at step 512: 5.531938552856445\n",
      "Training loss at step 544: 5.812864780426025\n",
      "Training loss at step 576: 6.139833450317383\n",
      "Training loss at step 608: 6.500265598297119\n",
      "Training loss at step 640: 6.89351749420166\n",
      "Training loss at step 672: 7.262689590454102\n",
      "Training loss at step 704: 7.52412223815918\n",
      "Training loss at step 736: 7.597938060760498\n",
      "Training loss at step 768: 7.2043986320495605\n",
      "Training loss at step 800: 6.36734676361084\n",
      "Training loss at step 832: 5.497171401977539\n",
      "Training loss at step 864: 4.848804473876953\n",
      "Training loss at step 896: 4.433497428894043\n",
      "Training loss at step 928: 4.17911434173584\n",
      "Training loss at step 960: 3.9676926136016846\n",
      "Training loss at step 992: 3.7916996479034424\n",
      "Training loss at step 1024: 3.640671730041504\n",
      "Training loss at step 1056: 3.4914028644561768\n",
      "Training loss at step 1088: 3.3126232624053955\n",
      "Training loss at step 1120: 3.1252148151397705\n",
      "Training loss at step 1152: 2.975254535675049\n",
      "Training loss at step 1184: 2.8751845359802246\n",
      "Training loss at step 1216: 2.819561004638672\n",
      "Training loss at step 1248: 2.8151931762695312\n",
      "Training loss at step 1280: 2.9547338485717773\n",
      "Training loss at step 1312: 3.3192169666290283\n",
      "Training loss at step 1344: 3.822233200073242\n",
      "Training loss at step 1376: 4.288910865783691\n",
      "Training loss at step 1408: 4.691715717315674\n",
      "Training loss at step 1440: 5.051687240600586\n",
      "Training loss at step 1472: 5.332535743713379\n",
      "Training loss at step 1504: 5.581386089324951\n",
      "Training loss at step 1536: 5.848608493804932\n",
      "Training loss at step 1568: 6.147160530090332\n",
      "Training loss at step 1600: 6.507280349731445\n",
      "Training loss at step 1632: 6.906200408935547\n",
      "Training loss at step 1664: 7.2341508865356445\n",
      "Training loss at step 1696: 7.497527599334717\n",
      "Training loss at step 1728: 7.632760047912598\n",
      "Training loss at step 1760: 7.370417594909668\n",
      "Training loss at step 1792: 6.590301513671875\n",
      "Training loss at step 1824: 5.694244384765625\n",
      "Training loss at step 1856: 4.950109958648682\n",
      "Training loss at step 1888: 4.470808506011963\n",
      "Training loss at step 1920: 4.162588119506836\n",
      "Training loss at step 1952: 3.9692435264587402\n",
      "Training loss at step 1984: 3.8601903915405273\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at step 0: 3.9985408782958984\n",
      "Training loss at step 32: 3.560681104660034\n",
      "Training loss at step 64: 3.3232946395874023\n",
      "Training loss at step 96: 3.147832155227661\n",
      "Training loss at step 128: 3.0042965412139893\n",
      "Training loss at step 160: 2.8949499130249023\n",
      "Training loss at step 192: 2.8275160789489746\n",
      "Training loss at step 224: 2.80320143699646\n",
      "Training loss at step 256: 2.839151382446289\n",
      "Training loss at step 288: 3.0163021087646484\n",
      "Training loss at step 320: 3.3897454738616943\n",
      "Training loss at step 352: 3.880099296569824\n",
      "Training loss at step 384: 4.362622261047363\n",
      "Training loss at step 416: 4.75065803527832\n",
      "Training loss at step 448: 5.051762580871582\n",
      "Training loss at step 480: 5.295605182647705\n",
      "Training loss at step 512: 5.544914245605469\n",
      "Training loss at step 544: 5.82465124130249\n",
      "Training loss at step 576: 6.146632194519043\n",
      "Training loss at step 608: 6.506648063659668\n",
      "Training loss at step 640: 6.894596099853516\n",
      "Training loss at step 672: 7.2627105712890625\n",
      "Training loss at step 704: 7.523987293243408\n",
      "Training loss at step 736: 7.597604751586914\n",
      "Training loss at step 768: 7.204820156097412\n",
      "Training loss at step 800: 6.368046760559082\n",
      "Training loss at step 832: 5.485910415649414\n",
      "Training loss at step 864: 4.81620454788208\n",
      "Training loss at step 896: 4.4184346199035645\n",
      "Training loss at step 928: 4.164965629577637\n",
      "Training loss at step 960: 3.95361065864563\n",
      "Training loss at step 992: 3.7796332836151123\n",
      "Training loss at step 1024: 3.646873950958252\n",
      "Training loss at step 1056: 3.5189883708953857\n",
      "Training loss at step 1088: 3.332581043243408\n",
      "Training loss at step 1120: 3.1320059299468994\n",
      "Training loss at step 1152: 2.974696397781372\n",
      "Training loss at step 1184: 2.8715829849243164\n",
      "Training loss at step 1216: 2.81497859954834\n",
      "Training loss at step 1248: 2.812220573425293\n",
      "Training loss at step 1280: 2.957105875015259\n",
      "Training loss at step 1312: 3.3315062522888184\n",
      "Training loss at step 1344: 3.8436875343322754\n",
      "Training loss at step 1376: 4.311356544494629\n",
      "Training loss at step 1408: 4.718895435333252\n",
      "Training loss at step 1440: 5.072629451751709\n",
      "Training loss at step 1472: 5.348740100860596\n",
      "Training loss at step 1504: 5.595803260803223\n",
      "Training loss at step 1536: 5.84676456451416\n",
      "Training loss at step 1568: 6.131865501403809\n",
      "Training loss at step 1600: 6.487244129180908\n",
      "Training loss at step 1632: 6.845982074737549\n",
      "Training loss at step 1664: 7.1991376876831055\n",
      "Training loss at step 1696: 7.497862815856934\n",
      "Training loss at step 1728: 7.629162788391113\n",
      "Training loss at step 1760: 7.367325782775879\n",
      "Training loss at step 1792: 6.595881462097168\n",
      "Training loss at step 1824: 5.731884002685547\n",
      "Training loss at step 1856: 4.976130485534668\n",
      "Training loss at step 1888: 4.475583076477051\n",
      "Training loss at step 1920: 4.154425144195557\n",
      "Training loss at step 1952: 3.94523024559021\n",
      "Training loss at step 1984: 3.827556610107422\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at step 0: 3.9975357055664062\n",
      "Training loss at step 32: 3.5599894523620605\n",
      "Training loss at step 64: 3.3233325481414795\n",
      "Training loss at step 96: 3.148615837097168\n",
      "Training loss at step 128: 3.005079984664917\n",
      "Training loss at step 160: 2.8950345516204834\n",
      "Training loss at step 192: 2.82637882232666\n",
      "Training loss at step 224: 2.800710678100586\n",
      "Training loss at step 256: 2.837770462036133\n",
      "Training loss at step 288: 3.0162875652313232\n",
      "Training loss at step 320: 3.3871848583221436\n",
      "Training loss at step 352: 3.869811773300171\n",
      "Training loss at step 384: 4.348243713378906\n",
      "Training loss at step 416: 4.740140438079834\n",
      "Training loss at step 448: 5.044337272644043\n",
      "Training loss at step 480: 5.2909088134765625\n",
      "Training loss at step 512: 5.541508674621582\n",
      "Training loss at step 544: 5.824253082275391\n",
      "Training loss at step 576: 6.1532487869262695\n",
      "Training loss at step 608: 6.524687767028809\n",
      "Training loss at step 640: 6.905276298522949\n",
      "Training loss at step 672: 7.267668724060059\n",
      "Training loss at step 704: 7.527171611785889\n",
      "Training loss at step 736: 7.600540637969971\n",
      "Training loss at step 768: 7.203789710998535\n",
      "Training loss at step 800: 6.3639726638793945\n",
      "Training loss at step 832: 5.4868316650390625\n",
      "Training loss at step 864: 4.822500705718994\n",
      "Training loss at step 896: 4.426302909851074\n",
      "Training loss at step 928: 4.172265529632568\n",
      "Training loss at step 960: 3.9618892669677734\n",
      "Training loss at step 992: 3.790907621383667\n",
      "Training loss at step 1024: 3.664450168609619\n",
      "Training loss at step 1056: 3.536457061767578\n",
      "Training loss at step 1088: 3.3511650562286377\n",
      "Training loss at step 1120: 3.1504807472229004\n",
      "Training loss at step 1152: 2.986384630203247\n",
      "Training loss at step 1184: 2.87947940826416\n",
      "Training loss at step 1216: 2.8201370239257812\n",
      "Training loss at step 1248: 2.8146474361419678\n",
      "Training loss at step 1280: 2.954958438873291\n",
      "Training loss at step 1312: 3.325239896774292\n",
      "Training loss at step 1344: 3.8348050117492676\n",
      "Training loss at step 1376: 4.307579040527344\n",
      "Training loss at step 1408: 4.716701984405518\n",
      "Training loss at step 1440: 5.078454971313477\n",
      "Training loss at step 1472: 5.361519813537598\n",
      "Training loss at step 1504: 5.608510494232178\n",
      "Training loss at step 1536: 5.860892295837402\n",
      "Training loss at step 1568: 6.146407127380371\n",
      "Training loss at step 1600: 6.504958629608154\n",
      "Training loss at step 1632: 6.88503360748291\n",
      "Training loss at step 1664: 7.213757514953613\n",
      "Training loss at step 1696: 7.50338077545166\n",
      "Training loss at step 1728: 7.630744457244873\n",
      "Training loss at step 1760: 7.367136478424072\n",
      "Training loss at step 1792: 6.595345973968506\n",
      "Training loss at step 1824: 5.721559524536133\n",
      "Training loss at step 1856: 4.967097282409668\n",
      "Training loss at step 1888: 4.476602554321289\n",
      "Training loss at step 1920: 4.155498504638672\n",
      "Training loss at step 1952: 3.937929153442383\n",
      "Training loss at step 1984: 3.818718433380127\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at step 0: 3.9979636669158936\n",
      "Training loss at step 32: 3.560115337371826\n",
      "Training loss at step 64: 3.323728561401367\n",
      "Training loss at step 96: 3.14983868598938\n",
      "Training loss at step 128: 3.0064353942871094\n",
      "Training loss at step 160: 2.8954758644104004\n",
      "Training loss at step 192: 2.825479030609131\n",
      "Training loss at step 224: 2.798720598220825\n",
      "Training loss at step 256: 2.835777521133423\n",
      "Training loss at step 288: 3.016279697418213\n",
      "Training loss at step 320: 3.3886468410491943\n",
      "Training loss at step 352: 3.8674044609069824\n",
      "Training loss at step 384: 4.336201190948486\n",
      "Training loss at step 416: 4.7302398681640625\n",
      "Training loss at step 448: 5.036381244659424\n",
      "Training loss at step 480: 5.284689426422119\n",
      "Training loss at step 512: 5.5358734130859375\n",
      "Training loss at step 544: 5.811140060424805\n",
      "Training loss at step 576: 6.126826286315918\n",
      "Training loss at step 608: 6.489249229431152\n",
      "Training loss at step 640: 6.893667697906494\n",
      "Training loss at step 672: 7.2665605545043945\n",
      "Training loss at step 704: 7.526293754577637\n",
      "Training loss at step 736: 7.59802770614624\n",
      "Training loss at step 768: 7.206843852996826\n",
      "Training loss at step 800: 6.367336273193359\n",
      "Training loss at step 832: 5.476490497589111\n",
      "Training loss at step 864: 4.805648326873779\n",
      "Training loss at step 896: 4.411987781524658\n",
      "Training loss at step 928: 4.15747594833374\n",
      "Training loss at step 960: 3.9473676681518555\n",
      "Training loss at step 992: 3.7732927799224854\n",
      "Training loss at step 1024: 3.6239402294158936\n",
      "Training loss at step 1056: 3.4758434295654297\n",
      "Training loss at step 1088: 3.3027920722961426\n",
      "Training loss at step 1120: 3.11967134475708\n",
      "Training loss at step 1152: 2.969481945037842\n",
      "Training loss at step 1184: 2.8699803352355957\n",
      "Training loss at step 1216: 2.81575608253479\n",
      "Training loss at step 1248: 2.8134043216705322\n",
      "Training loss at step 1280: 2.954119920730591\n",
      "Training loss at step 1312: 3.3152198791503906\n",
      "Training loss at step 1344: 3.8118324279785156\n",
      "Training loss at step 1376: 4.275933265686035\n",
      "Training loss at step 1408: 4.687830924987793\n",
      "Training loss at step 1440: 5.055230140686035\n",
      "Training loss at step 1472: 5.342118263244629\n",
      "Training loss at step 1504: 5.595161437988281\n",
      "Training loss at step 1536: 5.860886573791504\n",
      "Training loss at step 1568: 6.162087440490723\n",
      "Training loss at step 1600: 6.524565696716309\n",
      "Training loss at step 1632: 6.933182716369629\n",
      "Training loss at step 1664: 7.268418788909912\n",
      "Training loss at step 1696: 7.525740146636963\n",
      "Training loss at step 1728: 7.6439619064331055\n",
      "Training loss at step 1760: 7.373769760131836\n",
      "Training loss at step 1792: 6.586477756500244\n",
      "Training loss at step 1824: 5.693807125091553\n",
      "Training loss at step 1856: 4.9523210525512695\n",
      "Training loss at step 1888: 4.473687171936035\n",
      "Training loss at step 1920: 4.168217182159424\n",
      "Training loss at step 1952: 3.980752944946289\n",
      "Training loss at step 1984: 3.873685598373413\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at step 0: 3.9991872310638428\n",
      "Training loss at step 32: 3.5627503395080566\n",
      "Training loss at step 64: 3.3248801231384277\n",
      "Training loss at step 96: 3.14784836769104\n",
      "Training loss at step 128: 3.0044310092926025\n",
      "Training loss at step 160: 2.8967132568359375\n",
      "Training loss at step 192: 2.830303430557251\n",
      "Training loss at step 224: 2.8050153255462646\n",
      "Training loss at step 256: 2.8394510746002197\n",
      "Training loss at step 288: 3.0161259174346924\n",
      "Training loss at step 320: 3.3911595344543457\n",
      "Training loss at step 352: 3.8791613578796387\n",
      "Training loss at step 384: 4.358297348022461\n",
      "Training loss at step 416: 4.745546340942383\n",
      "Training loss at step 448: 5.049099922180176\n",
      "Training loss at step 480: 5.294940948486328\n",
      "Training loss at step 512: 5.545644760131836\n",
      "Training loss at step 544: 5.827611923217773\n",
      "Training loss at step 576: 6.156789302825928\n",
      "Training loss at step 608: 6.519729137420654\n",
      "Training loss at step 640: 6.902329444885254\n",
      "Training loss at step 672: 7.266826629638672\n",
      "Training loss at step 704: 7.526761054992676\n",
      "Training loss at step 736: 7.600248336791992\n",
      "Training loss at step 768: 7.20379638671875\n",
      "Training loss at step 800: 6.363733768463135\n",
      "Training loss at step 832: 5.493674278259277\n",
      "Training loss at step 864: 4.841160774230957\n",
      "Training loss at step 896: 4.421347618103027\n",
      "Training loss at step 928: 4.169625282287598\n",
      "Training loss at step 960: 3.9634780883789062\n",
      "Training loss at step 992: 3.784489154815674\n",
      "Training loss at step 1024: 3.6451218128204346\n",
      "Training loss at step 1056: 3.5239827632904053\n",
      "Training loss at step 1088: 3.338806390762329\n",
      "Training loss at step 1120: 3.130044460296631\n",
      "Training loss at step 1152: 2.9689838886260986\n",
      "Training loss at step 1184: 2.8658194541931152\n",
      "Training loss at step 1216: 2.810687780380249\n",
      "Training loss at step 1248: 2.8105428218841553\n",
      "Training loss at step 1280: 2.9589641094207764\n",
      "Training loss at step 1312: 3.331925868988037\n",
      "Training loss at step 1344: 3.8333020210266113\n",
      "Training loss at step 1376: 4.289438724517822\n",
      "Training loss at step 1408: 4.6963605880737305\n",
      "Training loss at step 1440: 5.050081253051758\n",
      "Training loss at step 1472: 5.332092761993408\n",
      "Training loss at step 1504: 5.583664417266846\n",
      "Training loss at step 1536: 5.827533721923828\n",
      "Training loss at step 1568: 6.116242408752441\n",
      "Training loss at step 1600: 6.456164360046387\n",
      "Training loss at step 1632: 6.8107991218566895\n",
      "Training loss at step 1664: 7.184521675109863\n",
      "Training loss at step 1696: 7.48383092880249\n",
      "Training loss at step 1728: 7.622119426727295\n",
      "Training loss at step 1760: 7.364645957946777\n",
      "Training loss at step 1792: 6.6049041748046875\n",
      "Training loss at step 1824: 5.772584438323975\n",
      "Training loss at step 1856: 5.0293402671813965\n",
      "Training loss at step 1888: 4.475808143615723\n",
      "Training loss at step 1920: 4.144760608673096\n",
      "Training loss at step 1952: 3.9335219860076904\n",
      "Training loss at step 1984: 3.822636842727661\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at step 0: 3.997978687286377\n",
      "Training loss at step 32: 3.5616488456726074\n",
      "Training loss at step 64: 3.327956199645996\n",
      "Training loss at step 96: 3.1561245918273926\n",
      "Training loss at step 128: 3.0117897987365723\n",
      "Training loss at step 160: 2.8976643085479736\n",
      "Training loss at step 192: 2.825150966644287\n",
      "Training loss at step 224: 2.798724889755249\n",
      "Training loss at step 256: 2.838887929916382\n",
      "Training loss at step 288: 3.0173263549804688\n",
      "Training loss at step 320: 3.3816332817077637\n",
      "Training loss at step 352: 3.8641040325164795\n",
      "Training loss at step 384: 4.34335470199585\n",
      "Training loss at step 416: 4.737591743469238\n",
      "Training loss at step 448: 5.0443315505981445\n",
      "Training loss at step 480: 5.294172763824463\n",
      "Training loss at step 512: 5.548929691314697\n",
      "Training loss at step 544: 5.822432518005371\n",
      "Training loss at step 576: 6.139300346374512\n",
      "Training loss at step 608: 6.508993148803711\n",
      "Training loss at step 640: 6.89605712890625\n",
      "Training loss at step 672: 7.262969017028809\n",
      "Training loss at step 704: 7.52419376373291\n",
      "Training loss at step 736: 7.597900867462158\n",
      "Training loss at step 768: 7.204560279846191\n",
      "Training loss at step 800: 6.364018440246582\n",
      "Training loss at step 832: 5.474363327026367\n",
      "Training loss at step 864: 4.796462535858154\n",
      "Training loss at step 896: 4.399095058441162\n",
      "Training loss at step 928: 4.149520397186279\n",
      "Training loss at step 960: 3.9443235397338867\n",
      "Training loss at step 992: 3.77888822555542\n",
      "Training loss at step 1024: 3.662153482437134\n",
      "Training loss at step 1056: 3.5419623851776123\n",
      "Training loss at step 1088: 3.3589882850646973\n",
      "Training loss at step 1120: 3.154592275619507\n",
      "Training loss at step 1152: 2.987401247024536\n",
      "Training loss at step 1184: 2.8780267238616943\n",
      "Training loss at step 1216: 2.8177895545959473\n",
      "Training loss at step 1248: 2.8133559226989746\n",
      "Training loss at step 1280: 2.955656051635742\n",
      "Training loss at step 1312: 3.3259849548339844\n",
      "Training loss at step 1344: 3.832963705062866\n",
      "Training loss at step 1376: 4.302883148193359\n",
      "Training loss at step 1408: 4.718753814697266\n",
      "Training loss at step 1440: 5.093594074249268\n",
      "Training loss at step 1472: 5.383009910583496\n",
      "Training loss at step 1504: 5.633566856384277\n",
      "Training loss at step 1536: 5.879733085632324\n",
      "Training loss at step 1568: 6.163536071777344\n",
      "Training loss at step 1600: 6.515376091003418\n",
      "Training loss at step 1632: 6.883665084838867\n",
      "Training loss at step 1664: 7.230291366577148\n",
      "Training loss at step 1696: 7.519189834594727\n",
      "Training loss at step 1728: 7.645946502685547\n",
      "Training loss at step 1760: 7.3735809326171875\n",
      "Training loss at step 1792: 6.590416431427002\n",
      "Training loss at step 1824: 5.726834297180176\n",
      "Training loss at step 1856: 4.985501289367676\n",
      "Training loss at step 1888: 4.475832939147949\n",
      "Training loss at step 1920: 4.152217864990234\n",
      "Training loss at step 1952: 3.9317991733551025\n",
      "Training loss at step 1984: 3.8142571449279785\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at step 0: 4.001570224761963\n",
      "Training loss at step 32: 3.563352108001709\n",
      "Training loss at step 64: 3.3241477012634277\n",
      "Training loss at step 96: 3.1475627422332764\n",
      "Training loss at step 128: 3.0042951107025146\n",
      "Training loss at step 160: 2.8954007625579834\n",
      "Training loss at step 192: 2.8267619609832764\n",
      "Training loss at step 224: 2.798901319503784\n",
      "Training loss at step 256: 2.8335559368133545\n",
      "Training loss at step 288: 3.0164852142333984\n",
      "Training loss at step 320: 3.393026828765869\n",
      "Training loss at step 352: 3.870717763900757\n",
      "Training loss at step 384: 4.330916404724121\n",
      "Training loss at step 416: 4.723118782043457\n",
      "Training loss at step 448: 5.033382892608643\n",
      "Training loss at step 480: 5.287284851074219\n",
      "Training loss at step 512: 5.538710594177246\n",
      "Training loss at step 544: 5.812505722045898\n",
      "Training loss at step 576: 6.130063533782959\n",
      "Training loss at step 608: 6.491778373718262\n",
      "Training loss at step 640: 6.89194917678833\n",
      "Training loss at step 672: 7.263379096984863\n",
      "Training loss at step 704: 7.5240373611450195\n",
      "Training loss at step 736: 7.597438812255859\n",
      "Training loss at step 768: 7.20445442199707\n",
      "Training loss at step 800: 6.363542556762695\n",
      "Training loss at step 832: 5.477968215942383\n",
      "Training loss at step 864: 4.80923318862915\n",
      "Training loss at step 896: 4.407470226287842\n",
      "Training loss at step 928: 4.154674053192139\n",
      "Training loss at step 960: 3.943646192550659\n",
      "Training loss at step 992: 3.7672510147094727\n",
      "Training loss at step 1024: 3.617976188659668\n",
      "Training loss at step 1056: 3.469353675842285\n",
      "Training loss at step 1088: 3.300900936126709\n",
      "Training loss at step 1120: 3.112989902496338\n",
      "Training loss at step 1152: 2.9613161087036133\n",
      "Training loss at step 1184: 2.8608686923980713\n",
      "Training loss at step 1216: 2.809307098388672\n",
      "Training loss at step 1248: 2.810978412628174\n",
      "Training loss at step 1280: 2.9556477069854736\n",
      "Training loss at step 1312: 3.315338134765625\n",
      "Training loss at step 1344: 3.8035635948181152\n",
      "Training loss at step 1376: 4.260232448577881\n",
      "Training loss at step 1408: 4.671909809112549\n",
      "Training loss at step 1440: 5.039126873016357\n",
      "Training loss at step 1472: 5.3298845291137695\n",
      "Training loss at step 1504: 5.587045192718506\n",
      "Training loss at step 1536: 5.856060981750488\n",
      "Training loss at step 1568: 6.154421806335449\n",
      "Training loss at step 1600: 6.515824317932129\n",
      "Training loss at step 1632: 6.89773416519165\n",
      "Training loss at step 1664: 7.2156195640563965\n",
      "Training loss at step 1696: 7.4977569580078125\n",
      "Training loss at step 1728: 7.629782676696777\n",
      "Training loss at step 1760: 7.367469310760498\n",
      "Training loss at step 1792: 6.59027099609375\n",
      "Training loss at step 1824: 5.7038960456848145\n",
      "Training loss at step 1856: 4.954734802246094\n",
      "Training loss at step 1888: 4.470070838928223\n",
      "Training loss at step 1920: 4.167724132537842\n",
      "Training loss at step 1952: 3.9795260429382324\n",
      "Training loss at step 1984: 3.876512050628662\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at step 0: 3.998859167098999\n",
      "Training loss at step 32: 3.5614850521087646\n",
      "Training loss at step 64: 3.3238112926483154\n",
      "Training loss at step 96: 3.1473705768585205\n",
      "Training loss at step 128: 3.0039281845092773\n",
      "Training loss at step 160: 2.8955459594726562\n",
      "Training loss at step 192: 2.8285131454467773\n",
      "Training loss at step 224: 2.803325891494751\n",
      "Training loss at step 256: 2.838632106781006\n",
      "Training loss at step 288: 3.0161445140838623\n",
      "Training loss at step 320: 3.3892226219177246\n",
      "Training loss at step 352: 3.8787567615509033\n",
      "Training loss at step 384: 4.360191345214844\n",
      "Training loss at step 416: 4.7501068115234375\n",
      "Training loss at step 448: 5.0561747550964355\n",
      "Training loss at step 480: 5.303747177124023\n",
      "Training loss at step 512: 5.554919242858887\n",
      "Training loss at step 544: 5.835829734802246\n",
      "Training loss at step 576: 6.162111282348633\n",
      "Training loss at step 608: 6.532853126525879\n",
      "Training loss at step 640: 6.9113969802856445\n",
      "Training loss at step 672: 7.272572994232178\n",
      "Training loss at step 704: 7.530550003051758\n",
      "Training loss at step 736: 7.602993488311768\n",
      "Training loss at step 768: 7.203925132751465\n",
      "Training loss at step 800: 6.359677791595459\n",
      "Training loss at step 832: 5.486851215362549\n",
      "Training loss at step 864: 4.818173408508301\n",
      "Training loss at step 896: 4.4091901779174805\n",
      "Training loss at step 928: 4.1587700843811035\n",
      "Training loss at step 960: 3.947328805923462\n",
      "Training loss at step 992: 3.7689545154571533\n",
      "Training loss at step 1024: 3.637403726577759\n",
      "Training loss at step 1056: 3.520113945007324\n",
      "Training loss at step 1088: 3.3373520374298096\n",
      "Training loss at step 1120: 3.1281251907348633\n",
      "Training loss at step 1152: 2.965627908706665\n",
      "Training loss at step 1184: 2.8609840869903564\n",
      "Training loss at step 1216: 2.8080997467041016\n",
      "Training loss at step 1248: 2.8097996711730957\n",
      "Training loss at step 1280: 2.960437536239624\n",
      "Training loss at step 1312: 3.3354640007019043\n",
      "Training loss at step 1344: 3.8366446495056152\n",
      "Training loss at step 1376: 4.289873123168945\n",
      "Training loss at step 1408: 4.699560642242432\n",
      "Training loss at step 1440: 5.048975467681885\n",
      "Training loss at step 1472: 5.328679084777832\n",
      "Training loss at step 1504: 5.577937126159668\n",
      "Training loss at step 1536: 5.824300765991211\n",
      "Training loss at step 1568: 6.116684913635254\n",
      "Training loss at step 1600: 6.467196941375732\n",
      "Training loss at step 1632: 6.809864044189453\n",
      "Training loss at step 1664: 7.1829986572265625\n",
      "Training loss at step 1696: 7.4815287590026855\n",
      "Training loss at step 1728: 7.618600368499756\n",
      "Training loss at step 1760: 7.363076686859131\n",
      "Training loss at step 1792: 6.606935501098633\n",
      "Training loss at step 1824: 5.755079746246338\n",
      "Training loss at step 1856: 4.981427192687988\n",
      "Training loss at step 1888: 4.468491554260254\n",
      "Training loss at step 1920: 4.1495513916015625\n",
      "Training loss at step 1952: 3.9476161003112793\n",
      "Training loss at step 1984: 3.835934638977051\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at step 0: 3.9971299171447754\n",
      "Training loss at step 32: 3.5604841709136963\n",
      "Training loss at step 64: 3.326195001602173\n",
      "Training loss at step 96: 3.1536028385162354\n",
      "Training loss at step 128: 3.009711980819702\n",
      "Training loss at step 160: 2.896747589111328\n",
      "Training loss at step 192: 2.8252439498901367\n",
      "Training loss at step 224: 2.7988932132720947\n",
      "Training loss at step 256: 2.837721109390259\n",
      "Training loss at step 288: 3.0168864727020264\n",
      "Training loss at step 320: 3.382723569869995\n",
      "Training loss at step 352: 3.8585057258605957\n",
      "Training loss at step 384: 4.330854415893555\n",
      "Training loss at step 416: 4.7268524169921875\n",
      "Training loss at step 448: 5.0384840965271\n",
      "Training loss at step 480: 5.294396877288818\n",
      "Training loss at step 512: 5.546099662780762\n",
      "Training loss at step 544: 5.803839683532715\n",
      "Training loss at step 576: 6.118892669677734\n",
      "Training loss at step 608: 6.487226486206055\n",
      "Training loss at step 640: 6.898970127105713\n",
      "Training loss at step 672: 7.271717071533203\n",
      "Training loss at step 704: 7.529061317443848\n",
      "Training loss at step 736: 7.598825454711914\n",
      "Training loss at step 768: 7.208003044128418\n",
      "Training loss at step 800: 6.366445541381836\n",
      "Training loss at step 832: 5.466958045959473\n",
      "Training loss at step 864: 4.783707618713379\n",
      "Training loss at step 896: 4.3769731521606445\n",
      "Training loss at step 928: 4.11870002746582\n",
      "Training loss at step 960: 3.908478021621704\n",
      "Training loss at step 992: 3.7362709045410156\n",
      "Training loss at step 1024: 3.6003012657165527\n",
      "Training loss at step 1056: 3.4805572032928467\n",
      "Training loss at step 1088: 3.3053290843963623\n",
      "Training loss at step 1120: 3.109623908996582\n",
      "Training loss at step 1152: 2.9542508125305176\n",
      "Training loss at step 1184: 2.8557395935058594\n",
      "Training loss at step 1216: 2.805952787399292\n",
      "Training loss at step 1248: 2.809443235397339\n",
      "Training loss at step 1280: 2.9581587314605713\n",
      "Training loss at step 1312: 3.3248579502105713\n",
      "Training loss at step 1344: 3.819072961807251\n",
      "Training loss at step 1376: 4.279277324676514\n",
      "Training loss at step 1408: 4.699002265930176\n",
      "Training loss at step 1440: 5.057604789733887\n",
      "Training loss at step 1472: 5.3526458740234375\n",
      "Training loss at step 1504: 5.6136794090271\n",
      "Training loss at step 1536: 5.883418083190918\n",
      "Training loss at step 1568: 6.182636737823486\n",
      "Training loss at step 1600: 6.545221328735352\n",
      "Training loss at step 1632: 6.952258110046387\n",
      "Training loss at step 1664: 7.285934925079346\n",
      "Training loss at step 1696: 7.5375189781188965\n",
      "Training loss at step 1728: 7.648764133453369\n",
      "Training loss at step 1760: 7.3748931884765625\n",
      "Training loss at step 1792: 6.585960388183594\n",
      "Training loss at step 1824: 5.6908745765686035\n",
      "Training loss at step 1856: 4.951405048370361\n",
      "Training loss at step 1888: 4.469743728637695\n",
      "Training loss at step 1920: 4.162469863891602\n",
      "Training loss at step 1952: 3.9697864055633545\n",
      "Training loss at step 1984: 3.8695337772369385\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at step 0: 4.00147008895874\n",
      "Training loss at step 32: 3.565061569213867\n",
      "Training loss at step 64: 3.3266355991363525\n",
      "Training loss at step 96: 3.1491434574127197\n",
      "Training loss at step 128: 3.005338430404663\n",
      "Training loss at step 160: 2.8978114128112793\n",
      "Training loss at step 192: 2.8315069675445557\n",
      "Training loss at step 224: 2.8054707050323486\n",
      "Training loss at step 256: 2.838296413421631\n",
      "Training loss at step 288: 3.0160348415374756\n",
      "Training loss at step 320: 3.3919994831085205\n",
      "Training loss at step 352: 3.8717193603515625\n",
      "Training loss at step 384: 4.3252949714660645\n",
      "Training loss at step 416: 4.718554496765137\n",
      "Training loss at step 448: 5.03108549118042\n",
      "Training loss at step 480: 5.288268089294434\n",
      "Training loss at step 512: 5.544010162353516\n",
      "Training loss at step 544: 5.823263168334961\n",
      "Training loss at step 576: 6.146389007568359\n",
      "Training loss at step 608: 6.516968727111816\n",
      "Training loss at step 640: 6.904970169067383\n",
      "Training loss at step 672: 7.26962947845459\n",
      "Training loss at step 704: 7.5294880867004395\n",
      "Training loss at step 736: 7.603355407714844\n",
      "Training loss at step 768: 7.204276084899902\n",
      "Training loss at step 800: 6.358612060546875\n",
      "Training loss at step 832: 5.4773359298706055\n",
      "Training loss at step 864: 4.809544086456299\n",
      "Training loss at step 896: 4.409493923187256\n",
      "Training loss at step 928: 4.164421081542969\n",
      "Training loss at step 960: 3.9617760181427\n",
      "Training loss at step 992: 3.781710624694824\n",
      "Training loss at step 1024: 3.6333136558532715\n",
      "Training loss at step 1056: 3.494553804397583\n",
      "Training loss at step 1088: 3.3209879398345947\n",
      "Training loss at step 1120: 3.11971378326416\n",
      "Training loss at step 1152: 2.964293956756592\n",
      "Training loss at step 1184: 2.8639864921569824\n",
      "Training loss at step 1216: 2.813283920288086\n",
      "Training loss at step 1248: 2.8141086101531982\n",
      "Training loss at step 1280: 2.952789306640625\n",
      "Training loss at step 1312: 3.3062257766723633\n",
      "Training loss at step 1344: 3.7898354530334473\n",
      "Training loss at step 1376: 4.243809700012207\n",
      "Training loss at step 1408: 4.651459693908691\n",
      "Training loss at step 1440: 5.009841442108154\n",
      "Training loss at step 1472: 5.304788589477539\n",
      "Training loss at step 1504: 5.569555759429932\n",
      "Training loss at step 1536: 5.831275463104248\n",
      "Training loss at step 1568: 6.121387481689453\n",
      "Training loss at step 1600: 6.458518028259277\n",
      "Training loss at step 1632: 6.803462982177734\n",
      "Training loss at step 1664: 7.182114601135254\n",
      "Training loss at step 1696: 7.481089115142822\n",
      "Training loss at step 1728: 7.618460178375244\n",
      "Training loss at step 1760: 7.3630475997924805\n",
      "Training loss at step 1792: 6.606379508972168\n",
      "Training loss at step 1824: 5.762224197387695\n",
      "Training loss at step 1856: 4.985540390014648\n",
      "Training loss at step 1888: 4.4519805908203125\n",
      "Training loss at step 1920: 4.131929874420166\n",
      "Training loss at step 1952: 3.94240665435791\n",
      "Training loss at step 1984: 3.8384039402008057\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at step 0: 3.999824047088623\n",
      "Training loss at step 32: 3.568222999572754\n",
      "Training loss at step 64: 3.3421642780303955\n",
      "Training loss at step 96: 3.1730880737304688\n",
      "Training loss at step 128: 3.025164842605591\n",
      "Training loss at step 160: 2.902194023132324\n",
      "Training loss at step 192: 2.825971841812134\n",
      "Training loss at step 224: 2.8071627616882324\n",
      "Training loss at step 256: 2.8559653759002686\n",
      "Training loss at step 288: 3.0270535945892334\n",
      "Training loss at step 320: 3.3781375885009766\n",
      "Training loss at step 352: 3.859487295150757\n",
      "Training loss at step 384: 4.336421966552734\n",
      "Training loss at step 416: 4.728161811828613\n",
      "Training loss at step 448: 5.041254043579102\n",
      "Training loss at step 480: 5.3017778396606445\n",
      "Training loss at step 512: 5.550957202911377\n",
      "Training loss at step 544: 5.808090686798096\n",
      "Training loss at step 576: 6.12302303314209\n",
      "Training loss at step 608: 6.4889068603515625\n",
      "Training loss at step 640: 6.893563747406006\n",
      "Training loss at step 672: 7.2661967277526855\n",
      "Training loss at step 704: 7.525371551513672\n",
      "Training loss at step 736: 7.597322463989258\n",
      "Training loss at step 768: 7.204805374145508\n",
      "Training loss at step 800: 6.36159610748291\n",
      "Training loss at step 832: 5.464853286743164\n",
      "Training loss at step 864: 4.778913497924805\n",
      "Training loss at step 896: 4.359098434448242\n",
      "Training loss at step 928: 4.098672389984131\n",
      "Training loss at step 960: 3.888777494430542\n",
      "Training loss at step 992: 3.7166991233825684\n",
      "Training loss at step 1024: 3.589428186416626\n",
      "Training loss at step 1056: 3.4711668491363525\n",
      "Training loss at step 1088: 3.286510705947876\n",
      "Training loss at step 1120: 3.087460994720459\n",
      "Training loss at step 1152: 2.937530755996704\n",
      "Training loss at step 1184: 2.8453774452209473\n",
      "Training loss at step 1216: 2.799353837966919\n",
      "Training loss at step 1248: 2.8077094554901123\n",
      "Training loss at step 1280: 2.964829444885254\n",
      "Training loss at step 1312: 3.333258628845215\n",
      "Training loss at step 1344: 3.8191232681274414\n",
      "Training loss at step 1376: 4.267739772796631\n",
      "Training loss at step 1408: 4.672379016876221\n",
      "Training loss at step 1440: 5.029008388519287\n",
      "Training loss at step 1472: 5.325362682342529\n",
      "Training loss at step 1504: 5.58901834487915\n",
      "Training loss at step 1536: 5.864898681640625\n",
      "Training loss at step 1568: 6.168276786804199\n",
      "Training loss at step 1600: 6.520174980163574\n",
      "Training loss at step 1632: 6.89943790435791\n",
      "Training loss at step 1664: 7.218442440032959\n",
      "Training loss at step 1696: 7.510462760925293\n",
      "Training loss at step 1728: 7.640300273895264\n",
      "Training loss at step 1760: 7.3711466789245605\n",
      "Training loss at step 1792: 6.59007453918457\n",
      "Training loss at step 1824: 5.704986572265625\n",
      "Training loss at step 1856: 4.95643949508667\n",
      "Training loss at step 1888: 4.4631667137146\n",
      "Training loss at step 1920: 4.159727096557617\n",
      "Training loss at step 1952: 3.98435115814209\n",
      "Training loss at step 1984: 3.893876075744629\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at step 0: 4.012621879577637\n",
      "Training loss at step 32: 3.5684900283813477\n",
      "Training loss at step 64: 3.3264055252075195\n",
      "Training loss at step 96: 3.1484310626983643\n",
      "Training loss at step 128: 3.0044350624084473\n",
      "Training loss at step 160: 2.896036148071289\n",
      "Training loss at step 192: 2.8283116817474365\n",
      "Training loss at step 224: 2.801319122314453\n",
      "Training loss at step 256: 2.835411548614502\n",
      "Training loss at step 288: 3.0161516666412354\n",
      "Training loss at step 320: 3.391995668411255\n",
      "Training loss at step 352: 3.868593454360962\n",
      "Training loss at step 384: 4.322609901428223\n",
      "Training loss at step 416: 4.719018459320068\n",
      "Training loss at step 448: 5.0331339836120605\n",
      "Training loss at step 480: 5.296623229980469\n",
      "Training loss at step 512: 5.550429344177246\n",
      "Training loss at step 544: 5.824097633361816\n",
      "Training loss at step 576: 6.143807888031006\n",
      "Training loss at step 608: 6.513378143310547\n",
      "Training loss at step 640: 6.901469707489014\n",
      "Training loss at step 672: 7.267068862915039\n",
      "Training loss at step 704: 7.528079986572266\n",
      "Training loss at step 736: 7.601861953735352\n",
      "Training loss at step 768: 7.203841209411621\n",
      "Training loss at step 800: 6.360630989074707\n",
      "Training loss at step 832: 5.47831392288208\n",
      "Training loss at step 864: 4.793946266174316\n",
      "Training loss at step 896: 4.390277862548828\n",
      "Training loss at step 928: 4.140120506286621\n",
      "Training loss at step 960: 3.932556629180908\n",
      "Training loss at step 992: 3.754582643508911\n",
      "Training loss at step 1024: 3.6098296642303467\n",
      "Training loss at step 1056: 3.496872901916504\n",
      "Training loss at step 1088: 3.3275482654571533\n",
      "Training loss at step 1120: 3.1297364234924316\n",
      "Training loss at step 1152: 2.967150926589966\n",
      "Training loss at step 1184: 2.864743947982788\n",
      "Training loss at step 1216: 2.81091570854187\n",
      "Training loss at step 1248: 2.8110475540161133\n",
      "Training loss at step 1280: 2.9561781883239746\n",
      "Training loss at step 1312: 3.320570230484009\n",
      "Training loss at step 1344: 3.811026096343994\n",
      "Training loss at step 1376: 4.270550727844238\n",
      "Training loss at step 1408: 4.689303398132324\n",
      "Training loss at step 1440: 5.042897701263428\n",
      "Training loss at step 1472: 5.330799102783203\n",
      "Training loss at step 1504: 5.588573932647705\n",
      "Training loss at step 1536: 5.836772918701172\n",
      "Training loss at step 1568: 6.124563694000244\n",
      "Training loss at step 1600: 6.46577787399292\n",
      "Training loss at step 1632: 6.809148788452148\n",
      "Training loss at step 1664: 7.181905746459961\n",
      "Training loss at step 1696: 7.47962760925293\n",
      "Training loss at step 1728: 7.6164703369140625\n",
      "Training loss at step 1760: 7.362255096435547\n",
      "Training loss at step 1792: 6.607192039489746\n",
      "Training loss at step 1824: 5.742840766906738\n",
      "Training loss at step 1856: 4.978308200836182\n",
      "Training loss at step 1888: 4.458797454833984\n",
      "Training loss at step 1920: 4.138724327087402\n",
      "Training loss at step 1952: 3.94553804397583\n",
      "Training loss at step 1984: 3.842750072479248\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at step 0: 3.998849630355835\n",
      "Training loss at step 32: 3.5602829456329346\n",
      "Training loss at step 64: 3.326425790786743\n",
      "Training loss at step 96: 3.1543283462524414\n",
      "Training loss at step 128: 3.0110538005828857\n",
      "Training loss at step 160: 2.897864580154419\n",
      "Training loss at step 192: 2.825728416442871\n",
      "Training loss at step 224: 2.801351308822632\n",
      "Training loss at step 256: 2.842343330383301\n",
      "Training loss at step 288: 3.0182526111602783\n",
      "Training loss at step 320: 3.379377603530884\n",
      "Training loss at step 352: 3.8519203662872314\n",
      "Training loss at step 384: 4.320589542388916\n",
      "Training loss at step 416: 4.715946197509766\n",
      "Training loss at step 448: 5.030409812927246\n",
      "Training loss at step 480: 5.291905403137207\n",
      "Training loss at step 512: 5.5416741371154785\n",
      "Training loss at step 544: 5.802131652832031\n",
      "Training loss at step 576: 6.11753511428833\n",
      "Training loss at step 608: 6.4869537353515625\n",
      "Training loss at step 640: 6.894496917724609\n",
      "Training loss at step 672: 7.2651567459106445\n",
      "Training loss at step 704: 7.524330139160156\n",
      "Training loss at step 736: 7.597630500793457\n",
      "Training loss at step 768: 7.203662872314453\n",
      "Training loss at step 800: 6.355603218078613\n",
      "Training loss at step 832: 5.459690570831299\n",
      "Training loss at step 864: 4.778245449066162\n",
      "Training loss at step 896: 4.362592697143555\n",
      "Training loss at step 928: 4.094645977020264\n",
      "Training loss at step 960: 3.8842968940734863\n",
      "Training loss at step 992: 3.711878776550293\n",
      "Training loss at step 1024: 3.5884289741516113\n",
      "Training loss at step 1056: 3.470088481903076\n",
      "Training loss at step 1088: 3.287321090698242\n",
      "Training loss at step 1120: 3.094353199005127\n",
      "Training loss at step 1152: 2.9428372383117676\n",
      "Training loss at step 1184: 2.848040819168091\n",
      "Training loss at step 1216: 2.8009698390960693\n",
      "Training loss at step 1248: 2.8076961040496826\n",
      "Training loss at step 1280: 2.9630250930786133\n",
      "Training loss at step 1312: 3.328554391860962\n",
      "Training loss at step 1344: 3.810892105102539\n",
      "Training loss at step 1376: 4.265070915222168\n",
      "Training loss at step 1408: 4.6794514656066895\n",
      "Training loss at step 1440: 5.051159381866455\n",
      "Training loss at step 1472: 5.349514007568359\n",
      "Training loss at step 1504: 5.611762523651123\n",
      "Training loss at step 1536: 5.876655101776123\n",
      "Training loss at step 1568: 6.170066833496094\n",
      "Training loss at step 1600: 6.52905797958374\n",
      "Training loss at step 1632: 6.914282321929932\n",
      "Training loss at step 1664: 7.242887496948242\n",
      "Training loss at step 1696: 7.515911102294922\n",
      "Training loss at step 1728: 7.638841152191162\n",
      "Training loss at step 1760: 7.371138572692871\n",
      "Training loss at step 1792: 6.586792945861816\n",
      "Training loss at step 1824: 5.696373462677002\n",
      "Training loss at step 1856: 4.959410667419434\n",
      "Training loss at step 1888: 4.466310977935791\n",
      "Training loss at step 1920: 4.153330326080322\n",
      "Training loss at step 1952: 3.9642105102539062\n",
      "Training loss at step 1984: 3.8711659908294678\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at step 0: 4.008708953857422\n",
      "Training loss at step 32: 3.5636191368103027\n",
      "Training loss at step 64: 3.3235957622528076\n",
      "Training loss at step 96: 3.1475770473480225\n",
      "Training loss at step 128: 3.004349708557129\n",
      "Training loss at step 160: 2.8955492973327637\n",
      "Training loss at step 192: 2.8279716968536377\n",
      "Training loss at step 224: 2.8019819259643555\n",
      "Training loss at step 256: 2.836729049682617\n",
      "Training loss at step 288: 3.0158984661102295\n",
      "Training loss at step 320: 3.386713981628418\n",
      "Training loss at step 352: 3.8599493503570557\n",
      "Training loss at step 384: 4.3077569007873535\n",
      "Training loss at step 416: 4.6970744132995605\n",
      "Training loss at step 448: 5.009761810302734\n",
      "Training loss at step 480: 5.271403789520264\n",
      "Training loss at step 512: 5.525823593139648\n",
      "Training loss at step 544: 5.79250431060791\n",
      "Training loss at step 576: 6.112469673156738\n",
      "Training loss at step 608: 6.486534118652344\n",
      "Training loss at step 640: 6.894031524658203\n",
      "Training loss at step 672: 7.264032363891602\n",
      "Training loss at step 704: 7.523967266082764\n",
      "Training loss at step 736: 7.598650932312012\n",
      "Training loss at step 768: 7.203901290893555\n",
      "Training loss at step 800: 6.354104995727539\n",
      "Training loss at step 832: 5.460061073303223\n",
      "Training loss at step 864: 4.783016204833984\n",
      "Training loss at step 896: 4.3677849769592285\n",
      "Training loss at step 928: 4.109870433807373\n",
      "Training loss at step 960: 3.90185809135437\n",
      "Training loss at step 992: 3.7214486598968506\n",
      "Training loss at step 1024: 3.5736501216888428\n",
      "Training loss at step 1056: 3.4354043006896973\n",
      "Training loss at step 1088: 3.2761459350585938\n",
      "Training loss at step 1120: 3.096086263656616\n",
      "Training loss at step 1152: 2.9511945247650146\n",
      "Training loss at step 1184: 2.8560378551483154\n",
      "Training loss at step 1216: 2.8081319332122803\n",
      "Training loss at step 1248: 2.8115413188934326\n",
      "Training loss at step 1280: 2.952228546142578\n",
      "Training loss at step 1312: 3.298308849334717\n",
      "Training loss at step 1344: 3.771512031555176\n",
      "Training loss at step 1376: 4.231655597686768\n",
      "Training loss at step 1408: 4.652402877807617\n",
      "Training loss at step 1440: 5.019452095031738\n",
      "Training loss at step 1472: 5.3186445236206055\n",
      "Training loss at step 1504: 5.590662956237793\n",
      "Training loss at step 1536: 5.862348556518555\n",
      "Training loss at step 1568: 6.152862548828125\n",
      "Training loss at step 1600: 6.493455410003662\n",
      "Training loss at step 1632: 6.828210830688477\n",
      "Training loss at step 1664: 7.1889214515686035\n",
      "Training loss at step 1696: 7.487812042236328\n",
      "Training loss at step 1728: 7.620151996612549\n",
      "Training loss at step 1760: 7.362986087799072\n",
      "Training loss at step 1792: 6.600643157958984\n",
      "Training loss at step 1824: 5.7252397537231445\n",
      "Training loss at step 1856: 4.966799736022949\n",
      "Training loss at step 1888: 4.445431232452393\n",
      "Training loss at step 1920: 4.130638122558594\n",
      "Training loss at step 1952: 3.954725503921509\n",
      "Training loss at step 1984: 3.8659865856170654\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at step 0: 3.999990463256836\n",
      "Training loss at step 32: 3.567261219024658\n",
      "Training loss at step 64: 3.3373188972473145\n",
      "Training loss at step 96: 3.1671152114868164\n",
      "Training loss at step 128: 3.0208258628845215\n",
      "Training loss at step 160: 2.9012820720672607\n",
      "Training loss at step 192: 2.825301170349121\n",
      "Training loss at step 224: 2.8054656982421875\n",
      "Training loss at step 256: 2.8533666133880615\n",
      "Training loss at step 288: 3.0255486965179443\n",
      "Training loss at step 320: 3.377444267272949\n",
      "Training loss at step 352: 3.8484344482421875\n",
      "Training loss at step 384: 4.318042278289795\n",
      "Training loss at step 416: 4.713744640350342\n",
      "Training loss at step 448: 5.028960704803467\n",
      "Training loss at step 480: 5.292595863342285\n",
      "Training loss at step 512: 5.544910907745361\n",
      "Training loss at step 544: 5.814291000366211\n",
      "Training loss at step 576: 6.132392406463623\n",
      "Training loss at step 608: 6.50244140625\n",
      "Training loss at step 640: 6.896114826202393\n",
      "Training loss at step 672: 7.264291286468506\n",
      "Training loss at step 704: 7.525871753692627\n",
      "Training loss at step 736: 7.600162982940674\n",
      "Training loss at step 768: 7.203658103942871\n",
      "Training loss at step 800: 6.35983419418335\n",
      "Training loss at step 832: 5.472888946533203\n",
      "Training loss at step 864: 4.785494327545166\n",
      "Training loss at step 896: 4.358615875244141\n",
      "Training loss at step 928: 4.094461917877197\n",
      "Training loss at step 960: 3.8813629150390625\n",
      "Training loss at step 992: 3.701730489730835\n",
      "Training loss at step 1024: 3.5618338584899902\n",
      "Training loss at step 1056: 3.4527840614318848\n",
      "Training loss at step 1088: 3.2795746326446533\n",
      "Training loss at step 1120: 3.0876553058624268\n",
      "Training loss at step 1152: 2.940082311630249\n",
      "Training loss at step 1184: 2.848489999771118\n",
      "Training loss at step 1216: 2.8014490604400635\n",
      "Training loss at step 1248: 2.8079099655151367\n",
      "Training loss at step 1280: 2.96266770362854\n",
      "Training loss at step 1312: 3.3241963386535645\n",
      "Training loss at step 1344: 3.7993760108947754\n",
      "Training loss at step 1376: 4.24714469909668\n",
      "Training loss at step 1408: 4.660588264465332\n",
      "Training loss at step 1440: 5.01054048538208\n",
      "Training loss at step 1472: 5.306778430938721\n",
      "Training loss at step 1504: 5.576824188232422\n",
      "Training loss at step 1536: 5.845889091491699\n",
      "Training loss at step 1568: 6.134213447570801\n",
      "Training loss at step 1600: 6.475441932678223\n",
      "Training loss at step 1632: 6.827035427093506\n",
      "Training loss at step 1664: 7.189165115356445\n",
      "Training loss at step 1696: 7.4847259521484375\n",
      "Training loss at step 1728: 7.6173295974731445\n",
      "Training loss at step 1760: 7.361537456512451\n",
      "Training loss at step 1792: 6.599742412567139\n",
      "Training loss at step 1824: 5.715649604797363\n",
      "Training loss at step 1856: 4.96940803527832\n",
      "Training loss at step 1888: 4.46088981628418\n",
      "Training loss at step 1920: 4.147426605224609\n",
      "Training loss at step 1952: 3.9734935760498047\n",
      "Training loss at step 1984: 3.890042543411255\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at step 0: 4.016483783721924\n",
      "Training loss at step 32: 3.563065767288208\n",
      "Training loss at step 64: 3.323305130004883\n",
      "Training loss at step 96: 3.1499972343444824\n",
      "Training loss at step 128: 3.0083911418914795\n",
      "Training loss at step 160: 2.89750075340271\n",
      "Training loss at step 192: 2.8253257274627686\n",
      "Training loss at step 224: 2.7962026596069336\n",
      "Training loss at step 256: 2.833427906036377\n",
      "Training loss at step 288: 3.015902519226074\n",
      "Training loss at step 320: 3.382129192352295\n",
      "Training loss at step 352: 3.8502302169799805\n",
      "Training loss at step 384: 4.306405067443848\n",
      "Training loss at step 416: 4.698941707611084\n",
      "Training loss at step 448: 5.0108137130737305\n",
      "Training loss at step 480: 5.274477005004883\n",
      "Training loss at step 512: 5.525412559509277\n",
      "Training loss at step 544: 5.790382385253906\n",
      "Training loss at step 576: 6.110367298126221\n",
      "Training loss at step 608: 6.486573219299316\n",
      "Training loss at step 640: 6.894489765167236\n",
      "Training loss at step 672: 7.26431941986084\n",
      "Training loss at step 704: 7.524005889892578\n",
      "Training loss at step 736: 7.599388122558594\n",
      "Training loss at step 768: 7.204679012298584\n",
      "Training loss at step 800: 6.351404190063477\n",
      "Training loss at step 832: 5.453478813171387\n",
      "Training loss at step 864: 4.77148962020874\n",
      "Training loss at step 896: 4.348365783691406\n",
      "Training loss at step 928: 4.0790205001831055\n",
      "Training loss at step 960: 3.864760637283325\n",
      "Training loss at step 992: 3.68851900100708\n",
      "Training loss at step 1024: 3.5521373748779297\n",
      "Training loss at step 1056: 3.441730260848999\n",
      "Training loss at step 1088: 3.2771403789520264\n",
      "Training loss at step 1120: 3.093625545501709\n",
      "Training loss at step 1152: 2.94443678855896\n",
      "Training loss at step 1184: 2.8509457111358643\n",
      "Training loss at step 1216: 2.8032898902893066\n",
      "Training loss at step 1248: 2.80829119682312\n",
      "Training loss at step 1280: 2.9586455821990967\n",
      "Training loss at step 1312: 3.3176074028015137\n",
      "Training loss at step 1344: 3.7966597080230713\n",
      "Training loss at step 1376: 4.256350040435791\n",
      "Training loss at step 1408: 4.680574893951416\n",
      "Training loss at step 1440: 5.030550003051758\n",
      "Training loss at step 1472: 5.324555397033691\n",
      "Training loss at step 1504: 5.596835136413574\n",
      "Training loss at step 1536: 5.868687629699707\n",
      "Training loss at step 1568: 6.160964012145996\n",
      "Training loss at step 1600: 6.503786087036133\n",
      "Training loss at step 1632: 6.865181922912598\n",
      "Training loss at step 1664: 7.206896781921387\n",
      "Training loss at step 1696: 7.4892120361328125\n",
      "Training loss at step 1728: 7.6200103759765625\n",
      "Training loss at step 1760: 7.362067222595215\n",
      "Training loss at step 1792: 6.594825267791748\n",
      "Training loss at step 1824: 5.708364486694336\n",
      "Training loss at step 1856: 4.963529109954834\n",
      "Training loss at step 1888: 4.456027507781982\n",
      "Training loss at step 1920: 4.142759323120117\n",
      "Training loss at step 1952: 3.9688260555267334\n",
      "Training loss at step 1984: 3.8877851963043213\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at step 0: 4.018721580505371\n",
      "Training loss at step 32: 3.567589282989502\n",
      "Training loss at step 64: 3.3240244388580322\n",
      "Training loss at step 96: 3.1475448608398438\n",
      "Training loss at step 128: 3.0044593811035156\n",
      "Training loss at step 160: 2.8952555656433105\n",
      "Training loss at step 192: 2.8268814086914062\n",
      "Training loss at step 224: 2.801737070083618\n",
      "Training loss at step 256: 2.837830066680908\n",
      "Training loss at step 288: 3.0159552097320557\n",
      "Training loss at step 320: 3.3856005668640137\n",
      "Training loss at step 352: 3.857335090637207\n",
      "Training loss at step 384: 4.305675506591797\n",
      "Training loss at step 416: 4.6949052810668945\n",
      "Training loss at step 448: 5.006655216217041\n",
      "Training loss at step 480: 5.269992828369141\n",
      "Training loss at step 512: 5.522465705871582\n",
      "Training loss at step 544: 5.78880500793457\n",
      "Training loss at step 576: 6.110058307647705\n",
      "Training loss at step 608: 6.486544609069824\n",
      "Training loss at step 640: 6.894275188446045\n",
      "Training loss at step 672: 7.264093399047852\n",
      "Training loss at step 704: 7.524011135101318\n",
      "Training loss at step 736: 7.599645614624023\n",
      "Training loss at step 768: 7.204775333404541\n",
      "Training loss at step 800: 6.351395130157471\n",
      "Training loss at step 832: 5.453415870666504\n",
      "Training loss at step 864: 4.767969131469727\n",
      "Training loss at step 896: 4.3355393409729\n",
      "Training loss at step 928: 4.064683437347412\n",
      "Training loss at step 960: 3.8530099391937256\n",
      "Training loss at step 992: 3.6768438816070557\n",
      "Training loss at step 1024: 3.5346970558166504\n",
      "Training loss at step 1056: 3.420124053955078\n",
      "Training loss at step 1088: 3.252218008041382\n",
      "Training loss at step 1120: 3.0717124938964844\n",
      "Training loss at step 1152: 2.931917428970337\n",
      "Training loss at step 1184: 2.843268632888794\n",
      "Training loss at step 1216: 2.7991764545440674\n",
      "Training loss at step 1248: 2.8076179027557373\n",
      "Training loss at step 1280: 2.959476947784424\n",
      "Training loss at step 1312: 3.3113012313842773\n",
      "Training loss at step 1344: 3.7783994674682617\n",
      "Training loss at step 1376: 4.234622001647949\n",
      "Training loss at step 1408: 4.655228614807129\n",
      "Training loss at step 1440: 5.011072635650635\n",
      "Training loss at step 1472: 5.3149213790893555\n",
      "Training loss at step 1504: 5.588889122009277\n",
      "Training loss at step 1536: 5.8590545654296875\n",
      "Training loss at step 1568: 6.136321067810059\n",
      "Training loss at step 1600: 6.4749555587768555\n",
      "Training loss at step 1632: 6.823960304260254\n",
      "Training loss at step 1664: 7.187074184417725\n",
      "Training loss at step 1696: 7.482958793640137\n",
      "Training loss at step 1728: 7.6154985427856445\n",
      "Training loss at step 1760: 7.361412525177002\n",
      "Training loss at step 1792: 6.60310173034668\n",
      "Training loss at step 1824: 5.721461296081543\n",
      "Training loss at step 1856: 4.972092628479004\n",
      "Training loss at step 1888: 4.462209224700928\n",
      "Training loss at step 1920: 4.136081218719482\n",
      "Training loss at step 1952: 3.962440013885498\n",
      "Training loss at step 1984: 3.8821651935577393\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at step 0: 3.9976906776428223\n",
      "Training loss at step 32: 3.561210870742798\n",
      "Training loss at step 64: 3.3304245471954346\n",
      "Training loss at step 96: 3.1575636863708496\n",
      "Training loss at step 128: 3.0118649005889893\n",
      "Training loss at step 160: 2.8961853981018066\n",
      "Training loss at step 192: 2.8281424045562744\n",
      "Training loss at step 224: 2.813777208328247\n",
      "Training loss at step 256: 2.859003782272339\n",
      "Training loss at step 288: 3.0253970623016357\n",
      "Training loss at step 320: 3.3773069381713867\n",
      "Training loss at step 352: 3.845653772354126\n",
      "Training loss at step 384: 4.301475524902344\n",
      "Training loss at step 416: 4.691173553466797\n",
      "Training loss at step 448: 5.003641128540039\n",
      "Training loss at step 480: 5.268596649169922\n",
      "Training loss at step 512: 5.522992134094238\n",
      "Training loss at step 544: 5.79131555557251\n",
      "Training loss at step 576: 6.114173412322998\n",
      "Training loss at step 608: 6.488236427307129\n",
      "Training loss at step 640: 6.891839981079102\n",
      "Training loss at step 672: 7.262672424316406\n",
      "Training loss at step 704: 7.524621486663818\n",
      "Training loss at step 736: 7.600726127624512\n",
      "Training loss at step 768: 7.204681396484375\n",
      "Training loss at step 800: 6.352357864379883\n",
      "Training loss at step 832: 5.45616340637207\n",
      "Training loss at step 864: 4.766223430633545\n",
      "Training loss at step 896: 4.325633525848389\n",
      "Training loss at step 928: 4.04717493057251\n",
      "Training loss at step 960: 3.8347649574279785\n",
      "Training loss at step 992: 3.659592866897583\n",
      "Training loss at step 1024: 3.5175185203552246\n",
      "Training loss at step 1056: 3.3942713737487793\n",
      "Training loss at step 1088: 3.2274675369262695\n",
      "Training loss at step 1120: 3.0544493198394775\n",
      "Training loss at step 1152: 2.921395778656006\n",
      "Training loss at step 1184: 2.838047504425049\n",
      "Training loss at step 1216: 2.797200918197632\n",
      "Training loss at step 1248: 2.8075757026672363\n",
      "Training loss at step 1280: 2.9569430351257324\n",
      "Training loss at step 1312: 3.2997968196868896\n",
      "Training loss at step 1344: 3.7597639560699463\n",
      "Training loss at step 1376: 4.2162041664123535\n",
      "Training loss at step 1408: 4.634589195251465\n",
      "Training loss at step 1440: 4.995033264160156\n",
      "Training loss at step 1472: 5.298224449157715\n",
      "Training loss at step 1504: 5.577746868133545\n",
      "Training loss at step 1536: 5.860604286193848\n",
      "Training loss at step 1568: 6.146792888641357\n",
      "Training loss at step 1600: 6.490208625793457\n",
      "Training loss at step 1632: 6.859297752380371\n",
      "Training loss at step 1664: 7.207459926605225\n",
      "Training loss at step 1696: 7.488389015197754\n",
      "Training loss at step 1728: 7.6166558265686035\n",
      "Training loss at step 1760: 7.361099720001221\n",
      "Training loss at step 1792: 6.596809387207031\n",
      "Training loss at step 1824: 5.711092948913574\n",
      "Training loss at step 1856: 4.967251777648926\n",
      "Training loss at step 1888: 4.464639186859131\n",
      "Training loss at step 1920: 4.141114234924316\n",
      "Training loss at step 1952: 3.9763755798339844\n",
      "Training loss at step 1984: 3.9079134464263916\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at step 0: 3.9980835914611816\n",
      "Training loss at step 32: 3.5657401084899902\n",
      "Training loss at step 64: 3.342135190963745\n",
      "Training loss at step 96: 3.1786997318267822\n",
      "Training loss at step 128: 3.034066915512085\n",
      "Training loss at step 160: 2.911182403564453\n",
      "Training loss at step 192: 2.8278346061706543\n",
      "Training loss at step 224: 2.7965750694274902\n",
      "Training loss at step 256: 2.842482566833496\n",
      "Training loss at step 288: 3.02374005317688\n",
      "Training loss at step 320: 3.377944231033325\n",
      "Training loss at step 352: 3.843120574951172\n",
      "Training loss at step 384: 4.301846504211426\n",
      "Training loss at step 416: 4.683696746826172\n",
      "Training loss at step 448: 4.99199104309082\n",
      "Training loss at step 480: 5.254941940307617\n",
      "Training loss at step 512: 5.505328178405762\n",
      "Training loss at step 544: 5.777255058288574\n",
      "Training loss at step 576: 6.10566520690918\n",
      "Training loss at step 608: 6.496241092681885\n",
      "Training loss at step 640: 6.904370307922363\n",
      "Training loss at step 672: 7.267159938812256\n",
      "Training loss at step 704: 7.524040222167969\n",
      "Training loss at step 736: 7.602591037750244\n",
      "Training loss at step 768: 7.210944652557373\n",
      "Training loss at step 800: 6.3516316413879395\n",
      "Training loss at step 832: 5.447995662689209\n",
      "Training loss at step 864: 4.757416248321533\n",
      "Training loss at step 896: 4.327682018280029\n",
      "Training loss at step 928: 4.056184768676758\n",
      "Training loss at step 960: 3.8466036319732666\n",
      "Training loss at step 992: 3.672362804412842\n",
      "Training loss at step 1024: 3.5343708992004395\n",
      "Training loss at step 1056: 3.430781126022339\n",
      "Training loss at step 1088: 3.2722671031951904\n",
      "Training loss at step 1120: 3.093780279159546\n",
      "Training loss at step 1152: 2.945160388946533\n",
      "Training loss at step 1184: 2.850925922393799\n",
      "Training loss at step 1216: 2.80336332321167\n",
      "Training loss at step 1248: 2.808372974395752\n",
      "Training loss at step 1280: 2.9593398571014404\n",
      "Training loss at step 1312: 3.318730354309082\n",
      "Training loss at step 1344: 3.793750762939453\n",
      "Training loss at step 1376: 4.2557291984558105\n",
      "Training loss at step 1408: 4.684784889221191\n",
      "Training loss at step 1440: 5.035579681396484\n",
      "Training loss at step 1472: 5.331099510192871\n",
      "Training loss at step 1504: 5.603736877441406\n",
      "Training loss at step 1536: 5.8608479499816895\n",
      "Training loss at step 1568: 6.133597373962402\n",
      "Training loss at step 1600: 6.4741010665893555\n",
      "Training loss at step 1632: 6.826754093170166\n",
      "Training loss at step 1664: 7.187803268432617\n",
      "Training loss at step 1696: 7.48153018951416\n",
      "Training loss at step 1728: 7.613999366760254\n",
      "Training loss at step 1760: 7.361237525939941\n",
      "Training loss at step 1792: 6.601040363311768\n",
      "Training loss at step 1824: 5.712031364440918\n",
      "Training loss at step 1856: 4.959497451782227\n",
      "Training loss at step 1888: 4.454192161560059\n",
      "Training loss at step 1920: 4.133824825286865\n",
      "Training loss at step 1952: 3.968376636505127\n",
      "Training loss at step 1984: 3.8937158584594727\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at step 0: 4.00868034362793\n",
      "Training loss at step 32: 3.5624189376831055\n",
      "Training loss at step 64: 3.3232979774475098\n",
      "Training loss at step 96: 3.1483163833618164\n",
      "Training loss at step 128: 3.0060458183288574\n",
      "Training loss at step 160: 2.896207809448242\n",
      "Training loss at step 192: 2.825579881668091\n",
      "Training loss at step 224: 2.7966220378875732\n",
      "Training loss at step 256: 2.8318052291870117\n",
      "Training loss at step 288: 3.0172808170318604\n",
      "Training loss at step 320: 3.389758825302124\n",
      "Training loss at step 352: 3.8542916774749756\n",
      "Training loss at step 384: 4.30162239074707\n",
      "Training loss at step 416: 4.688630104064941\n",
      "Training loss at step 448: 4.998579025268555\n",
      "Training loss at step 480: 5.26107931137085\n",
      "Training loss at step 512: 5.512277603149414\n",
      "Training loss at step 544: 5.781194686889648\n",
      "Training loss at step 576: 6.1058244705200195\n",
      "Training loss at step 608: 6.4892377853393555\n",
      "Training loss at step 640: 6.897741317749023\n",
      "Training loss at step 672: 7.265511989593506\n",
      "Training loss at step 704: 7.524030685424805\n",
      "Training loss at step 736: 7.600806713104248\n",
      "Training loss at step 768: 7.2069501876831055\n",
      "Training loss at step 800: 6.35026741027832\n",
      "Training loss at step 832: 5.449557304382324\n",
      "Training loss at step 864: 4.7686004638671875\n",
      "Training loss at step 896: 4.352991580963135\n",
      "Training loss at step 928: 4.085430145263672\n",
      "Training loss at step 960: 3.8643112182617188\n",
      "Training loss at step 992: 3.7016806602478027\n",
      "Training loss at step 1024: 3.6124179363250732\n",
      "Training loss at step 1056: 3.5170650482177734\n",
      "Training loss at step 1088: 3.3443167209625244\n",
      "Training loss at step 1120: 3.1415295600891113\n",
      "Training loss at step 1152: 2.9724295139312744\n",
      "Training loss at step 1184: 2.8628876209259033\n",
      "Training loss at step 1216: 2.80715012550354\n",
      "Training loss at step 1248: 2.808548927307129\n",
      "Training loss at step 1280: 2.965491533279419\n",
      "Training loss at step 1312: 3.3521080017089844\n",
      "Training loss at step 1344: 3.859386444091797\n",
      "Training loss at step 1376: 4.308719635009766\n",
      "Training loss at step 1408: 4.719273090362549\n",
      "Training loss at step 1440: 5.090996265411377\n",
      "Training loss at step 1472: 5.4018940925598145\n",
      "Training loss at step 1504: 5.671854496002197\n",
      "Training loss at step 1536: 5.927947998046875\n",
      "Training loss at step 1568: 6.191945552825928\n",
      "Training loss at step 1600: 6.519430160522461\n",
      "Training loss at step 1632: 6.861916542053223\n",
      "Training loss at step 1664: 7.202116012573242\n",
      "Training loss at step 1696: 7.492550373077393\n",
      "Training loss at step 1728: 7.6223931312561035\n",
      "Training loss at step 1760: 7.363435745239258\n",
      "Training loss at step 1792: 6.60152530670166\n",
      "Training loss at step 1824: 5.725201606750488\n",
      "Training loss at step 1856: 4.9739227294921875\n",
      "Training loss at step 1888: 4.4582061767578125\n",
      "Training loss at step 1920: 4.1245574951171875\n",
      "Training loss at step 1952: 3.93453311920166\n",
      "Training loss at step 1984: 3.8514628410339355\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at step 0: 4.026002883911133\n",
      "Training loss at step 32: 3.5730350017547607\n",
      "Training loss at step 64: 3.327608346939087\n",
      "Training loss at step 96: 3.1487979888916016\n",
      "Training loss at step 128: 3.004316806793213\n",
      "Training loss at step 160: 2.8955416679382324\n",
      "Training loss at step 192: 2.8273890018463135\n",
      "Training loss at step 224: 2.8004038333892822\n",
      "Training loss at step 256: 2.834735155105591\n",
      "Training loss at step 288: 3.0158514976501465\n",
      "Training loss at step 320: 3.388686418533325\n",
      "Training loss at step 352: 3.859311103820801\n",
      "Training loss at step 384: 4.302844047546387\n",
      "Training loss at step 416: 4.683710098266602\n",
      "Training loss at step 448: 4.991869926452637\n",
      "Training loss at step 480: 5.253062725067139\n",
      "Training loss at step 512: 5.505684852600098\n",
      "Training loss at step 544: 5.778410911560059\n",
      "Training loss at step 576: 6.10544490814209\n",
      "Training loss at step 608: 6.487314224243164\n",
      "Training loss at step 640: 6.89508056640625\n",
      "Training loss at step 672: 7.2641191482543945\n",
      "Training loss at step 704: 7.523939609527588\n",
      "Training loss at step 736: 7.599491119384766\n",
      "Training loss at step 768: 7.204707145690918\n",
      "Training loss at step 800: 6.351718425750732\n",
      "Training loss at step 832: 5.453429698944092\n",
      "Training loss at step 864: 4.7624287605285645\n",
      "Training loss at step 896: 4.320014953613281\n",
      "Training loss at step 928: 4.032171726226807\n",
      "Training loss at step 960: 3.8208179473876953\n",
      "Training loss at step 992: 3.6535422801971436\n",
      "Training loss at step 1024: 3.5154948234558105\n",
      "Training loss at step 1056: 3.3822176456451416\n",
      "Training loss at step 1088: 3.2279202938079834\n",
      "Training loss at step 1120: 3.067410469055176\n",
      "Training loss at step 1152: 2.932596206665039\n",
      "Training loss at step 1184: 2.8442938327789307\n",
      "Training loss at step 1216: 2.802326202392578\n",
      "Training loss at step 1248: 2.813575267791748\n",
      "Training loss at step 1280: 2.9504919052124023\n",
      "Training loss at step 1312: 3.278000593185425\n",
      "Training loss at step 1344: 3.7383437156677246\n",
      "Training loss at step 1376: 4.205804824829102\n",
      "Training loss at step 1408: 4.639847755432129\n",
      "Training loss at step 1440: 5.014069557189941\n",
      "Training loss at step 1472: 5.329723358154297\n",
      "Training loss at step 1504: 5.620601654052734\n",
      "Training loss at step 1536: 5.906973838806152\n",
      "Training loss at step 1568: 6.186219215393066\n",
      "Training loss at step 1600: 6.532827854156494\n",
      "Training loss at step 1632: 6.888657569885254\n",
      "Training loss at step 1664: 7.222650527954102\n",
      "Training loss at step 1696: 7.495742321014404\n",
      "Training loss at step 1728: 7.623243808746338\n",
      "Training loss at step 1760: 7.364188194274902\n",
      "Training loss at step 1792: 6.595791816711426\n",
      "Training loss at step 1824: 5.712946891784668\n",
      "Training loss at step 1856: 4.961943626403809\n",
      "Training loss at step 1888: 4.448997974395752\n",
      "Training loss at step 1920: 4.1144328117370605\n",
      "Training loss at step 1952: 3.9372949600219727\n",
      "Training loss at step 1984: 3.8639960289001465\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at step 0: 4.035572052001953\n",
      "Training loss at step 32: 3.5979785919189453\n",
      "Training loss at step 64: 3.366570234298706\n",
      "Training loss at step 96: 3.196110248565674\n",
      "Training loss at step 128: 3.042846918106079\n",
      "Training loss at step 160: 2.9125795364379883\n",
      "Training loss at step 192: 2.826995611190796\n",
      "Training loss at step 224: 2.797790288925171\n",
      "Training loss at step 256: 2.849355697631836\n",
      "Training loss at step 288: 3.0302255153656006\n",
      "Training loss at step 320: 3.3802332878112793\n",
      "Training loss at step 352: 3.8429980278015137\n",
      "Training loss at step 384: 4.303018569946289\n",
      "Training loss at step 416: 4.695840835571289\n",
      "Training loss at step 448: 5.008595943450928\n",
      "Training loss at step 480: 5.273806095123291\n",
      "Training loss at step 512: 5.531620502471924\n",
      "Training loss at step 544: 5.800099849700928\n",
      "Training loss at step 576: 6.125289440155029\n",
      "Training loss at step 608: 6.502161026000977\n",
      "Training loss at step 640: 6.89754056930542\n",
      "Training loss at step 672: 7.2661614418029785\n",
      "Training loss at step 704: 7.528800964355469\n",
      "Training loss at step 736: 7.603481769561768\n",
      "Training loss at step 768: 7.204219818115234\n",
      "Training loss at step 800: 6.356479644775391\n",
      "Training loss at step 832: 5.466835975646973\n",
      "Training loss at step 864: 4.7628607749938965\n",
      "Training loss at step 896: 4.328568935394287\n",
      "Training loss at step 928: 4.066324710845947\n",
      "Training loss at step 960: 3.8681790828704834\n",
      "Training loss at step 992: 3.695082902908325\n",
      "Training loss at step 1024: 3.555067777633667\n",
      "Training loss at step 1056: 3.451854705810547\n",
      "Training loss at step 1088: 3.2798538208007812\n",
      "Training loss at step 1120: 3.0934886932373047\n",
      "Training loss at step 1152: 2.948662042617798\n",
      "Training loss at step 1184: 2.8565304279327393\n",
      "Training loss at step 1216: 2.8081777095794678\n",
      "Training loss at step 1248: 2.8106515407562256\n",
      "Training loss at step 1280: 2.953754186630249\n",
      "Training loss at step 1312: 3.3010096549987793\n",
      "Training loss at step 1344: 3.7717442512512207\n",
      "Training loss at step 1376: 4.2269392013549805\n",
      "Training loss at step 1408: 4.636105537414551\n",
      "Training loss at step 1440: 4.983057498931885\n",
      "Training loss at step 1472: 5.290744781494141\n",
      "Training loss at step 1504: 5.5747857093811035\n",
      "Training loss at step 1536: 5.81499719619751\n",
      "Training loss at step 1568: 6.086243629455566\n",
      "Training loss at step 1600: 6.415363311767578\n",
      "Training loss at step 1632: 6.791608810424805\n",
      "Training loss at step 1664: 7.178594589233398\n",
      "Training loss at step 1696: 7.4760870933532715\n",
      "Training loss at step 1728: 7.610729694366455\n",
      "Training loss at step 1760: 7.361071586608887\n",
      "Training loss at step 1792: 6.620607852935791\n",
      "Training loss at step 1824: 5.767536163330078\n",
      "Training loss at step 1856: 4.992865562438965\n",
      "Training loss at step 1888: 4.462396621704102\n",
      "Training loss at step 1920: 4.115472316741943\n",
      "Training loss at step 1952: 3.9333529472351074\n",
      "Training loss at step 1984: 3.8604209423065186\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at step 0: 4.032759189605713\n",
      "Training loss at step 32: 3.5670981407165527\n",
      "Training loss at step 64: 3.323796033859253\n",
      "Training loss at step 96: 3.149527072906494\n",
      "Training loss at step 128: 3.009141445159912\n",
      "Training loss at step 160: 2.899120807647705\n",
      "Training loss at step 192: 2.8263556957244873\n",
      "Training loss at step 224: 2.7946152687072754\n",
      "Training loss at step 256: 2.8304450511932373\n",
      "Training loss at step 288: 3.0161385536193848\n",
      "Training loss at step 320: 3.3829338550567627\n",
      "Training loss at step 352: 3.8480265140533447\n",
      "Training loss at step 384: 4.302289009094238\n",
      "Training loss at step 416: 4.689939975738525\n",
      "Training loss at step 448: 5.000662803649902\n",
      "Training loss at step 480: 5.259661674499512\n",
      "Training loss at step 512: 5.508028030395508\n",
      "Training loss at step 544: 5.778338432312012\n",
      "Training loss at step 576: 6.105277061462402\n",
      "Training loss at step 608: 6.486559867858887\n",
      "Training loss at step 640: 6.8932037353515625\n",
      "Training loss at step 672: 7.262945652008057\n",
      "Training loss at step 704: 7.525250434875488\n",
      "Training loss at step 736: 7.605711936950684\n",
      "Training loss at step 768: 7.211087703704834\n",
      "Training loss at step 800: 6.350800514221191\n",
      "Training loss at step 832: 5.44823694229126\n",
      "Training loss at step 864: 4.751097202301025\n",
      "Training loss at step 896: 4.296273231506348\n",
      "Training loss at step 928: 4.014859199523926\n",
      "Training loss at step 960: 3.809957265853882\n",
      "Training loss at step 992: 3.641007900238037\n",
      "Training loss at step 1024: 3.5232725143432617\n",
      "Training loss at step 1056: 3.4105536937713623\n",
      "Training loss at step 1088: 3.225109338760376\n",
      "Training loss at step 1120: 3.0525760650634766\n",
      "Training loss at step 1152: 2.924126625061035\n",
      "Training loss at step 1184: 2.8416802883148193\n",
      "Training loss at step 1216: 2.7991042137145996\n",
      "Training loss at step 1248: 2.8077762126922607\n",
      "Training loss at step 1280: 2.959584951400757\n",
      "Training loss at step 1312: 3.3034677505493164\n",
      "Training loss at step 1344: 3.760207176208496\n",
      "Training loss at step 1376: 4.210661888122559\n",
      "Training loss at step 1408: 4.637791633605957\n",
      "Training loss at step 1440: 5.014803409576416\n",
      "Training loss at step 1472: 5.33253812789917\n",
      "Training loss at step 1504: 5.621782302856445\n",
      "Training loss at step 1536: 5.889261245727539\n",
      "Training loss at step 1568: 6.160727500915527\n",
      "Training loss at step 1600: 6.511075019836426\n",
      "Training loss at step 1632: 6.874841690063477\n",
      "Training loss at step 1664: 7.214420318603516\n",
      "Training loss at step 1696: 7.511510372161865\n",
      "Training loss at step 1728: 7.64031982421875\n",
      "Training loss at step 1760: 7.370709419250488\n",
      "Training loss at step 1792: 6.59127140045166\n",
      "Training loss at step 1824: 5.695352554321289\n",
      "Training loss at step 1856: 4.949223041534424\n",
      "Training loss at step 1888: 4.461891174316406\n",
      "Training loss at step 1920: 4.13227653503418\n",
      "Training loss at step 1952: 3.9589595794677734\n",
      "Training loss at step 1984: 3.8954625129699707\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at step 0: 4.057381629943848\n",
      "Training loss at step 32: 3.584606409072876\n",
      "Training loss at step 64: 3.3373241424560547\n",
      "Training loss at step 96: 3.1549184322357178\n",
      "Training loss at step 128: 3.0073065757751465\n",
      "Training loss at step 160: 2.897313356399536\n",
      "Training loss at step 192: 2.827963352203369\n",
      "Training loss at step 224: 2.798429012298584\n",
      "Training loss at step 256: 2.8310461044311523\n",
      "Training loss at step 288: 3.018699884414673\n",
      "Training loss at step 320: 3.3980154991149902\n",
      "Training loss at step 352: 3.865478515625\n",
      "Training loss at step 384: 4.302666664123535\n",
      "Training loss at step 416: 4.6850128173828125\n",
      "Training loss at step 448: 4.993697166442871\n",
      "Training loss at step 480: 5.251929759979248\n",
      "Training loss at step 512: 5.499605178833008\n",
      "Training loss at step 544: 5.776696681976318\n",
      "Training loss at step 576: 6.1217851638793945\n",
      "Training loss at step 608: 6.527520179748535\n",
      "Training loss at step 640: 6.928766250610352\n",
      "Training loss at step 672: 7.282235145568848\n",
      "Training loss at step 704: 7.529272079467773\n",
      "Training loss at step 736: 7.597513675689697\n",
      "Training loss at step 768: 7.205747604370117\n",
      "Training loss at step 800: 6.351779460906982\n",
      "Training loss at step 832: 5.4498395919799805\n",
      "Training loss at step 864: 4.746151924133301\n",
      "Training loss at step 896: 4.286285877227783\n",
      "Training loss at step 928: 4.002122402191162\n",
      "Training loss at step 960: 3.7941157817840576\n",
      "Training loss at step 992: 3.624408006668091\n",
      "Training loss at step 1024: 3.480158567428589\n",
      "Training loss at step 1056: 3.3434576988220215\n",
      "Training loss at step 1088: 3.186807155609131\n",
      "Training loss at step 1120: 3.033998489379883\n",
      "Training loss at step 1152: 2.9149842262268066\n",
      "Training loss at step 1184: 2.8363723754882812\n",
      "Training loss at step 1216: 2.7974472045898438\n",
      "Training loss at step 1248: 2.80859637260437\n",
      "Training loss at step 1280: 2.9501819610595703\n",
      "Training loss at step 1312: 3.275400161743164\n",
      "Training loss at step 1344: 3.7310538291931152\n",
      "Training loss at step 1376: 4.194396495819092\n",
      "Training loss at step 1408: 4.618100643157959\n",
      "Training loss at step 1440: 4.9850172996521\n",
      "Training loss at step 1472: 5.302004814147949\n",
      "Training loss at step 1504: 5.589095115661621\n",
      "Training loss at step 1536: 5.854794979095459\n",
      "Training loss at step 1568: 6.131032466888428\n",
      "Training loss at step 1600: 6.478214263916016\n",
      "Training loss at step 1632: 6.824546813964844\n",
      "Training loss at step 1664: 7.1845316886901855\n",
      "Training loss at step 1696: 7.480199813842773\n",
      "Training loss at step 1728: 7.614419937133789\n",
      "Training loss at step 1760: 7.361541748046875\n",
      "Training loss at step 1792: 6.602863311767578\n",
      "Training loss at step 1824: 5.712008476257324\n",
      "Training loss at step 1856: 4.953550338745117\n",
      "Training loss at step 1888: 4.4536004066467285\n",
      "Training loss at step 1920: 4.124516010284424\n",
      "Training loss at step 1952: 3.941486120223999\n",
      "Training loss at step 1984: 3.877528667449951\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at step 0: 4.014240264892578\n",
      "Training loss at step 32: 3.570917844772339\n",
      "Training loss at step 64: 3.33573317527771\n",
      "Training loss at step 96: 3.159048557281494\n",
      "Training loss at step 128: 3.010279417037964\n",
      "Training loss at step 160: 2.8951168060302734\n",
      "Training loss at step 192: 2.8333702087402344\n",
      "Training loss at step 224: 2.8270819187164307\n",
      "Training loss at step 256: 2.873377561569214\n",
      "Training loss at step 288: 3.031386613845825\n",
      "Training loss at step 320: 3.3772661685943604\n",
      "Training loss at step 352: 3.8452389240264893\n",
      "Training loss at step 384: 4.302730083465576\n",
      "Training loss at step 416: 4.694594383239746\n",
      "Training loss at step 448: 5.009057521820068\n",
      "Training loss at step 480: 5.270946502685547\n",
      "Training loss at step 512: 5.529372692108154\n",
      "Training loss at step 544: 5.798327922821045\n",
      "Training loss at step 576: 6.122455596923828\n",
      "Training loss at step 608: 6.504203796386719\n",
      "Training loss at step 640: 6.899800777435303\n",
      "Training loss at step 672: 7.267213821411133\n",
      "Training loss at step 704: 7.528263092041016\n",
      "Training loss at step 736: 7.6010332107543945\n",
      "Training loss at step 768: 7.20365047454834\n",
      "Training loss at step 800: 6.359126091003418\n",
      "Training loss at step 832: 5.466561317443848\n",
      "Training loss at step 864: 4.764882564544678\n",
      "Training loss at step 896: 4.308194160461426\n",
      "Training loss at step 928: 4.013748645782471\n",
      "Training loss at step 960: 3.8003668785095215\n",
      "Training loss at step 992: 3.62874436378479\n",
      "Training loss at step 1024: 3.486253023147583\n",
      "Training loss at step 1056: 3.3456521034240723\n",
      "Training loss at step 1088: 3.1782100200653076\n",
      "Training loss at step 1120: 3.0287206172943115\n",
      "Training loss at step 1152: 2.9145078659057617\n",
      "Training loss at step 1184: 2.836543083190918\n",
      "Training loss at step 1216: 2.796877861022949\n",
      "Training loss at step 1248: 2.808513879776001\n",
      "Training loss at step 1280: 2.950077533721924\n",
      "Training loss at step 1312: 3.2736964225769043\n",
      "Training loss at step 1344: 3.7254385948181152\n",
      "Training loss at step 1376: 4.190822601318359\n",
      "Training loss at step 1408: 4.603418827056885\n",
      "Training loss at step 1440: 4.960000038146973\n",
      "Training loss at step 1472: 5.274255752563477\n",
      "Training loss at step 1504: 5.559192180633545\n",
      "Training loss at step 1536: 5.836727619171143\n",
      "Training loss at step 1568: 6.122492790222168\n",
      "Training loss at step 1600: 6.485810279846191\n",
      "Training loss at step 1632: 6.849830627441406\n",
      "Training loss at step 1664: 7.194633483886719\n",
      "Training loss at step 1696: 7.4786763191223145\n",
      "Training loss at step 1728: 7.611880779266357\n",
      "Training loss at step 1760: 7.360554218292236\n",
      "Training loss at step 1792: 6.598329544067383\n",
      "Training loss at step 1824: 5.703726768493652\n",
      "Training loss at step 1856: 4.953070640563965\n",
      "Training loss at step 1888: 4.467672348022461\n",
      "Training loss at step 1920: 4.145689010620117\n",
      "Training loss at step 1952: 3.9616451263427734\n",
      "Training loss at step 1984: 3.889772653579712\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at step 0: 4.006912708282471\n",
      "Training loss at step 32: 3.578955888748169\n",
      "Training loss at step 64: 3.354998826980591\n",
      "Training loss at step 96: 3.201188087463379\n",
      "Training loss at step 128: 3.057680606842041\n",
      "Training loss at step 160: 2.9285271167755127\n",
      "Training loss at step 192: 2.835700511932373\n",
      "Training loss at step 224: 2.7945849895477295\n",
      "Training loss at step 256: 2.832947254180908\n",
      "Training loss at step 288: 3.0188536643981934\n",
      "Training loss at step 320: 3.3782224655151367\n",
      "Training loss at step 352: 3.847043991088867\n",
      "Training loss at step 384: 4.312078475952148\n",
      "Training loss at step 416: 4.685623645782471\n",
      "Training loss at step 448: 4.989548206329346\n",
      "Training loss at step 480: 5.248751640319824\n",
      "Training loss at step 512: 5.49923038482666\n",
      "Training loss at step 544: 5.775902271270752\n",
      "Training loss at step 576: 6.104707717895508\n",
      "Training loss at step 608: 6.486976623535156\n",
      "Training loss at step 640: 6.8929853439331055\n",
      "Training loss at step 672: 7.262759208679199\n",
      "Training loss at step 704: 7.527859687805176\n",
      "Training loss at step 736: 7.610927581787109\n",
      "Training loss at step 768: 7.2153825759887695\n",
      "Training loss at step 800: 6.351923942565918\n",
      "Training loss at step 832: 5.44782018661499\n",
      "Training loss at step 864: 4.74813175201416\n",
      "Training loss at step 896: 4.303398132324219\n",
      "Training loss at step 928: 4.03405237197876\n",
      "Training loss at step 960: 3.827139377593994\n",
      "Training loss at step 992: 3.653042793273926\n",
      "Training loss at step 1024: 3.511471748352051\n",
      "Training loss at step 1056: 3.39652681350708\n",
      "Training loss at step 1088: 3.2208197116851807\n",
      "Training loss at step 1120: 3.0533854961395264\n",
      "Training loss at step 1152: 2.926772117614746\n",
      "Training loss at step 1184: 2.8446199893951416\n",
      "Training loss at step 1216: 2.8015248775482178\n",
      "Training loss at step 1248: 2.808387279510498\n",
      "Training loss at step 1280: 2.9567008018493652\n",
      "Training loss at step 1312: 3.301374673843384\n",
      "Training loss at step 1344: 3.766785144805908\n",
      "Training loss at step 1376: 4.218094825744629\n",
      "Training loss at step 1408: 4.623571395874023\n",
      "Training loss at step 1440: 4.96869421005249\n",
      "Training loss at step 1472: 5.277891635894775\n",
      "Training loss at step 1504: 5.548057556152344\n",
      "Training loss at step 1536: 5.8134002685546875\n",
      "Training loss at step 1568: 6.096109390258789\n",
      "Training loss at step 1600: 6.451096534729004\n",
      "Training loss at step 1632: 6.805253982543945\n",
      "Training loss at step 1664: 7.178629398345947\n",
      "Training loss at step 1696: 7.475803375244141\n",
      "Training loss at step 1728: 7.609755516052246\n",
      "Training loss at step 1760: 7.361000061035156\n",
      "Training loss at step 1792: 6.612191200256348\n",
      "Training loss at step 1824: 5.714616775512695\n",
      "Training loss at step 1856: 4.951629638671875\n",
      "Training loss at step 1888: 4.45947265625\n",
      "Training loss at step 1920: 4.134261608123779\n",
      "Training loss at step 1952: 3.954862356185913\n",
      "Training loss at step 1984: 3.894071578979492\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at step 0: 4.043111801147461\n",
      "Training loss at step 32: 3.574118137359619\n",
      "Training loss at step 64: 3.3295228481292725\n",
      "Training loss at step 96: 3.1484718322753906\n",
      "Training loss at step 128: 3.0040202140808105\n",
      "Training loss at step 160: 2.894967555999756\n",
      "Training loss at step 192: 2.8256053924560547\n",
      "Training loss at step 224: 2.7959258556365967\n",
      "Training loss at step 256: 2.8298778533935547\n",
      "Training loss at step 288: 3.0217628479003906\n",
      "Training loss at step 320: 3.402003765106201\n",
      "Training loss at step 352: 3.8644893169403076\n",
      "Training loss at step 384: 4.303222179412842\n",
      "Training loss at step 416: 4.690918445587158\n",
      "Training loss at step 448: 4.999638557434082\n",
      "Training loss at step 480: 5.254577159881592\n",
      "Training loss at step 512: 5.499753952026367\n",
      "Training loss at step 544: 5.776823997497559\n",
      "Training loss at step 576: 6.117579460144043\n",
      "Training loss at step 608: 6.518408298492432\n",
      "Training loss at step 640: 6.921111583709717\n",
      "Training loss at step 672: 7.278228282928467\n",
      "Training loss at step 704: 7.527713298797607\n",
      "Training loss at step 736: 7.597413539886475\n",
      "Training loss at step 768: 7.204904556274414\n",
      "Training loss at step 800: 6.350641250610352\n",
      "Training loss at step 832: 5.448426246643066\n",
      "Training loss at step 864: 4.745340347290039\n",
      "Training loss at step 896: 4.278676509857178\n",
      "Training loss at step 928: 3.987433910369873\n",
      "Training loss at step 960: 3.7817015647888184\n",
      "Training loss at step 992: 3.6147122383117676\n",
      "Training loss at step 1024: 3.4753124713897705\n",
      "Training loss at step 1056: 3.352313280105591\n",
      "Training loss at step 1088: 3.1932733058929443\n",
      "Training loss at step 1120: 3.039091110229492\n",
      "Training loss at step 1152: 2.9191038608551025\n",
      "Training loss at step 1184: 2.8400521278381348\n",
      "Training loss at step 1216: 2.800105094909668\n",
      "Training loss at step 1248: 2.8087995052337646\n",
      "Training loss at step 1280: 2.952148675918579\n",
      "Training loss at step 1312: 3.288219451904297\n",
      "Training loss at step 1344: 3.74875545501709\n",
      "Training loss at step 1376: 4.205617427825928\n",
      "Training loss at step 1408: 4.622459888458252\n",
      "Training loss at step 1440: 4.989108085632324\n",
      "Training loss at step 1472: 5.3022966384887695\n",
      "Training loss at step 1504: 5.583954334259033\n",
      "Training loss at step 1536: 5.858002662658691\n",
      "Training loss at step 1568: 6.143788814544678\n",
      "Training loss at step 1600: 6.509921073913574\n",
      "Training loss at step 1632: 6.8915300369262695\n",
      "Training loss at step 1664: 7.218442440032959\n",
      "Training loss at step 1696: 7.493526458740234\n",
      "Training loss at step 1728: 7.625487327575684\n",
      "Training loss at step 1760: 7.364406108856201\n",
      "Training loss at step 1792: 6.591241836547852\n",
      "Training loss at step 1824: 5.695213794708252\n",
      "Training loss at step 1856: 4.9568376541137695\n",
      "Training loss at step 1888: 4.483187675476074\n",
      "Training loss at step 1920: 4.169205188751221\n",
      "Training loss at step 1952: 3.9926390647888184\n",
      "Training loss at step 1984: 3.9159934520721436\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at step 0: 4.006181240081787\n",
      "Training loss at step 32: 3.5682058334350586\n",
      "Training loss at step 64: 3.330162286758423\n",
      "Training loss at step 96: 3.1531319618225098\n",
      "Training loss at step 128: 3.007906198501587\n",
      "Training loss at step 160: 2.8995914459228516\n",
      "Training loss at step 192: 2.832331418991089\n",
      "Training loss at step 224: 2.8052821159362793\n",
      "Training loss at step 256: 2.83707594871521\n",
      "Training loss at step 288: 3.0158567428588867\n",
      "Training loss at step 320: 3.3919076919555664\n",
      "Training loss at step 352: 3.8641648292541504\n",
      "Training loss at step 384: 4.304121017456055\n",
      "Training loss at step 416: 4.691781044006348\n",
      "Training loss at step 448: 5.003363132476807\n",
      "Training loss at step 480: 5.261960029602051\n",
      "Training loss at step 512: 5.515597820281982\n",
      "Training loss at step 544: 5.784856796264648\n",
      "Training loss at step 576: 6.110665321350098\n",
      "Training loss at step 608: 6.49167537689209\n",
      "Training loss at step 640: 6.893070220947266\n",
      "Training loss at step 672: 7.263739109039307\n",
      "Training loss at step 704: 7.526123046875\n",
      "Training loss at step 736: 7.600314617156982\n",
      "Training loss at step 768: 7.203691482543945\n",
      "Training loss at step 800: 6.357342720031738\n",
      "Training loss at step 832: 5.460768222808838\n",
      "Training loss at step 864: 4.761570930480957\n",
      "Training loss at step 896: 4.30256462097168\n",
      "Training loss at step 928: 4.00657320022583\n",
      "Training loss at step 960: 3.7877745628356934\n",
      "Training loss at step 992: 3.617555856704712\n",
      "Training loss at step 1024: 3.4755988121032715\n",
      "Training loss at step 1056: 3.335789442062378\n",
      "Training loss at step 1088: 3.180431365966797\n",
      "Training loss at step 1120: 3.0314133167266846\n",
      "Training loss at step 1152: 2.9143247604370117\n",
      "Training loss at step 1184: 2.836474657058716\n",
      "Training loss at step 1216: 2.799527645111084\n",
      "Training loss at step 1248: 2.8151092529296875\n",
      "Training loss at step 1280: 2.9531829357147217\n",
      "Training loss at step 1312: 3.271103620529175\n",
      "Training loss at step 1344: 3.7250053882598877\n",
      "Training loss at step 1376: 4.191192150115967\n",
      "Training loss at step 1408: 4.610576152801514\n",
      "Training loss at step 1440: 4.975343227386475\n",
      "Training loss at step 1472: 5.287228584289551\n",
      "Training loss at step 1504: 5.567684173583984\n",
      "Training loss at step 1536: 5.835390090942383\n",
      "Training loss at step 1568: 6.122336387634277\n",
      "Training loss at step 1600: 6.48394250869751\n",
      "Training loss at step 1632: 6.831910133361816\n",
      "Training loss at step 1664: 7.184391975402832\n",
      "Training loss at step 1696: 7.475299835205078\n",
      "Training loss at step 1728: 7.610828399658203\n",
      "Training loss at step 1760: 7.360726833343506\n",
      "Training loss at step 1792: 6.603057384490967\n",
      "Training loss at step 1824: 5.7141852378845215\n",
      "Training loss at step 1856: 4.9534592628479\n",
      "Training loss at step 1888: 4.457110404968262\n",
      "Training loss at step 1920: 4.1317620277404785\n",
      "Training loss at step 1952: 3.9399871826171875\n",
      "Training loss at step 1984: 3.847493886947632\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at step 0: 4.025627136230469\n",
      "Training loss at step 32: 3.5879287719726562\n",
      "Training loss at step 64: 3.3514580726623535\n",
      "Training loss at step 96: 3.182668924331665\n",
      "Training loss at step 128: 3.034590721130371\n",
      "Training loss at step 160: 2.910745859146118\n",
      "Training loss at step 192: 2.8279550075531006\n",
      "Training loss at step 224: 2.795535087585449\n",
      "Training loss at step 256: 2.840555191040039\n",
      "Training loss at step 288: 3.024137258529663\n",
      "Training loss at step 320: 3.378760814666748\n",
      "Training loss at step 352: 3.843972682952881\n",
      "Training loss at step 384: 4.300410270690918\n",
      "Training loss at step 416: 4.686697483062744\n",
      "Training loss at step 448: 4.998351097106934\n",
      "Training loss at step 480: 5.259608268737793\n",
      "Training loss at step 512: 5.515830993652344\n",
      "Training loss at step 544: 5.788219451904297\n",
      "Training loss at step 576: 6.116268157958984\n",
      "Training loss at step 608: 6.496589660644531\n",
      "Training loss at step 640: 6.895139217376709\n",
      "Training loss at step 672: 7.266149997711182\n",
      "Training loss at step 704: 7.529815673828125\n",
      "Training loss at step 736: 7.6060895919799805\n",
      "Training loss at step 768: 7.205767631530762\n",
      "Training loss at step 800: 6.352728843688965\n",
      "Training loss at step 832: 5.457013130187988\n",
      "Training loss at step 864: 4.751596450805664\n",
      "Training loss at step 896: 4.290231227874756\n",
      "Training loss at step 928: 4.009445667266846\n",
      "Training loss at step 960: 3.8043570518493652\n",
      "Training loss at step 992: 3.6331517696380615\n",
      "Training loss at step 1024: 3.487070083618164\n",
      "Training loss at step 1056: 3.3507866859436035\n",
      "Training loss at step 1088: 3.1905720233917236\n",
      "Training loss at step 1120: 3.038020372390747\n",
      "Training loss at step 1152: 2.917722225189209\n",
      "Training loss at step 1184: 2.838986396789551\n",
      "Training loss at step 1216: 2.801791191101074\n",
      "Training loss at step 1248: 2.8125674724578857\n",
      "Training loss at step 1280: 2.950303554534912\n",
      "Training loss at step 1312: 3.2749059200286865\n",
      "Training loss at step 1344: 3.730757236480713\n",
      "Training loss at step 1376: 4.1926140785217285\n",
      "Training loss at step 1408: 4.598517417907715\n",
      "Training loss at step 1440: 4.946261405944824\n",
      "Training loss at step 1472: 5.253903865814209\n",
      "Training loss at step 1504: 5.542754173278809\n",
      "Training loss at step 1536: 5.823662757873535\n",
      "Training loss at step 1568: 6.114401817321777\n",
      "Training loss at step 1600: 6.479154586791992\n",
      "Training loss at step 1632: 6.824446201324463\n",
      "Training loss at step 1664: 7.1809983253479\n",
      "Training loss at step 1696: 7.473876953125\n",
      "Training loss at step 1728: 7.607874870300293\n",
      "Training loss at step 1760: 7.361673355102539\n",
      "Training loss at step 1792: 6.607029914855957\n",
      "Training loss at step 1824: 5.700911521911621\n",
      "Training loss at step 1856: 4.939659118652344\n",
      "Training loss at step 1888: 4.449920654296875\n",
      "Training loss at step 1920: 4.130121231079102\n",
      "Training loss at step 1952: 3.9524288177490234\n",
      "Training loss at step 1984: 3.8785665035247803\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at step 0: 4.024840831756592\n",
      "Training loss at step 32: 3.56330943107605\n",
      "Training loss at step 64: 3.3237709999084473\n",
      "Training loss at step 96: 3.1502315998077393\n",
      "Training loss at step 128: 3.0099220275878906\n",
      "Training loss at step 160: 2.9000258445739746\n",
      "Training loss at step 192: 2.827176094055176\n",
      "Training loss at step 224: 2.7946107387542725\n",
      "Training loss at step 256: 2.829432249069214\n",
      "Training loss at step 288: 3.018435478210449\n",
      "Training loss at step 320: 3.385680675506592\n",
      "Training loss at step 352: 3.845444440841675\n",
      "Training loss at step 384: 4.300789833068848\n",
      "Training loss at step 416: 4.683679580688477\n",
      "Training loss at step 448: 4.990847587585449\n",
      "Training loss at step 480: 5.248599052429199\n",
      "Training loss at step 512: 5.498889923095703\n",
      "Training loss at step 544: 5.7789812088012695\n",
      "Training loss at step 576: 6.110945224761963\n",
      "Training loss at step 608: 6.502480506896973\n",
      "Training loss at step 640: 6.905941963195801\n",
      "Training loss at step 672: 7.267958641052246\n",
      "Training loss at step 704: 7.5241498947143555\n",
      "Training loss at step 736: 7.601217746734619\n",
      "Training loss at step 768: 7.211666584014893\n",
      "Training loss at step 800: 6.3557634353637695\n",
      "Training loss at step 832: 5.451822280883789\n",
      "Training loss at step 864: 4.746186256408691\n",
      "Training loss at step 896: 4.274750232696533\n",
      "Training loss at step 928: 3.9793460369110107\n",
      "Training loss at step 960: 3.7698516845703125\n",
      "Training loss at step 992: 3.604320764541626\n",
      "Training loss at step 1024: 3.459456443786621\n",
      "Training loss at step 1056: 3.3175740242004395\n",
      "Training loss at step 1088: 3.166904926300049\n",
      "Training loss at step 1120: 3.0274245738983154\n",
      "Training loss at step 1152: 2.9153690338134766\n",
      "Training loss at step 1184: 2.8376710414886475\n",
      "Training loss at step 1216: 2.7969202995300293\n",
      "Training loss at step 1248: 2.808824300765991\n",
      "Training loss at step 1280: 2.9502077102661133\n",
      "Training loss at step 1312: 3.27225399017334\n",
      "Training loss at step 1344: 3.7257909774780273\n",
      "Training loss at step 1376: 4.190810680389404\n",
      "Training loss at step 1408: 4.599842071533203\n",
      "Training loss at step 1440: 4.952660083770752\n",
      "Training loss at step 1472: 5.261857509613037\n",
      "Training loss at step 1504: 5.548871040344238\n",
      "Training loss at step 1536: 5.8288116455078125\n",
      "Training loss at step 1568: 6.124372959136963\n",
      "Training loss at step 1600: 6.492609977722168\n",
      "Training loss at step 1632: 6.841916084289551\n",
      "Training loss at step 1664: 7.187649726867676\n",
      "Training loss at step 1696: 7.475242614746094\n",
      "Training loss at step 1728: 7.609121322631836\n",
      "Training loss at step 1760: 7.360672473907471\n",
      "Training loss at step 1792: 6.601753234863281\n",
      "Training loss at step 1824: 5.697487831115723\n",
      "Training loss at step 1856: 4.941927909851074\n",
      "Training loss at step 1888: 4.4576239585876465\n",
      "Training loss at step 1920: 4.143115997314453\n",
      "Training loss at step 1952: 3.968109607696533\n",
      "Training loss at step 1984: 3.8913824558258057\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at step 0: 4.02733039855957\n",
      "Training loss at step 32: 3.57726788520813\n",
      "Training loss at step 64: 3.3416318893432617\n",
      "Training loss at step 96: 3.163670063018799\n",
      "Training loss at step 128: 3.014923095703125\n",
      "Training loss at step 160: 2.903831720352173\n",
      "Training loss at step 192: 2.8334591388702393\n",
      "Training loss at step 224: 2.802206516265869\n",
      "Training loss at step 256: 2.8318934440612793\n",
      "Training loss at step 288: 3.0195252895355225\n",
      "Training loss at step 320: 3.401618003845215\n",
      "Training loss at step 352: 3.8662893772125244\n",
      "Training loss at step 384: 4.305509567260742\n",
      "Training loss at step 416: 4.695950031280518\n",
      "Training loss at step 448: 5.005256652832031\n",
      "Training loss at step 480: 5.258502006530762\n",
      "Training loss at step 512: 5.502800464630127\n",
      "Training loss at step 544: 5.776018142700195\n",
      "Training loss at step 576: 6.105490684509277\n",
      "Training loss at step 608: 6.494810104370117\n",
      "Training loss at step 640: 6.9022722244262695\n",
      "Training loss at step 672: 7.267669677734375\n",
      "Training loss at step 704: 7.524590015411377\n",
      "Training loss at step 736: 7.597438812255859\n",
      "Training loss at step 768: 7.204207897186279\n",
      "Training loss at step 800: 6.356125831604004\n",
      "Training loss at step 832: 5.45023775100708\n",
      "Training loss at step 864: 4.745805263519287\n",
      "Training loss at step 896: 4.274931907653809\n",
      "Training loss at step 928: 3.9749562740325928\n",
      "Training loss at step 960: 3.765839099884033\n",
      "Training loss at step 992: 3.6010398864746094\n",
      "Training loss at step 1024: 3.4564590454101562\n",
      "Training loss at step 1056: 3.3136813640594482\n",
      "Training loss at step 1088: 3.1654045581817627\n",
      "Training loss at step 1120: 3.028674364089966\n",
      "Training loss at step 1152: 2.9186949729919434\n",
      "Training loss at step 1184: 2.840590715408325\n",
      "Training loss at step 1216: 2.797090768814087\n",
      "Training loss at step 1248: 2.8089799880981445\n",
      "Training loss at step 1280: 2.951328992843628\n",
      "Training loss at step 1312: 3.2707817554473877\n",
      "Training loss at step 1344: 3.7221217155456543\n",
      "Training loss at step 1376: 4.190629005432129\n",
      "Training loss at step 1408: 4.60059928894043\n",
      "Training loss at step 1440: 4.954341888427734\n",
      "Training loss at step 1472: 5.26863956451416\n",
      "Training loss at step 1504: 5.558708190917969\n",
      "Training loss at step 1536: 5.837879180908203\n",
      "Training loss at step 1568: 6.137847423553467\n",
      "Training loss at step 1600: 6.509366035461426\n",
      "Training loss at step 1632: 6.871480941772461\n",
      "Training loss at step 1664: 7.203032493591309\n",
      "Training loss at step 1696: 7.482097625732422\n",
      "Training loss at step 1728: 7.611138820648193\n",
      "Training loss at step 1760: 7.360321998596191\n",
      "Training loss at step 1792: 6.598371505737305\n",
      "Training loss at step 1824: 5.699249267578125\n",
      "Training loss at step 1856: 4.949378967285156\n",
      "Training loss at step 1888: 4.467518329620361\n",
      "Training loss at step 1920: 4.153200149536133\n",
      "Training loss at step 1952: 3.9699246883392334\n",
      "Training loss at step 1984: 3.891126871109009\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at step 0: 3.9986884593963623\n",
      "Training loss at step 32: 3.5609796047210693\n",
      "Training loss at step 64: 3.3234641551971436\n",
      "Training loss at step 96: 3.1474251747131348\n",
      "Training loss at step 128: 3.0040602684020996\n",
      "Training loss at step 160: 2.898319721221924\n",
      "Training loss at step 192: 2.83880352973938\n",
      "Training loss at step 224: 2.822009325027466\n",
      "Training loss at step 256: 2.854877233505249\n",
      "Training loss at step 288: 3.018387794494629\n",
      "Training loss at step 320: 3.3815975189208984\n",
      "Training loss at step 352: 3.851517677307129\n",
      "Training loss at step 384: 4.300624847412109\n",
      "Training loss at step 416: 4.686183929443359\n",
      "Training loss at step 448: 4.996660232543945\n",
      "Training loss at step 480: 5.256421089172363\n",
      "Training loss at step 512: 5.511397361755371\n",
      "Training loss at step 544: 5.784461498260498\n",
      "Training loss at step 576: 6.1125593185424805\n",
      "Training loss at step 608: 6.497435569763184\n",
      "Training loss at step 640: 6.90386962890625\n",
      "Training loss at step 672: 7.272625923156738\n",
      "Training loss at step 704: 7.534707069396973\n",
      "Training loss at step 736: 7.6070051193237305\n",
      "Training loss at step 768: 7.204563617706299\n",
      "Training loss at step 800: 6.355932712554932\n",
      "Training loss at step 832: 5.461174964904785\n",
      "Training loss at step 864: 4.759551048278809\n",
      "Training loss at step 896: 4.2878336906433105\n",
      "Training loss at step 928: 3.988643169403076\n",
      "Training loss at step 960: 3.7750778198242188\n",
      "Training loss at step 992: 3.606964349746704\n",
      "Training loss at step 1024: 3.461754560470581\n",
      "Training loss at step 1056: 3.318965435028076\n",
      "Training loss at step 1088: 3.16579532623291\n",
      "Training loss at step 1120: 3.0295145511627197\n",
      "Training loss at step 1152: 2.9239656925201416\n",
      "Training loss at step 1184: 2.8496761322021484\n",
      "Training loss at step 1216: 2.808088779449463\n",
      "Training loss at step 1248: 2.811293125152588\n",
      "Training loss at step 1280: 2.951206684112549\n",
      "Training loss at step 1312: 3.2715413570404053\n",
      "Training loss at step 1344: 3.7218611240386963\n",
      "Training loss at step 1376: 4.194943904876709\n",
      "Training loss at step 1408: 4.59669303894043\n",
      "Training loss at step 1440: 4.938044548034668\n",
      "Training loss at step 1472: 5.244932174682617\n",
      "Training loss at step 1504: 5.52375602722168\n",
      "Training loss at step 1536: 5.7868194580078125\n",
      "Training loss at step 1568: 6.092533111572266\n",
      "Training loss at step 1600: 6.443930625915527\n",
      "Training loss at step 1632: 6.798604488372803\n",
      "Training loss at step 1664: 7.177770614624023\n",
      "Training loss at step 1696: 7.473282814025879\n",
      "Training loss at step 1728: 7.60756778717041\n",
      "Training loss at step 1760: 7.361887454986572\n",
      "Training loss at step 1792: 6.611944198608398\n",
      "Training loss at step 1824: 5.712591648101807\n",
      "Training loss at step 1856: 4.938268661499023\n",
      "Training loss at step 1888: 4.4413957595825195\n",
      "Training loss at step 1920: 4.120800971984863\n",
      "Training loss at step 1952: 3.9238545894622803\n",
      "Training loss at step 1984: 3.8371849060058594\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at step 0: 4.0034990310668945\n",
      "Training loss at step 32: 3.573195695877075\n",
      "Training loss at step 64: 3.332244396209717\n",
      "Training loss at step 96: 3.1579971313476562\n",
      "Training loss at step 128: 3.0136027336120605\n",
      "Training loss at step 160: 2.8986306190490723\n",
      "Training loss at step 192: 2.8251335620880127\n",
      "Training loss at step 224: 2.797004222869873\n",
      "Training loss at step 256: 2.8338727951049805\n",
      "Training loss at step 288: 3.016068935394287\n",
      "Training loss at step 320: 3.377070665359497\n",
      "Training loss at step 352: 3.8469462394714355\n",
      "Training loss at step 384: 4.324913501739502\n",
      "Training loss at step 416: 4.694400310516357\n",
      "Training loss at step 448: 4.9929914474487305\n",
      "Training loss at step 480: 5.249822616577148\n",
      "Training loss at step 512: 5.49913215637207\n",
      "Training loss at step 544: 5.776934623718262\n",
      "Training loss at step 576: 6.1049957275390625\n",
      "Training loss at step 608: 6.487178802490234\n",
      "Training loss at step 640: 6.892301082611084\n",
      "Training loss at step 672: 7.2636494636535645\n",
      "Training loss at step 704: 7.533504009246826\n",
      "Training loss at step 736: 7.624353408813477\n",
      "Training loss at step 768: 7.229792594909668\n",
      "Training loss at step 800: 6.358426094055176\n",
      "Training loss at step 832: 5.449012279510498\n",
      "Training loss at step 864: 4.745639801025391\n",
      "Training loss at step 896: 4.2770915031433105\n",
      "Training loss at step 928: 3.988530158996582\n",
      "Training loss at step 960: 3.782083034515381\n",
      "Training loss at step 992: 3.615328311920166\n",
      "Training loss at step 1024: 3.4679317474365234\n",
      "Training loss at step 1056: 3.328951597213745\n",
      "Training loss at step 1088: 3.177156448364258\n",
      "Training loss at step 1120: 3.0318894386291504\n",
      "Training loss at step 1152: 2.916125535964966\n",
      "Training loss at step 1184: 2.838862657546997\n",
      "Training loss at step 1216: 2.8014180660247803\n",
      "Training loss at step 1248: 2.8118717670440674\n",
      "Training loss at step 1280: 2.9500839710235596\n",
      "Training loss at step 1312: 3.2762413024902344\n",
      "Training loss at step 1344: 3.736675262451172\n",
      "Training loss at step 1376: 4.19983434677124\n",
      "Training loss at step 1408: 4.614041328430176\n",
      "Training loss at step 1440: 4.958477973937988\n",
      "Training loss at step 1472: 5.279239654541016\n",
      "Training loss at step 1504: 5.573186874389648\n",
      "Training loss at step 1536: 5.841280937194824\n",
      "Training loss at step 1568: 6.139720916748047\n",
      "Training loss at step 1600: 6.482245922088623\n",
      "Training loss at step 1632: 6.813222408294678\n",
      "Training loss at step 1664: 7.177844047546387\n",
      "Training loss at step 1696: 7.473416805267334\n",
      "Training loss at step 1728: 7.608013153076172\n",
      "Training loss at step 1760: 7.361642360687256\n",
      "Training loss at step 1792: 6.617408752441406\n",
      "Training loss at step 1824: 5.720977783203125\n",
      "Training loss at step 1856: 4.941378593444824\n",
      "Training loss at step 1888: 4.441253185272217\n",
      "Training loss at step 1920: 4.121513366699219\n",
      "Training loss at step 1952: 3.946091651916504\n",
      "Training loss at step 1984: 3.876662015914917\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at step 0: 3.997952938079834\n",
      "Training loss at step 32: 3.566530227661133\n",
      "Training loss at step 64: 3.3296010494232178\n",
      "Training loss at step 96: 3.1584813594818115\n",
      "Training loss at step 128: 3.0176150798797607\n",
      "Training loss at step 160: 2.9027318954467773\n",
      "Training loss at step 192: 2.82669997215271\n",
      "Training loss at step 224: 2.7947781085968018\n",
      "Training loss at step 256: 2.8305561542510986\n",
      "Training loss at step 288: 3.0192103385925293\n",
      "Training loss at step 320: 3.3928611278533936\n",
      "Training loss at step 352: 3.8480777740478516\n",
      "Training loss at step 384: 4.308713436126709\n",
      "Training loss at step 416: 4.689610004425049\n",
      "Training loss at step 448: 4.993677139282227\n",
      "Training loss at step 480: 5.261073112487793\n",
      "Training loss at step 512: 5.526115417480469\n",
      "Training loss at step 544: 5.823601722717285\n",
      "Training loss at step 576: 6.1974005699157715\n",
      "Training loss at step 608: 6.585962772369385\n",
      "Training loss at step 640: 6.966087341308594\n",
      "Training loss at step 672: 7.300661563873291\n",
      "Training loss at step 704: 7.536397457122803\n",
      "Training loss at step 736: 7.598560810089111\n",
      "Training loss at step 768: 7.204710960388184\n",
      "Training loss at step 800: 6.351942539215088\n",
      "Training loss at step 832: 5.448287487030029\n",
      "Training loss at step 864: 4.748732566833496\n",
      "Training loss at step 896: 4.274018287658691\n",
      "Training loss at step 928: 3.972043991088867\n",
      "Training loss at step 960: 3.7663447856903076\n",
      "Training loss at step 992: 3.6027417182922363\n",
      "Training loss at step 1024: 3.4588844776153564\n",
      "Training loss at step 1056: 3.322138786315918\n",
      "Training loss at step 1088: 3.1762661933898926\n",
      "Training loss at step 1120: 3.035492181777954\n",
      "Training loss at step 1152: 2.9205636978149414\n",
      "Training loss at step 1184: 2.845140218734741\n",
      "Training loss at step 1216: 2.8078181743621826\n",
      "Training loss at step 1248: 2.8154172897338867\n",
      "Training loss at step 1280: 2.9503774642944336\n",
      "Training loss at step 1312: 3.2845895290374756\n",
      "Training loss at step 1344: 3.7536091804504395\n",
      "Training loss at step 1376: 4.217107772827148\n",
      "Training loss at step 1408: 4.635772705078125\n",
      "Training loss at step 1440: 4.989699840545654\n",
      "Training loss at step 1472: 5.305044174194336\n",
      "Training loss at step 1504: 5.578738212585449\n",
      "Training loss at step 1536: 5.868343830108643\n",
      "Training loss at step 1568: 6.182616233825684\n",
      "Training loss at step 1600: 6.5639801025390625\n",
      "Training loss at step 1632: 6.9819440841674805\n",
      "Training loss at step 1664: 7.313968658447266\n",
      "Training loss at step 1696: 7.559776306152344\n",
      "Training loss at step 1728: 7.6604719161987305\n",
      "Training loss at step 1760: 7.379630088806152\n",
      "Training loss at step 1792: 6.583922386169434\n",
      "Training loss at step 1824: 5.682895660400391\n",
      "Training loss at step 1856: 4.958918571472168\n",
      "Training loss at step 1888: 4.500629425048828\n",
      "Training loss at step 1920: 4.207012176513672\n",
      "Training loss at step 1952: 4.048709392547607\n",
      "Training loss at step 1984: 3.9905893802642822\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at step 0: 3.997352123260498\n",
      "Training loss at step 32: 3.563833236694336\n",
      "Training loss at step 64: 3.335191488265991\n",
      "Training loss at step 96: 3.1630465984344482\n",
      "Training loss at step 128: 3.0206809043884277\n",
      "Training loss at step 160: 2.9143619537353516\n",
      "Training loss at step 192: 2.847285270690918\n",
      "Training loss at step 224: 2.816422939300537\n",
      "Training loss at step 256: 2.8400137424468994\n",
      "Training loss at step 288: 3.018460512161255\n",
      "Training loss at step 320: 3.4184775352478027\n",
      "Training loss at step 352: 3.905226230621338\n",
      "Training loss at step 384: 4.329092025756836\n",
      "Training loss at step 416: 4.720188140869141\n",
      "Training loss at step 448: 5.028921127319336\n",
      "Training loss at step 480: 5.288862228393555\n",
      "Training loss at step 512: 5.53827428817749\n",
      "Training loss at step 544: 5.798830986022949\n",
      "Training loss at step 576: 6.120474338531494\n",
      "Training loss at step 608: 6.496955871582031\n",
      "Training loss at step 640: 6.895737648010254\n",
      "Training loss at step 672: 7.2653422355651855\n",
      "Training loss at step 704: 7.527573108673096\n",
      "Training loss at step 736: 7.600818634033203\n",
      "Training loss at step 768: 7.204536437988281\n",
      "Training loss at step 800: 6.376397609710693\n",
      "Training loss at step 832: 5.516271591186523\n",
      "Training loss at step 864: 4.7902350425720215\n",
      "Training loss at step 896: 4.304581165313721\n",
      "Training loss at step 928: 4.027673721313477\n",
      "Training loss at step 960: 3.8683855533599854\n",
      "Training loss at step 992: 3.7176525592803955\n",
      "Training loss at step 1024: 3.574524402618408\n",
      "Training loss at step 1056: 3.422656774520874\n",
      "Training loss at step 1088: 3.2237741947174072\n",
      "Training loss at step 1120: 3.0519847869873047\n",
      "Training loss at step 1152: 2.9255661964416504\n",
      "Training loss at step 1184: 2.839993476867676\n",
      "Training loss at step 1216: 2.7977867126464844\n",
      "Training loss at step 1248: 2.807831287384033\n",
      "Training loss at step 1280: 2.951108455657959\n",
      "Training loss at step 1312: 3.2797861099243164\n",
      "Training loss at step 1344: 3.7397913932800293\n",
      "Training loss at step 1376: 4.204174518585205\n",
      "Training loss at step 1408: 4.621872901916504\n",
      "Training loss at step 1440: 4.954543113708496\n",
      "Training loss at step 1472: 5.267543315887451\n",
      "Training loss at step 1504: 5.549928665161133\n",
      "Training loss at step 1536: 5.800782203674316\n",
      "Training loss at step 1568: 6.093158721923828\n",
      "Training loss at step 1600: 6.4167985916137695\n",
      "Training loss at step 1632: 6.791357517242432\n",
      "Training loss at step 1664: 7.178490161895752\n",
      "Training loss at step 1696: 7.4808268547058105\n",
      "Training loss at step 1728: 7.619029521942139\n",
      "Training loss at step 1760: 7.363343238830566\n",
      "Training loss at step 1792: 6.608612060546875\n",
      "Training loss at step 1824: 5.743946552276611\n",
      "Training loss at step 1856: 4.951339244842529\n",
      "Training loss at step 1888: 4.424263954162598\n",
      "Training loss at step 1920: 4.100399017333984\n",
      "Training loss at step 1952: 3.9186155796051025\n",
      "Training loss at step 1984: 3.8652572631835938\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def train_step(x_tr, y_tr):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_tr, training=True)  # Forward pass\n",
    "        loss_value = custom_loss(y_tr, y_pred)\n",
    "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss_value\n",
    "\n",
    "# Now we can use this function in a training loop\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for start in range(0, len(x_tr), batch_size):\n",
    "        end = start + batch_size\n",
    "        x_batch = x_tr[start:end]\n",
    "        y_batch = y_tr[start:end]\n",
    "        loss_value = train_step(x_batch, y_batch)\n",
    "\n",
    "        print('Training loss at step %s: %s' % (start, float(loss_value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 549us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_pinn = model.predict(x_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81447864, 0.8380156 ],\n",
       "       [0.81274563, 0.8365689 ],\n",
       "       [0.8110127 , 0.8351221 ],\n",
       "       ...,\n",
       "       [0.6804603 , 0.7348248 ],\n",
       "       [0.67874753, 0.73335105],\n",
       "       [0.6770348 , 0.73187727]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pinn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b28e019ad0>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred_pinn[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b28e0a5d90>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred_pinn[:,1])\n",
    "plt.plot(y_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
